---
title: "Probability and Information"
author: "Mac Strelioff"
date: "5/13/2019"
output: html_document
math: true
---



<div id="probability-theory-and-information-theory" class="section level1">
<h1>Probability Theory and Information Theory</h1>
<div id="types-of-probabilities-and-their-computations" class="section level2">
<h2>Types of Probabilities and Their Computations</h2>
<p>motivation? Many important variables (future income, GDP, who I’ll marry, whether I’ll get sick, what disease I have given some symptoms, …)</p>
</div>
<div id="randomness-event-spaces-and-probability" class="section level2">
<h2>Randomness, Event Spaces, and Probability</h2>
<p>motivating example.. Imagine that a vaccine against a dangerous disease recently becomes available. However, there is a small risk that the vaccine will produce a condition just as bad as the disease itself. You do not know whether you will get the disease, or whether, given the vaccine, you will contract the side effect. Should you get the vaccine or abstain and live with a higher risk of disease?</p>
Knowledge of random variables, and related concepts, can help in this and many other situations. Specifically;

<p>%Knowing the probabilities of each event in the event space under conditions where you take or abstain from the vaccine could determine your decision.</p>
<p>A random variable random variable is a variable with an unknown value, but known possible values. An event is an observed value of a random variable. An event space contains all possible values of the random variable. Probabilities are values assigned to the events in an event space (i.e. the possible values of a random variable) and represent how likely each event is relative to other events in the event space.</p>
Here <span class="math inline">\(p(e)\)</span> will be used to represent the probability of an event. Some special probabilities include the probability of any event in the event space, which is 1. And the probability of any event other than <span class="math inline">\(p(e)\)</span>, known as the compliment of <span class="math inline">\(p(e)\)</span>, denoted with <span class="math inline">\(p(\neg e)\)</span>, is found by;
<span class="math display">\[\begin{equation}
p(\neg e) = 1 - p(e)
\end{equation}\]</span>
<p>For example, the value observed when a six sided die is rolled could be considered a random variable with possible values of 1 through 6. Rolling the die could be an experiment, and, if a 5 lands face up, then 5 would be the outcome.</p>
<p>Probabilities are often thought of with reference to experiments and outcomes. In this context, an experiment is any opportunity to observe a relevant outcome. Outcomes are the consequences of an experiment, and one is typically interested in outcomes of a particular kind. For example, if coin flips are thought of as an experiment, then the outcomes of this experiment could be heads or tails. In this context, probabilities assign numbers to the outcomes (e.g. heads, or tails) of an experiment (e.g. coin toss).</p>
<p>see <a href="https://en.wikipedia.org/wiki/Probability_interpretations" class="uri">https://en.wikipedia.org/wiki/Probability_interpretations</a></p>
<p>define event define event space as all the events that could happen probability = events of interest / all possible events</p>
</div>
<div id="joint-events-and-the-multiplication-rule" class="section level2">
<h2>Joint Events and the Multiplication Rule</h2>
<p>A joint event refers to two or more events occurring together. They are colloquially talked about as one event ‘and’ another event occurring together. More formally, joint events are called intersections (represented with the <span class="math inline">\(\cap\)</span> symbol) between events. For events <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span>, the probability of their joint event will be represented with <span class="math inline">\(p(e_1 \cap e_2)\)</span>. The probability of an intersection of events is the same regardless of which event is considered first;</p>
<span class="math display">\[\begin{equation} \label{joint reflexivity}
p(e_1 \cap e_2) = p(e_2 \cap e_1)
\end{equation}\]</span>
For two events, <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span>, their intersection is found by;
<span class="math display">\[\begin{equation} \label{joint probability definition}
p(e_1 \&amp; e_2) = p(e_1\cap e_2) = p(e_1|e_2)p(e_2)
\end{equation}\]</span>
<p>where <span class="math inline">\(p(e_1|e_2)\)</span> is a conditional probability, discussed in the next section.</p>
</div>
<div id="conditional-events-and-bayes-rule" class="section level2">
<h2>Conditional Events and Bayes’ Rule</h2>
<p>Conditional events refer to one event, <span class="math inline">\(e_1\)</span>, after another event, <span class="math inline">\(e_2\)</span>, is known. <span class="math inline">\(p(e_1|e_2)\)</span> represents the probability of <span class="math inline">\(e_1\)</span> given, or after knowing, <span class="math inline">\(e_2\)</span>. These can be defined by rearranging the multiplication rule (equation ) as follows;</p>
<span class="math display">\[\begin{equation}
p(e_1|e_2)p(e_2)=p(e_1\cap e_2) \rightarrow p(e_1|e_2)= \frac{p(e_1\cap e_2)}{p(e_2)}
\end{equation}\]</span>
Noting that, by the reflexively of joint events (equation ) and the definition of the multiplication rule (equation ), <span class="math inline">\(p(e_1 \cap e_2) = p(e_2 \cap e_1)= p(e_2 | e_1) p(e_1)\)</span>, and so the above equation becomes;
<span class="math display">\[\begin{equation} \label{Bayes Theorem}
p(e_1|e_2)=\frac{p(e_2 | e_1) p(e_1)}{p(e_2)}
\end{equation}\]</span>
<p>Equation  is known as Bayes Theorem.</p>
</div>
<div id="unions-of-events-and-the-addition-rule" class="section level2">
<h2>Unions of Events and the Addition Rule</h2>
<p>A union (represented with the <span class="math inline">\(\cup\)</span> symbol) of events refers to at least one of multiple events occurring. For events, <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span>, their union would include the probability that <span class="math inline">\(e_1\)</span> occurs, the probability that or <span class="math inline">\(e_2\)</span> occurs, and the probability that both <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> occur. Colloquially this is talked about the probability of <span class="math inline">\(e_1\)</span> ‘or’ <span class="math inline">\(e_2\)</span>. Formally this is expressed and computed as;</p>
<span class="math display">\[\begin{equation} \label{addition rule}
p(e_1\text{ or } e_2) = p(e_1 \cup e_2) = p(e_1) + p(e_2) - p(e_1 \cap e_2)
\end{equation}\]</span>
<p>Where <span class="math inline">\(p(e_1 \cap e_2)\)</span> is a joint probability, defined in Equation .</p>
</div>
<div id="independent-events" class="section level2">
<h2>Independent Events</h2>
Independence is a common assumption in many statistical techniques. Statisticians assume independence primarily because it simplifies the computation of certain probabilities. Events are said to be independent if knowing one event does not change the probability of the other event. Formally, if events <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> are independent, this would mean that;
<span class="math display">\[\begin{equation} \label{independent definition}
p(e_1|e_2) = p(e_1) \text{ and } p(e_2|e_1) = p(e_2)
\end{equation}\]</span>
If <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> are independent, then their joint probability, defined in in Equation , simplifies as so;
<span class="math display">\[\begin{equation} \label{product rule with independence}
p(e_1 \cap e_2) = p(e_1|e_2)p(e_2) = p(e_1)p(e_2)
\end{equation}\]</span>
<p>Where the last equality is only true if <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> are independent (i.e. <span class="math inline">\(p(e_1|e_2)=p(e_1)\)</span>).</p>
This then simplifies the addition rule in Equation  so that;
<span class="math display">\[\begin{equation}
p(e_1 \cup e_2) = p(e_1) + p(e_2) - p(e_1|e_2)p(e_2) = p(e_1) + p(e_2) - p(e_1)p(e_2)
\end{equation}\]</span>
<p>Where again, the last part of this equality is only true if <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> are independent.</p>
</div>
<div id="mutually-exclusive-events" class="section level2">
<h2>Mutually Exclusive Events</h2>
<p>Events <span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> are said to be mutually exclusive if the occurrence of either event precludes the occurrence of the other event. Formally mutual exclusivity means that;</p>
<span class="math display">\[\begin{equation} \label{mutually exclusive definition}
p(e_1 | e_2) = 0 \text{ and } p(e_2 | e_1) = 0
\end{equation}\]</span>
If two events are mutually exclusive, then the probability of their joint event is;
<span class="math display">\[\begin{equation}
p(e_1 \cap e_2) = p(e_1|e_2)p(e_2) = 0*p(e_2) = 0
\end{equation}\]</span>
And the probability of their union simplifies to;
<span class="math display">\[\begin{equation}
p(e_1 \cup e_2) = p(e_1) + p(e_2) - p(e_1 \cap e_2) = p(e_1) + p(e_2) - 0 = p(e_1) + p(e_2)
\end{equation}\]</span>
</div>
</div>
<div id="probability-functions-and-parameter-estimation-via-likelihoods" class="section level1">
<h1>Probability Functions and Parameter Estimation via Likelihoods</h1>
<p>The general concepts of parameterized probability functions and likelihoods are introduced here. For specific distributions, see Chapter .</p>
<p>events can be thought of as values in spaces.. probability functions assign probabilities to data, assuming that parameters are known likelihoods assign probabilities to parameters, assuming the data are known or observed</p>
<div id="domain-of-a-function-as-an-event-space" class="section level2">
<h2>Domain of a Function as an Event Space</h2>
<p>In Section , probabilities were introduced with respect to events. If these events are a value, <span class="math inline">\(x\)</span>, from a large set of possible values, <span class="math inline">\(X\)</span>, then a probability function, denoted <span class="math inline">\(f(x|\theta)\)</span>, can be used to assign probabilities to the values <span class="math inline">\(x \in X\)</span>.</p>
</div>
<div id="pdfs-or-pmfs-and-cdfs" class="section level2">
<h2>PDFs or PMFs, and CDFs</h2>
<p>Probability functions are referred to as probability density functions (PDFs) if <span class="math inline">\(x\)</span> takes continuous values, and probability mass functions (PMFs) if <span class="math inline">\(x\)</span> takes discrete values. Regardless of the type of variable <span class="math inline">\(x\)</span> is, a probability function that assignes probabilities to values <span class="math inline">\(x\)</span> that depend on a known parameter or parameter vector, <span class="math inline">\(\theta\)</span>, is denoted <span class="math inline">\(f(x|\theta)\)</span>. The cumulative distribution function (CDF), denoted <span class="math inline">\(F(x|\theta)\)</span>, represents the total probability assigned to values of <span class="math inline">\(X\)</span> less than a particular value <span class="math inline">\(x\)</span>. The CDF is related to the PDF or PMF through integration from the left side. All of this can be summarized as;</p>
<span class="math display">\[\begin{equation}
p(X \leq x |\theta) = F(x|\theta) = \int_{-\infty}^x f(x|\theta) = \int_{-\infty}^x p(X=x|\theta)
\end{equation}\]</span>
<p>Note that integrals are replaced with summation when <span class="math inline">\(x\)</span> takes discrete values.</p>
<p>A technical difficulty when considering values in a continuous domain is that the probability of any single value is 0. To sidestep this issue, one can consider values within a tiny set of values around <span class="math inline">\(x\)</span>, that is, <span class="math inline">\(\{x:x\in x\pm \Delta\}\)</span>, for an arbitrarily small <span class="math inline">\(\Delta\)</span>.</p>
<p>Instead of being based on observations, these assign probabilities to a range of values, <span class="math inline">\(x\)</span>, in the domain of the function.</p>
</div>
<div id="likelihood-and-log-likelihood" class="section level2">
<h2>Likelihood and Log Likelihood</h2>
<p>The likelihood, denoted <span class="math inline">\(\mathcal{L}(\theta|x)\)</span>, assigns probabilities to values of a parameter or parameter vector, <span class="math inline">\(\theta\)</span>, when the events or data, <span class="math inline">\(x\)</span> are treated as known. When a number, <span class="math inline">\(n\)</span>, of observations are made, and independence between the observations is assumed, the likelihood can be expressed as;</p>
<span class="math display">\[\begin{equation}
\mathcal{L}(\theta | x_1,x_2,...,x_n) = p(\theta | x_1,x_2,...,x_n) = p(\theta|x_1) p(\theta|x_2) ... p(\theta|x_n) = \prod_{i=1}^n p(\theta|x_i)
\end{equation}\]</span>
<p>Likelihoods can be difficult to work with analytically if they are complicated functions, and numerically if they are very small numbers. Because of this, log likelihoods are often used in place of likelihoods. A log likelihood is defined as;</p>
<span class="math display">\[\begin{equation}
\ell(\theta | x_1,x_2,...,x_n) = log(\mathcal{L}(\theta | x_1,x_2,...,x_n)) = \sum_{i=1}^n p(\theta | x_i)
\end{equation}\]</span>
</div>
<div id="score-function-and-fisher-information" class="section level2">
<h2>Score Function and Fisher Information</h2>
<p>Usually statisticians are interested in the most likely parameters, that is, the parameter values that maximize the likelihood. One way to find these parameters is to find the derivative of the log likelihood and solve for the parameter values that make this equal to zero. The score function, <span class="math inline">\(U(\theta)\)</span>, is the derivative of the log likelihood. Specifically;</p>
<span class="math display">\[\begin{equation}
U(\theta) = \frac{d}{d\theta}\ell(\theta| x_1,x_2,...,x_n)
\end{equation}\]</span>
<p>Statisticians are also concerned with the uncertainty in parameter estimates. One statistic used to assess this is Fisher Information, <span class="math inline">\(I(\theta)\)</span>, defined as the negative expectation of the second derivative of the log likelihood;</p>
<span class="math display">\[\begin{equation}
I(\theta) = -E\bigg(\frac{d^2}{d^2\theta}\ell (\theta | x_1,x_2,...,x_n)\bigg) = \int_{-\infty}^{\infty} \frac{d^2}{d^2\theta}\ell (\theta | x_1,x_2,...,x_n) f(x|\theta) d\theta
\end{equation}\]</span>
<p>The inverse Fisher Information, <span class="math inline">\(\frac{1}{I(\theta)}\)</span>, is the variance of the sampling distribution for parameter estimates obtained by maximizing the log likelihood. As a second derivative, Fisher Information also represents the peakedness of the likelihood around the maximum likelihoods estimate. A large <span class="math inline">\(I(\theta)\)</span> indicates a steeper peak around the maximum likelihood estimate, which is interpreted as a more informative sample.</p>
</div>
</div>
<div id="information-and-entropy" class="section level1">
<h1>Information and Entropy</h1>
<p>see <a href="https://en.wikipedia.org/wiki/Quantities_of_information" class="uri">https://en.wikipedia.org/wiki/Quantities_of_information</a> see <a href="https://en.wikipedia.org/wiki/Information_theory" class="uri">https://en.wikipedia.org/wiki/Information_theory</a></p>
<div id="surprise-self-information" class="section level2">
<h2>Surprise (Self Information)</h2>
<p>For an event, <span class="math inline">\(e\)</span>, surprise (also called information or self-information) is defined to be the function satisfying these properties;</p>

<p>The function satisfying these properties is:</p>
<span class="math display">\[\begin{equation}\label{InformationDfn}
I(e)=-log(p(e))=log\left(\frac{1}{p(e)} \right)
\end{equation}\]</span>
</div>
<div id="entropy" class="section level2">
<h2>Entropy</h2>
<p>Entropy is the expected information;</p>
<span class="math display">\[\begin{equation}\label{EntropyDfn}
H(E)=E(I(E)) = E(-log(p(E)))  = \int_E p(e)I(e) = -\int_E p(e)log(p(e))
\end{equation}\]</span>
<p>entropy is the expected information</p>
</div>
<div id="joint-entropy" class="section level2">
<h2>Joint Entropy</h2>
</div>
<div id="conditional-entropy" class="section level2">
<h2>Conditional Entropy</h2>
</div>
<div id="relative-entropy-divergence" class="section level2">
<h2>Relative Entropy (Divergence)</h2>
<p>KL divergence</p>
</div>
<div id="mutual-information" class="section level2">
<h2>Mutual Information</h2>
<p>Mutual information quantifies the information obtained about one random variable through the observation of another. can be expressed as average divergance? self information is a special case of mutual information, the mutual information of a variable and itself. Given the definition of Information in Equation , Mutual Information is defined as:</p>
<span class="math display">\[\begin{equation}\label{MutualInformationDfn}
I(E_1;E_2)=\int_{E_2} \int_{E_1} p(e_a,e_2)log\left(\frac{p(e_1,e_2)}{p(e_1)p(e_2)}  \right)
\end{equation}\]</span>
</div>
</div>
