---
title: "Machine Learning"
author: "Mac Strelioff"
date: "`r Sys.time()`"
math: true
output:
  blogdown::html_page:
    toc: true
menu:
  InsightStudying:
    parent: Foundations
    weight: 25
linktitle: Machine Learning
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(entropy)

# set seed for reproducability
set.seed(10201991)
```

# Considerations

## Bias-variance trade-off

## Overfitting and Underfitting

Cross Validation; Classification

Assess by comparing a performance metric on training and testing data.

## Cost Functions and Metrics

Modeling: Validation metrics, 

metrics (precision, recall, F1)

R squared, RMSE

Likelihood

regularisation (ridge, lasso), 

## Feature Engineering

### Seperability

### Assumptions about form of relationship

Process: feature selection, data cleaning / imputation with common pitfalls, model training, bias-variance trade-off

# Unsupervised

## Clustering

### k-means

### Agglomerative

### Devisive

## Matrix Decomposition

### PCA Principle Components Analysis

### SVD Singular Value Decomposition

## Text-based

### LDA Latent Direchilote Analysis

### LSA Latent Semantic Analysis

# Supervised

## Regression

### Linear

### Support Vector Machine (SVM)

## Classification

### Naive Bayes

### Discriminant Analysis

#### LDA

When to use: 

- 

Pros: 

- 

Cons: 

- 

#### QDA

When to use: 

- 

Pros: 

- 

Cons: 

- 

### KNN

When to use: 

- 

Pros: 

- 

Cons: 

- 

### Logistic Regression

When to use: 

- 

Pros: 

- 

Cons: 

- 

# Ensemble Methods

boosting, bagging

XGBoost, NLP (bag of words, vector-space models, sentiment analysis), Rec systems, Collab filtering, Optimization, XGBoost

## Trees and Forests

[Good blog on analysis of feature importance](https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e)

Also see [SHAP](https://github.com/slundberg/shap) for interpreting predictions from tree models!


Benefits of trees over OLS

https://www.quora.com/How-does-a-random-forest-fix-regression-problems-non-normality-heteroscedasticity-multicollinearity-outliers-missing-values-and-categorical-variables

### Regression

### Classification

Deep learning, Rec systems, Content and collaborative filtering, Optimization, Probabalistic programming

#### Assessment

Confusion matrix, F1, precision-recall curve

ROC, AUC

# Open ended Template

## Raw data structure? 

- Table of information about consumer
- Table of transaction history


## Define target variable

e.g. Fraud would be if a consumer calls and labels a transaction as fraud. 

## Preprocession, 

- EDA - distributions, correlations

## Feature engineering

## Performance metrics and how they apply

- Precision
- Recall 
- ... 

## Cautions: 

- Don't mention models you aren't familiar with

## Imagine rolling the model out 

- What issues might arise? 
- What actions do you take in production? 















