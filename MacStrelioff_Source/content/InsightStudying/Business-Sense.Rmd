---
title: "Product Sense"
author: "Mac Strelioff"
date: "`r Sys.time()`"
math: true
menu:
  InsightStudying:
    parent: Foundations
    weight: 99
linktitle: Product Sense
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(entropy)

# set seed for reproducability
set.seed(10201991)
```


# Problem Types and Strategies

## New Product

Overall product sense is about what to build and why. 

1. Overarching goals / stage of the company
2. Contextualize: Draw a user funnel or user flow for the specific product
3. Draw a dashboard, then populate with platform and product metrics

# Overall resources

- [https://www.youtube.com/playlist?list=PLOhHNjZItNnM5r2JCX9KzrFH5WYWKrpAA](https://www.youtube.com/playlist?list=PLOhHNjZItNnM5r2JCX9KzrFH5WYWKrpAA)

# Deep-Dives

[Deep Dive guide](https://sites.google.com/insightdatascience.com/interviewstrategies/interviews/interview-logistics/deep-dives?authuser=0)


# Platform Concepts and Metrics

## Users

### User Funnel

Churn,

funnel analysis

### User Flow

- Traffic source: Where users come from (search, referral, ... )
- number new visits, percent new visits
- Page visits: users arriving at page
- Bounce rate: the percentage of visitors to a particular website who navigate away from the site after viewing only one page.
- Pages viewed / visit
- Time on pages
- Time on site
- Conversion (purchase, reservation, end-goal action)

### Lifetime Value

## KPIs

[Engagement Metrics](https://mixpanel.com/topics/important-user-engagement-metrics-apps/)

Active user metrics are especially important for monetization with ad revenue. 

Daily active users: 
$$
DAU = n_{users,day}
$$

Average daily active users:
$$
\begin{aligned}
ADAU &= \frac{\text{total number of active users in a month}}{\text{days in the average month}}\\
&= \frac{\sum_{days}^{n_{days}} DAU_{day}}{n_{days}}
\end{aligned}
$$

Monthly active users: 
$$
\begin{aligned}
MAU &= \frac{\text{total number of active users in a year}}{12} \\
&= \frac{\sum_{days}^{365} DAU_{day}}{n_{months}}
\end{aligned}
$$

Stickiness: Here the numerator is a measure of activity within a month, and the denominator is a measure of activity within a year. 
$$
\begin{aligned}
S &= \frac{ADAU}{MAU} \\ 
  &= \frac{\frac{1}{n_{days}}\sum_{days}^{n_{days}} DAU_{day}}{\frac{1}{n_{months}}\sum_{days}^{365}DAU_{day}}\\
  &= \frac{n_{months}\sum_{days}^{n_{days}}DAU_{day}}{n_{days}\sum_{days}^{365}DAU_{day}}
\end{aligned}
$$

[alternatively](https://blog.popcornmetrics.com/5-user-engagement-metrics-for-growth/), stickiness could be measured as $DAU$ over $MAU$

- Daily active users: number of users in a day
- Active users: Average Daily Active Users = monthly users / days in average month
- Active users: Monthly Active Users = users in a year / months in year
- Stickiness: Average Daily Active Users / Monthly Active Users = 

- Support ticiets: new tickets + unresolved tickets
- Time to ticket resolution

- [https://www.klipfolio.com/resources/kpi-examples](https://www.klipfolio.com/resources/kpi-examples)

## Monetization 

- customer lifetime value (LTV)
- monthly recurring revenue (MRR)

# Product Concepts and Metrics

## Demand

## Engagement

- clicks
- bounce rate on subsequent page -- used combined with clicks to mitigate click bait
- Shares
- Upvotes
- DAU
- time of sessions

## Value

- Shares
- Upvotes

## Add from meeting with Alejandro

- User data (ways users use the app)
- Usage data (ways the app interacts with devices, networks, servers, product versions, ...)


# OLD NOTES: 

# Insight topics list:
engagement, search engine optimization (SEO), key-performance indicators (KPIs),

Experiment design, A/A and A/B testing, power analysis; 

ML focused business case study (features, algorithms, validation, value), business focused data challenges



# Template

## Value of a new feature

e.g. higher engagement, better labels for training data or other user behaivors

## Deamand for a feature

- Surveys
- Focus Groups
- UX interviews / shadows
- Retrospective analysis (looking at past user behavior)

## Treatment Design

How exactly will this be implemented in the treatment group? 

Specify treatment and control groups.

### Issues

- Networks: Users that interact might be in different conditions
- Learning effects: Users might respond differently initially than they do asymptotically. Can run experiments longer until the treatment effect seems to stabalize. 

## Constructs and Metrics

Engagement:

- Lift
- CTR
- Duration

Monetization: 

- CTR
- revenue per user
- add revenue
- ...

Guard Rail Metrics:

- 

## Metric evaluation and selection

1. What if we optimize for ... ?: The choice of metrics determines what the platform is being optimized for, so think about what will happen if the platform is optimized for the chosen metric.

### Method

### Size 

Power analysis

### Duration

Bandits versus A/B tests, 

### Other considerations: 

- Heterogenous treatment effects


# Example Question Formats


# Mock questions and templates 

## Monitoring Twitter serach

Metrics:

Measure health: 

Working well + being used … 

Track number of users using search! 

Consider people who have used the search once.. (can assess need) 


Use of search

 # users that use search

Usage (prop of users that interact with search)

 # users using search / # active users

Proportion of times a user comes and uses search 

Time interval(s):

Daily

Weekly

 # number of search sessions 

Total search volume (server traffic, … -- important!) 


Quality of search


Chose any suggestion

Rank of suggestion that they chose

Look at total number of searches, and searches in different categories / segmentations

Depends on infrastructure / ease of cutting later


-- favorites, retweets, … Other metrics from a deep-dive.


CUTS IN  DATA


Think of groups that might be using feature differently

New vs old users

Device type (iphone vs android) 

Browser



Conditions where the feature may be behaving differently (languages, countries, …) .. 

Note: countries would have different bandwidths (country easier to measure than bandiwdth itself) 

Language that the search is using. 




SPIKE IN THE METRIC # of searches


Bug


Event



Think of more people on platform moving with searches… 


 # clicks and # searches -- if it’s a bug, then clicks prob wouldn’t also spike.





Impressions, clicks, … 


Top of funnel, 


Logging in, going to search, writing stuff, hitting search .


‘Ok lets write down some ideas and see how we feel about them … ‘


Looking for intuition about how things will move and interact? 


Looking for: 

Organized in thinking

Incl understanding of problem space

Communicating thinking well







[Giulio Palombo's collection of business focused data challenges](https://datamasked.com/)

Company deep dives; data+schema brainstorming; ML algorithms; Insights;

Company blogs are a great resource: check out how StitchFix, Instacart use data science.

More company deep dives!




























