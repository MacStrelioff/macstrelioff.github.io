---
title: "Probability and Statistics"
author: "Mac Strelioff"
date: "2019-08-23 09:55:29"
math: true
output:
  blogdown::html_page:
    toc: true
    toc_depth: 4
menu:
  InsightStudying:
    parent: Foundations
    weight: 20
linktitle: Probability and Statistics
---


<div id="TOC">
<ul>
<li><a href="#theoretical-foundations">Theoretical Foundations</a><ul>
<li><a href="#probability-functions">Probability Functions</a></li>
<li><a href="#probability-rules">Probability Rules</a></li>
<li><a href="#maximum-likelihood-and-bayes-theorem">Maximum Likelihood and Bayes’ Theorem</a></li>
<li><a href="#odds-and-other-transformations">Odds and other transformations</a></li>
<li><a href="#expectation-and-variance">Expectation and Variance</a></li>
<li><a href="#models-as-conditional-expectations">Models as conditional expectations</a></li>
<li><a href="#central-limit-theorem">Central limit theorem</a></li>
<li><a href="#information-theory-and-entropy">Information theory and entropy</a></li>
</ul></li>
<li><a href="#experiment-design">Experiment Design</a><ul>
<li><a href="#foundations">Foundations</a></li>
<li><a href="#concerns">Concerns</a></li>
<li><a href="#treatment-units">Treatment Units</a></li>
<li><a href="#generative-model-and-adjustment-variables">Generative Model and Adjustment Variables</a></li>
<li><a href="#common-designs">Common Designs</a></li>
<li><a href="#assignment-mechanism">Assignment Mechanism</a></li>
<li><a href="#duration">Duration</a></li>
<li><a href="#integrety-checks">Integrety Checks</a></li>
</ul></li>
<li><a href="#common-tests">Common Tests</a><ul>
<li><a href="#t-test">t-test</a></li>
<li><a href="#anova">ANOVA</a></li>
<li><a href="#linear-model">Linear Model</a></li>
<li><a href="#z-test-for-proportions">Z test for proportions</a></li>
<li><a href="#chi-square">Chi-Square</a></li>
<li><a href="#logistic-regression">Logistic Regression</a></li>
<li><a href="#likelihood-ratio-and-bayes-factors">Likelihood Ratio and Bayes Factors</a></li>
<li><a href="#always-valid-p-values-ck-optimizely-white-paper">always valid p-values (ck optimizely white paper)</a></li>
</ul></li>
<li><a href="#different-estimands-for-ci">Different Estimands For CI</a></li>
<li><a href="#more-on-variance">more on variance</a><ul>
<li><a href="#emperical-variance-estimation">Emperical Variance Estimation</a></li>
<li><a href="#mixed-effects-models">Mixed Effects Models</a></li>
<li><a href="#effiencicy-or-variance-reduction">Effiencicy or Variance Reduction</a></li>
<li><a href="#glms">GLMs</a></li>
</ul></li>
<li><a href="#causal-inference-methods">Causal Inference Methods</a><ul>
<li><a href="#difference-in-differences">Difference in Differences</a></li>
<li><a href="#causal-impact">Causal Impact</a></li>
<li><a href="#synthetic-controls">Synthetic Controls</a></li>
<li><a href="#propensity-score-matching">Propensity Score Matching</a></li>
<li><a href="#fixed-effects-regression">Fixed Effects Regression</a></li>
<li><a href="#instrumental-variables">Instrumental variables</a></li>
<li><a href="#regression-discontinuity">Regression Discontinuity</a></li>
</ul></li>
</ul>
</div>

<!--
Fermi problems (order of magnitude)
-->
<div id="theoretical-foundations" class="section level1">
<h1>Theoretical Foundations</h1>
<p>combinatorics (permutations and combinations)</p>
<div id="probability-functions" class="section level2">
<h2>Probability Functions</h2>
<p>pdf, cdf</p>
</div>
<div id="probability-rules" class="section level2">
<h2>Probability Rules</h2>
<p>basic probability rules</p>
<ul>
<li>law of total probability</li>
</ul>
<p>Practice problems on the amoeba <a href="https://www.quora.com/Bobo-the-amoeba-has-a-25-25-and-50-chance-of-producing-0-1-or-2-offspring-respectively-Each-of-Bobos-descendants-also-have-the-same-probabilities-What-is-the-probability-that-Bobos-lineage-dies-out">here</a> and <a href="https://www.quora.com/An-amoeba-has-a-75-chance-of-splitting-in-two-and-25-chance-of-dying-Is-there-an-intuitive-reason-why-the-probability-of-extinction-is-not-1">here</a>.</p>
</div>
<div id="maximum-likelihood-and-bayes-theorem" class="section level2">
<h2>Maximum Likelihood and Bayes’ Theorem</h2>
<p>likelihood is one term in Bayes’ Theorem</p>
</div>
<div id="odds-and-other-transformations" class="section level2">
<h2>Odds and other transformations</h2>
<p>odds, log odds, relative risk, … .</p>
</div>
<div id="expectation-and-variance" class="section level2">
<h2>Expectation and Variance</h2>
<p>expectation, variance, conditional or iterated expectations, law of total variance, variance of multiple variables</p>
</div>
<div id="models-as-conditional-expectations" class="section level2">
<h2>Models as conditional expectations</h2>
<p>Models output an expectation that depends on the model, its structure, its features, and in Bayesian settings it’s priors</p>
</div>
<div id="central-limit-theorem" class="section level2">
<h2>Central limit theorem</h2>
<p>Sum of any random variable converges to normal distribution.</p>
<ul>
<li>show for binomial case, to justify Z test</li>
</ul>
</div>
<div id="information-theory-and-entropy" class="section level2">
<h2>Information theory and entropy</h2>
<ul>
<li>entropy is minimized by a Bayesian estimator</li>
</ul>
</div>
</div>
<div id="experiment-design" class="section level1">
<h1>Experiment Design</h1>
<div id="foundations" class="section level2">
<h2>Foundations</h2>
<ul>
<li>Hypotheses</li>
<li>Treatment and control conditions</li>
<li>assumptions (including CI assumptions, SUTVA, …?)</li>
</ul>
</div>
<div id="concerns" class="section level2">
<h2>Concerns</h2>
<ul>
<li>network effects: front-end, it could be from different interactions, back-end it could be from changes in algorithm behavior for units in C based on different behavior from units in T – e.g. if a new recommender for units in T influences them to watch more of x, then x may also get recommended more to those in C.</li>
<li>learning effects (change aversion, novelty seeking)</li>
<li>early adopters</li>
<li>Non-compliance: Those assicned to treatment may not actually experience the treatment.</li>
<li>Crossover: Those assigned to control might gain access to the treatment.</li>
<li>Treatment inhomogenaity: Some user segments might respond differently than others.</li>
</ul>
</div>
<div id="treatment-units" class="section level2">
<h2>Treatment Units</h2>
<p>What is the unit at which we assign treatments?</p>
<p>Ideally independent individuals, but online it is hard to know who is visiting a webpage, or crucial to keep experiences comparable across devices. Also, in networks, individuals are not independent and it is important to keep user experience consistent across connected individuals.</p>
<p>Proxies for individuals include;</p>
<ul>
<li>User ID or account – most clearly tied to a user, but</li>
<li>cookies – device and browser specific, so these could differ across a user’s browsers or devices.</li>
<li>IP address (device request return address) – device specific, so a user’s experience might differ across devices.</li>
</ul>
<p>In networks, loosely connected clusters of individuals can be used as experimental units (see unofficial google data science blog post on this).</p>
<ul>
<li><p>a solution to SUTVA violations, but decreases sample size and power dramatically</p></li>
<li><p>cluster-based, stratified, serial, balanced, …</p></li>
<li><p>propensity scores and matching</p></li>
</ul>
</div>
<div id="generative-model-and-adjustment-variables" class="section level2">
<h2>Generative Model and Adjustment Variables</h2>
<ul>
<li>Specify the hypothesized generative process</li>
<li>Confounds</li>
<li>Precision</li>
<li>Neusance</li>
</ul>
</div>
<div id="common-designs" class="section level2">
<h2>Common Designs</h2>
<p>A/B testing</p>
<p>A/A testing to estimate variation</p>
<p>Variance reduction designs (paired designs, matching, …)</p>
<p>Bandits for limited data or maximizing an objective</p>
</div>
<div id="assignment-mechanism" class="section level2">
<h2>Assignment Mechanism</h2>
<ul>
<li>maps samples (xi,yi) into treatment or control conditions.</li>
<li>randomized control trials ideal, not always possible</li>
<li><p>other options, …?</p></li>
<li><p>test assignment validity, could use propensity scores or maybe chi square.</p></li>
</ul>
</div>
<div id="duration" class="section level2">
<h2>Duration</h2>
<ul>
<li>learning effects: initial exploration or novelty seeking</li>
<li><p>learning effects: initial change aversion</p></li>
<li>power analysis for sample size</li>
<li><p>time to run to mitigate</p></li>
</ul>
<!---
# Experiment Design

## Objective, demand, and value

Objective is based on a metric (increase clickthrough or revenue per user). 

Demand -- if adding a new user feature, how can demand for the feature be assessed? 

value = benefit - cost. 

Expected value helps with decisions about the size and duration of an experiment

## Constructs, metrics, and scoping

Once an objective is clear, the details of what can be measured need to be flushed out. 

Metrics (fill in from udamy course section on metrics)

Netflix metrics -- streaming hours, retention (users staying on platform), viewing for a title (e.g. effected by artwork -- but may be at the detrement of general viewing?) 

### User flow and target metrics

Think of the sequence of actions a user might take on the site. Experiments can target transtition probabilities between any user/platform states. 

- number of clicks
- time on page
- ... 

### Invariants

Metrics that shouldn't change or differ across groups. For example, demographic variables should be the same across groups if the randomization or balancing worked properly. Also, many application performance metrics and business metrics should be unchanged, or monitored just in case they change. 

### Confounding variables

Mitigated by randomization. 

### Precision variables

Can also highlight features that one would want to match treatment and control on.

Examples: 

- number of posts
- number of followers
- visibility / impressions

## Metric Validation

User expreience research, retrospective analyses of past data or log files, ... . 

## Conditions

Define the experimental manipulations. 

## Treatment Units

What is the unit at which we assign treatments? 

Ideally independent individuals, but online it is hard to know who is visiting a webpage, or crucial to keep experiences comparable across devices. Also, in networks, individuals are not independent and it is important to keep user experience consistent across connected individuals. 

Proxies for individuals include;

- User ID or account -- most clearly tied to a user, but 
- cookies -- device and browser specific, so these could differ across a user's browsers or devices.
- IP address (device request return address) -- device specific, so a user's experience might differ across devices.

In networks, loosely connected clusters of individuals can be used as experimental units (see unofficial google data science blog post on this).

## Assignment Mechanism 

The assignment mechanism samples members from a population and assignes them to conditions. 

How are units assigned to treatments?

Randomized control trials are the ideal, but many issues arise in online experimentation settings. 

(look up desirable properties form causal inference notes)

### Population 

What group is being sampled from?

### Cohorts

Random sample, cluster-based, stratified, serial, balanced, ... 

### Synthetic Control Groups

Propensity matching

### Limitations

- Non-compliance: Those assicned to treatment may not actually experience the treatment. 
- Crossover: Those assigned to control might gain access to the treatment. 
- Treatment inhomogenaity: Some user segments might respond differently than others.

# Implementation

Batched, or real-time

## Size

power, sample size

## Duration

- learning effects: initial exploration or novelty seeking
- learning effects: initial change aversion

Solution: Consider running experiment past any initial observed effect.

### Temporal variation

### Optional stopping

Why it's an issue for frequentists

Optamizely using a threshold on FDR from likelihood ratio tests in frequentist setting

Bayesian justifications

p-values versus likelihood ratios

## Estimands

- Average treatment effect
- Treatment on treated

## Effiencicy or Variance Reduction

- look up variance reduction in A/B tests, a common method might be to incorporate precision variables like demographic data or user data such as device or browser. 

e.g. with a two sample t-test, $Y_t - Y_{t-1} = \beta_0$, versus a model $Y_t = \beta_0 + \beta_1 Y_{t-1}$

- get table for different tests of means from soc sci 10 notes.

## Checking assignment integrety

- Check demographics across buckets, if randomization worked then demographics should be approximately equally represented in the buckets. 

--->
</div>
<div id="integrety-checks" class="section level2">
<h2>Integrety Checks</h2>
<ul>
<li>check that those assigned to treatment received it</li>
<li><p>check that stratifications were implemented correctly</p></li>
<li><p>Check demographics across buckets, if randomization worked then demographics should be approximately equally represented in the buckets.</p></li>
</ul>
</div>
</div>
<div id="common-tests" class="section level1">
<h1>Common Tests</h1>
<div id="t-test" class="section level2">
<h2>t-test</h2>
<ul>
<li>different variance formulations.</li>
<li>one-sample</li>
<li>two independent sampels</li>
<li>two dependent samples</li>
</ul>
</div>
<div id="anova" class="section level2">
<h2>ANOVA</h2>
</div>
<div id="linear-model" class="section level2">
<h2>Linear Model</h2>
</div>
<div id="z-test-for-proportions" class="section level2">
<h2>Z test for proportions</h2>
<p>Binary data</p>
</div>
<div id="chi-square" class="section level2">
<h2>Chi-Square</h2>
</div>
<div id="logistic-regression" class="section level2">
<h2>Logistic Regression</h2>
</div>
<div id="likelihood-ratio-and-bayes-factors" class="section level2">
<h2>Likelihood Ratio and Bayes Factors</h2>
</div>
<div id="always-valid-p-values-ck-optimizely-white-paper" class="section level2">
<h2>always valid p-values (ck optimizely white paper)</h2>
</div>
</div>
<div id="different-estimands-for-ci" class="section level1">
<h1>Different Estimands For CI</h1>
<ul>
<li>Average treatment effect</li>
<li>Treatment on treated</li>
</ul>
</div>
<div id="more-on-variance" class="section level1">
<h1>more on variance</h1>
<div id="emperical-variance-estimation" class="section level2">
<h2>Emperical Variance Estimation</h2>
<p>bootstrapping</p>
<p>A/A testing</p>
</div>
<div id="mixed-effects-models" class="section level2">
<h2>Mixed Effects Models</h2>
<ul>
<li>Maime’s consulting project? Other use cases?</li>
</ul>
</div>
<div id="effiencicy-or-variance-reduction" class="section level2">
<h2>Effiencicy or Variance Reduction</h2>
<ul>
<li>look up variance reduction in A/B tests, a common method might be to incorporate precision variables like demographic data or user data such as device or browser.</li>
</ul>
<p>e.g. with a two sample t-test, <span class="math inline">\(Y_t - Y_{t-1} = \beta_0\)</span>, versus a model <span class="math inline">\(Y_t = \beta_0 + \beta_1 Y_{t-1}\)</span></p>
<ul>
<li>get table for different tests of means from soc sci 10 notes.</li>
</ul>
</div>
<div id="glms" class="section level2">
<h2>GLMs</h2>
<!--
models for when the errors aren't assumed to be normally distributed
--->
<p>Stats: descriptive, R-squared, chi-squared;</p>
<p>Probability: distributions, CLT, sampling distributions, p-value,</p>
<p>Stats: k-s, Q-Q plot, hypothesis testing, experimentation;</p>
<p>Probability: Bayes, bootstrap</p>
<p>Probability: maximum likelihood estimation; time series analysis (ARIMA models), granger causality</p>
<p>Dynamic experimentation (multi-armed bandits)</p>
<p>Unit testing; EDA visualization (seaborn, Plotly, Bokeh)</p>
</div>
</div>
<div id="causal-inference-methods" class="section level1">
<h1>Causal Inference Methods</h1>
<p>Good medium blog post <a href="https://towardsdatascience.com/causal-inference-using-difference-in-differences-causal-impact-and-synthetic-control-f8639c408268">here</a></p>
<p>For each mention the assumptions and the model.</p>
<div id="difference-in-differences" class="section level2">
<h2>Difference in Differences</h2>
</div>
<div id="causal-impact" class="section level2">
<h2>Causal Impact</h2>
</div>
<div id="synthetic-controls" class="section level2">
<h2>Synthetic Controls</h2>
</div>
<div id="propensity-score-matching" class="section level2">
<h2>Propensity Score Matching</h2>
</div>
<div id="fixed-effects-regression" class="section level2">
<h2>Fixed Effects Regression</h2>
</div>
<div id="instrumental-variables" class="section level2">
<h2>Instrumental variables</h2>
</div>
<div id="regression-discontinuity" class="section level2">
<h2>Regression Discontinuity</h2>
</div>
</div>
