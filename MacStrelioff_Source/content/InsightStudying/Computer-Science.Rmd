---
title: "Computer Science"
author: "Mac Strelioff"
date: "`r Sys.time()`"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 4
menu:
  InsightStudying:
    parent: Foundations
    weight: 15
linktitle: Computer Science
math: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(reticulate)

# setup python usage
# NOTE: python vars persist across chunks when knitting, but not in RStudio. 
knitr::opts_chunk$set(comment = ">>>")
#py_discover_config() # to see versions of Python
use_python("/anaconda3/bin/python")

# set seed for reproducability
set.seed(10201991)
```

# Foundations

Data type manipulation (char, string, numeric, binary, ascii) regular expressions; 

## Complexity

The worst-case complexity of an algorithm is represented with big-O notation. Big-O notation is adapted from mathematics where $O(f(n))$ is used to represent the terms that remain relevant when taking a limit of the computations required by the algorithm, $f(n)$, as $n$ approaches $\infty$. The same notation is used for time complexity (number of operations) and for space complexity (memory requirements). 

### Computational Complexity 

Here I'll check the number of computations required by algorithms of different complexities.
```{python}
ns_to_test = [0,1,10,20]
```

#### Constant Time: O(1)

$O(1)$ represents comstant time complexity -- a component of an algorithm that is only performed once, regardless of the input size.

```{python}
def constant_example(n):
    num_ops = 1      # 1 operation
    num_ops +=1      # 1 operation
    return num_ops   # total: 2 operations


for n in ns_to_test:
    out=constant_example(n)
    print('f({}): {}'.format(n,out))
```

#### Logrithmic Time: O(log(n))

Very slowly increases in computational demand. It can result from splitting the input on each recusrive call.

```{python}
def log_example(n,num_ops=0):
    # 1 operation per call
    # if n>1, half n and recursively call again
    if n>=1:
        n/=2; num_ops += 1
        num_ops += log_example(n)
    return num_ops
        
for n in ns_to_test:
    out=log_example(n)
    print('f({}): {}'.format(n,out))
```

#### Polynomial Time: O(n), O(n^2), ...

[good hackerrank video with explanation of polynomial complexity for a recursive solution to fibbinochi](https://www.youtube.com/watch?v=P8Xa2BitN3I&list=PLI1t_8YX-ApvMthLj56t1Rf-Buio5Y8KL&index=11)

Each for loop scales complexity by a factor of $n$, so one loop would be linear ($O(n)$), two loops would be quadratic $O(n^2)$, and three loops would be cubic ($O(n^3)$), and so on. The example below is a quadratic time example. 

```{python}
def linear_example(n): 
    num_ops = 0         # initialize counter
    for i in range(n):  # n times, perform...
        num_ops +=1     # 1 operation (n*1)
    return num_ops      # 1+n*1 = 1+n operations, O(n)


for n in ns_to_test:
    out=linear_example(n)
    print('f({}): {}'.format(n,out))

def quadratic_example(n):
    num_ops = 0             # initialize counter
    for i in range(n):      # n times
        for j in range(n):  # n times (n*n)
            num_ops+=1      # 1 operation (1*n*n)
    return num_ops          # total 1 + 1*n + 1*n*n, O(n^2)


for n in ns_to_test:
    out=quadratic_example(n)
    print('f({}): {}'.format(n,out))
```

#### Exponential Time: $O(x^n)$

With exponential time, the number of operations increases by a constant *factor* whith the length of the input. An example of this is in recursion, where a function iteratively calls itself $n$ times for each element of the input.

In the example below, I call the function twice within each call. The complexity is then a geometric series, and the closed for solution for the number of operations can be found with;

$$ \sum_{i=1}^N ar^{i-1} = \frac{a(1-r^{N})}{1-r} $$

Where $r=2$, $a=2$, $n$ is looped over, and we start the index at 0 ($i-1$) instead of 1, so: 

$$ \sum_{i=0}^n 2*2^{i} = \frac{(1-2^{n+1})}{1-2} = \frac{(1-2^{n+1})}{-1}=-(1-2^{n+1}) = 2^{n+1}-1 $$

```{python}
def exponential_example(n,num_ops=0):
    num_ops += 1 # 1 operation per call
    # recursively called twice for each n>0 (2**n times)    
    if n > 0:
        n-=1
        num_ops += exponential_example(n) # 2**(n)
        num_ops += exponential_example(n) # 2**(n)
    return num_ops # 
    
for n in ns_to_test:
    out=exponential_example(n)
    print('f({}): {}'.format(n,out))
```

#### Logrithmic Time: O(log(N))

## Data Structures

basic structures (tuples, list, arrays, dict), list comprehensions, 

Good descriptions of [lists](https://runestone.academy/runestone/books/published/pythonds/AlgorithmAnalysis/Lists.html), [dicts](https://runestone.academy/runestone/books/published/pythonds/AlgorithmAnalysis/Dictionaries.html), and [why some operations are much faster in sets or dict keys](https://stackoverflow.com/questions/8929284/what-makes-sets-faster-than-lists).

In depth description of [hash tables](https://en.wikipedia.org/wiki/Hash_table?fbclid=IwAR1N5-jAoM9e6iY58CDP9MAwycenvOXXJwmkpa0eBVDKed3RBs9uVBm9Kkc). 

Data structures (hash, stack, queue, tree, linked list); 

# Sorting

sorting (bubble, selection, insertion, merge, quick)

Sorting and graph algos (depth-first and breadth-first seach)

sorting (heap, tim)

Lots of [sort algorithms](https://www.geeksforgeeks.org/sorting-algorithms/)

e.g. 'find median in a large dataset' -- sort half of it.

# Searching

Lots of [search algorithms](https://en.wikipedia.org/wiki/Category:Search_algorithms)

## Linear Search: Binary Search

[good hackerrank video](https://www.youtube.com/watch?v=P3YID7liBug)

- requires sorting before applying the search

## Graph Search: DFS and BFS

[good hackerrank video](https://www.youtube.com/watch?v=zaBhtODEL0w)

- DFS can use a dictionary or set to 

# Ranking Algorithms

Lots of [ranking algorithms](https://en.wikipedia.org/wiki/Ranking_(information_retrieval))

# Recommendation

Lots of [recommendation algorithms](https://en.wikipedia.org/wiki/Recommender_system)


<!---
Data science methods play a major role in discovering recommendations for users. 

Econ, compliments and substitutes (competitors). 

Types of recommendation; compliments (these go together), competitors (you might also like...), temporal (might buy this again in the future). Horizontal and vertical focus 

Temporal involves forecasting, which is a topic for another post. 
--->

# Algorithms

lambda functions;

```{python}

nums=[1,1,2,2,1]
val=1

count = 0
for i in range(len(nums)):
  if nums[i] != val:
    nums[count] = nums[i]
    count += 1

print(count)
print(nums)
```


# TODO / Other Topics:  

## recursion; 

## Dijkstra's algorithm, 

## dynamic programming (knapsack problem, Fibonacci sequence)

## Functional programming

# Tools

## Git and GitHub

git for version control (resolving merge conflicts)

## SQL 

### General Structure of SQL querys

[Order of execution for clauses below](https://sqlbolt.com/lesson/select_queries_order_of_execution)

```{, eval=FALSE, echo=TRUE}
SELECT (column names to select) [AS (name for selection)]

FROM (table to select from)

WHERE (logical condition on rows)
  column = (value or subquery),
  OR column IN (list or subquery)
  
GROUP BY 

HAVING (constraint on grouped rows)
  
LIMIT n [OFFSET m]

```

The `SELECT` clause can contain aggregations, and subqueries. 

The `FROM` clause can contain joins.

The `WHERE` clause can also contain sub queries.

### Aggregation functions

The `GROUP BY` clause can contain `GROUPING SETS`, such as a `ROLLUP()` and `CUBE()` functions. These hierarchically group the rows passed to the aggregation functions. `ROLLUP()` hierarchically groups by arguments, starting left to right. `CUBE()` passes all permutations of its arguments to the aggregation functions. 

[Grouping sets are described a little here](https://pgexercises.com/questions/aggregates/fachoursbymonth3.html).

### Window functions

[Orver() explained here](https://pgexercises.com/questions/aggregates/countmembers.html). Some more detailed information [here](http://www.sqlservertutorial.net/sql-server-window-functions/).

Window functions include `OVER()` and `ROW_NUMBER()`. They take two optional arguments, `PARTITION BY` and `ORDER BY`. 

# Resources

- SQL training resources;
- [pgexercises](https://pgexercises.com/)
- [Udacity course](https://classroom.udacity.com/courses/ud198)
- [sqlbolt](https://sqlbolt.com/lesson/select_queries_introduction)
- [Mode Analytics](https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/) HackerRank (basic select, aggregation)
- [Hacker Rank](https://www.hackerrank.com/domains/sql)
- [W3School](https://www.w3schools.com/sql/exercise.asp?filename=exercise_select1)

- Python and other coding languages:
- [HackerRank](https://www.hackerrank.com/dashboard)
- [LeetCode](https://leetcode.com/)













