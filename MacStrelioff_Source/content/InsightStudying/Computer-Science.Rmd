---
title: "Basic Computer Science"
author: "Mac Strelioff"
date: "`r Sys.time()`"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 4
menu:
  InsightStudying:
    parent: Foundations
    weight: 15
linktitle: Computer Science
math: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(reticulate)

# setup python usage
# NOTE: python vars persist across chunks when knitting, but not in RStudio. 
knitr::opts_chunk$set(comment = ">>>")
#py_discover_config() # to see versions of Python
use_python("/anaconda3/bin/python")

# set seed for reproducability
set.seed(10201991)
```

<!--
basic structures (tuples, list, arrays, dict), list comprehensions, 
Data structures (hash, stack, queue, tree, linked list);
sorting (bubble, selection, insertion, merge, quick)
Sorting and graph algos (depth-first and breadth-first seach)
sorting (heap, tim)
-->

# Foundations

Data type manipulation (char, string, numeric, binary, ascii) regular expressions; 

## Complexity

The worst-case complexity of an algorithm is represented with big-O notation. Big-O notation is adapted from mathematics where $O(f(n))$ is used to represent the terms that remain relevant when taking a limit of the computations required by the algorithm, $f(n)$, as $n$ approaches $\infty$. The same notation is used for time complexity (number of operations) and for space complexity (memory requirements). 

### Computational Complexity 

Here I'll check the number of computations required by algorithms of different complexities.
```{python}
ns_to_test = [0,1,10,20]
```

#### Constant Time: O(1)

$O(1)$ represents comstant time complexity -- a component of an algorithm that is only performed once, regardless of the input size.

```{python}
def constant_example(n):
    num_ops = 1      # 1 operation
    num_ops +=1      # 1 operation
    return num_ops   # total: 2 operations


for n in ns_to_test:
    out=constant_example(n)
    print('f({}): {}'.format(n,out))
```

#### Logrithmic Time: O(log(n))

Very slowly increases in computational demand. It can result from splitting the input on each recusrive call.

```{python}
def log_example(n,num_ops=0):
    # 1 operation per call
    # if n>1, half n and recursively call again
    if n>=1:
        n/=2; num_ops += 1
        num_ops += log_example(n)
    return num_ops
        
for n in ns_to_test:
    out=log_example(n)
    print('f({}): {}'.format(n,out))
```

#### Polynomial Time: O(n), O(n^2), ...

[good hackerrank video with explanation of polynomial complexity for a recursive solution to fibbinochi](https://www.youtube.com/watch?v=P8Xa2BitN3I&list=PLI1t_8YX-ApvMthLj56t1Rf-Buio5Y8KL&index=11)

Each for loop scales complexity by a factor of $n$, so one loop would be linear ($O(n)$), two loops would be quadratic $O(n^2)$, and three loops would be cubic ($O(n^3)$), and so on. The example below is a quadratic time example. 

```{python}
def linear_example(n): 
    num_ops = 0         # initialize counter
    for i in range(n):  # n times, perform...
        num_ops +=1     # 1 operation (n*1)
    return num_ops      # 1+n*1 = 1+n operations, O(n)

for n in ns_to_test:
    out=linear_example(n)
    print('f({}): {}'.format(n,out))

def quadratic_example(n):
    num_ops = 0             # initialize counter
    for i in range(n):      # n times
        for j in range(n):  # n times (n*n)
            num_ops+=1      # 1 operation (1*n*n)
    return num_ops          # total 1 + 1*n + 1*n*n, O(n^2)

for n in ns_to_test:
    out=quadratic_example(n)
    print('f({}): {}'.format(n,out))
```

#### Exponential Time: $O(x^n)$

With exponential time, the number of operations increases by a constant *factor* whith the length of the input. An example of this is in recursion, where a function iteratively calls itself $n$ times for each element of the input.

In the example below, I call the function twice within each call. The complexity is then a geometric series, and the closed for solution for the number of operations can be found with;

$$ \sum_{i=1}^N ar^{i-1} = \frac{a(1-r^{N})}{1-r} $$

Where $r=2$, $a=2$, $n$ is looped over, and we start the index at 0 ($i-1$) instead of 1, so: 

$$ \sum_{i=0}^n 2*2^{i} = \frac{(1-2^{n+1})}{1-2} = \frac{(1-2^{n+1})}{-1}=-(1-2^{n+1}) = 2^{n+1}-1 $$

Recursive calls generally have time complexity of $O(branches^{depth})$.

```{python}
def exponential_example(n,num_ops=0):
    num_ops += 1 # 1 operation per call
    # recursively called twice for each n>0 (2**n times)    
    if n > 0:
        n-=1
        num_ops += exponential_example(n) # 2**(n)
        num_ops += exponential_example(n) # 2**(n)
    return num_ops # 
    
for n in ns_to_test:
    out=exponential_example(n)
    print('f({}): {}'.format(n,out))
```

## Data Structures

### Lists and Dictionaries

Good descriptions of [lists](https://runestone.academy/runestone/books/published/pythonds/AlgorithmAnalysis/Lists.html), [dicts](https://runestone.academy/runestone/books/published/pythonds/AlgorithmAnalysis/Dictionaries.html), and [why some operations are much faster in sets or dict keys](https://stackoverflow.com/questions/8929284/what-makes-sets-faster-than-lists).

In depth description of [hash tables](https://en.wikipedia.org/wiki/Hash_table?fbclid=IwAR1N5-jAoM9e6iY58CDP9MAwycenvOXXJwmkpa0eBVDKed3RBs9uVBm9Kkc). 

### Queues and Stacks

Queues and stacks are like lists that are used to prioritize operations. 

- Queues are First-in-last-out structures -- meaning that the highest priority is given to the least recently queued thing. Imagine people in a queue for a theme park, those who entered the queue first are prioritized for admission to the park.
- Stacks are Last-in-First-out structures -- meaning that the highest priority is given to the most recently stacked element. Imagine a stack of books, the ones at the top of the stack are read first. 

### Graphs and Trees

[short definition with pictures](https://www.jenniferbland.com/the-difference-between-a-tree-and-a-graph-data-structure/)

## Sorting

Lots of [sort algorithms](https://www.geeksforgeeks.org/sorting-algorithms/)

Python's sotred() function uses [TimSort](https://en.wikipedia.org/wiki/Timsort). 

Complexity for common sorts: 

- $O(Nlog(N))$ for quicksort, and merge sort. 

In efficient sorting algorithms, the $N$ part comes from the algorithm being called on up to each element, and the $logN$ part comes from binary sorting in ways that render parts of the array unnecessary later. 

e.g. 'find median in a large dataset' -- sort half of it.

# Searching

Lots of [search algorithms](https://en.wikipedia.org/wiki/Category:Search_algorithms)

## Linear Search: Binary Search

Complexity $O(logN)$. 

[good hackerrank video](https://www.youtube.com/watch?v=P3YID7liBug)

- requires sorting before applying the search

## Graph Search

Graphs are a collection of nodes and edges (connections between nodes). In the code below, I use dictionaries to represent graphs -- keys represent nodes, and the list of elements represents all of the nodes that the parent node is connected to. 

```{python}
# examples
Examples = []

# Example 1: something where DFS would do equally well?
tmp_graph = {1: [2,4], 2: [3], 3: [5], 4: [5,7], 5: [6,7], 6: [], 7: []}
Examples.append(tmp_graph)

# Example 2: something where DFS will run faster
tmp_graph = {1:[2,3,4,5],2:[6,10,8,9],3:[],4:[],5:[],6:[7],7:[],8:[],9:[],10:[]}
Examples.append(tmp_graph)

# Example 3: something where BFS will run faster (swapped 3 and 10)
tmp_graph = {1:[2,7,4,5],2:[6,10,8,9],3:[],4:[],5:[],6:[3],7:[],8:[],9:[],10:[]}
Examples.append(tmp_graph)
```


### Breadth First (BFS) and queues

Breadth Frist Search (BFS) queues (FILO structures) nodes based on their distance from an origin node. This can be implemented with a list (queue) by searching the nodes at the head of the list and appending encountered nodes to the tail of the list. 

```{python}
# breadth first search: just a queue
def BFS_queue(graph,start,end):
    queue = [start] 
    visited = set()
    # build and search through queue
    while queue:
        visiting = queue[0]
        # if this was visited already, continue
        if visiting in visited: continue
        # mark node as visited
        visited.add(visiting)
        # if this is the end, return 
        if visiting == end: return True,visited
        # otherwise, append children to search queue
        for child in graph[visiting]: queue.append(child)
        queue.remove(visiting) # remove the visited node
    # if end was never found, return False
    return False,visited

# breadth first search: For loop over each layer
def BFS(graph,start,end):
    queue = [start] 
    visited = set()
    # build and search through queue
    while queue:
        for visiting in queue:
            # if this was visited already, continue
            if visiting in visited: continue
            # mark node as visited
            visited.add(visiting)
            # if this is the end, return 
            if visiting == end: return True,visited
            # otherwise, append children to search queue
            for child in graph[visiting]:
                queue.append(child)
    # if end was never found, return False
    return False,visited
```

### Depth First (DFS) 

Depth First search can be implemented with recursively (below) or with a stack (LIFO structures). 
[good hackerrank video](https://www.youtube.com/watch?v=zaBhtODEL0w)

- Example using DFS to find if a path to a node exists.

```{python}
# Depth first search with recursion
def DFS(graph,start,end):
    visited = set()
    return _DFS(graph,start,end,visited),visited
    
def _DFS(graph,start,end,visited):
    # if this was visited already, return False
    if start in visited: return False
    # mark node as visited
    visited.add(start)
    # if this is the target node, return True
    if start == end: return True
    # DFS through the children of this node
    for child in graph[start]:
        if _DFS(graph,child,end,visited):
            return True
    return False
```

### DFS vs BFS

```{python}

for example in Examples:
    print('DFS  path: ', DFS(example,1,7))
    print('BFSq path: ', BFS(example,1,7))
    print('BFS  path: ', BFS(example,1,7),'\n')
```


### Examples: 

- L332: Reconstruct a path from a starting node that hits all nodes once

```{python}

tickets = [["JFK","KUL"],["JFK","NRT"],["NRT","JFK"]]

# convert to graph implemented in dict:
import collections
tree = collections.defaultdict(list)
for parent,child in tickets:
    tree[parent].append(child)

# start at JFK
path = ["JFK"]

# define DFS algo
def dfs(parent = 'JFK'):
    # success condition -- all tickets have been accounted for
    if len(path) == len(tickets) + 1: 
        print("Final Path: {}".format(path))
        return path
    # get destinations (children) from current node
    children = sorted(tree[parent])
    # iterate over children of this node
    for child in children:
        # include child in path
        tree[parent].remove(child)
        path.append(child)
        # call DFS again starting at the child node
        print("Checking: {} -> {}".format(parent,child))
        sub_route = dfs(child)
        if sub_route: 
            return sub_route
        else: print("No successful sub-route")
        # implicitely return None if sub_route empty
        # if no successful sub-route, remove child from path, 
        path.pop()
        #  and add child back to parent to be searched later
        tree[parent].append(child)

# run the dfs algo
dfs()
```

<!--
# Ranking Algorithms

Lots of [ranking algorithms](https://en.wikipedia.org/wiki/Ranking_(information_retrieval))

# Recommendation

Lots of [recommendation algorithms](https://en.wikipedia.org/wiki/Recommender_system)
-->

<!---
Data science methods play a major role in discovering recommendations for users. 

Econ, compliments and substitutes (competitors). 

Types of recommendation; compliments (these go together), competitors (you might also like...), temporal (might buy this again in the future). Horizontal and vertical focus 

Temporal involves forecasting, which is a topic for another post. 
--->

## Pointers

e.g. Find longest substring that is a pallendrome

Optimal way: Start at each letter, move out each 

e.g. reverse a linked list

e.g. max price from a single buy and sell?

e.g. swapping values in an array? 

# Algorithms

lambda functions;

```{python}

nums=[1,1,2,2,1]
val=1

count = 0
for i in range(len(nums)):
  if nums[i] != val:
    nums[count] = nums[i]
    count += 1

print(count)
print(nums)
```


# TODO / Other Topics:  

# Recursion; 

- Recursive calls 
- Methods applied within each recursion

## Dijkstra's algorithm

## dynamic programming (knapsack problem, Fibonacci sequence)

## Functional programming

# Tools

## Git and GitHub

git for version control (resolving merge conflicts)

## SQL 

### General Structure of SQL querys

[Order of execution for clauses below](https://sqlbolt.com/lesson/select_queries_order_of_execution)

```{, eval=FALSE, echo=TRUE}
SELECT (column names to select) [AS (name for selection)]
 
FROM (table to select from) 
[INNER,LEFT,RIGHT,OUTTER] JOIN table2 
ON [join keys and conditionals]

WHERE (logical condition on rows)
  column = (value or subquery),
  OR column IN (list or subquery)
  
GROUP BY (column[,column,...])

HAVING [AGGREGATION(column) condition]
  
LIMIT n [OFFSET m]
```

- `SELECT` clause can contain columns, aggregations, window functions, and subqueries. 
- `FROM` clause can contain a single table, or joins between tables
- `JOIN`s are useful for appending tables as columns, versus 
- `ON` filters the table that is returned from the JOIN -- it acts similarly to the WHERE clause.
- `WHERE` clause filters the table retreived by FROM can also contain sub queries, and can perform the same filtering as `ON`
- `GROUP BY` groups by a single column or a set of values if given multiple columns
- `HAVING` can be used to filter groups based on an aggregation function
- `UNION` appends tables as rows

### Aggregation functions

The `GROUP BY` clause can contain `GROUPING SETS`, such as a `ROLLUP()` and `CUBE()` functions. These hierarchically group the rows passed to the aggregation functions. `ROLLUP()` hierarchically groups by arguments, starting left to right. `CUBE()` passes all permutations of its arguments to the aggregation functions. 

[Grouping sets are described a little here](https://pgexercises.com/questions/aggregates/fachoursbymonth3.html).

### Window functions

[Orver() explained here](https://pgexercises.com/questions/aggregates/countmembers.html). Some more detailed information [here](http://www.sqlservertutorial.net/sql-server-window-functions/).

Window functions include `OVER()` and `ROW_NUMBER()`. They take two optional arguments, `PARTITION BY` and `ORDER BY`. 

- `RANK() OVER([partition_by_clause] order_by_clause)`: ranks the column specified in the order by clause, ties are assigned the same rank and result in skipped values
- `DENSE_RANK() OVER([partition_by_clause] order_by_clause)`: ranks the column specified in the order by clause, ties are assigned the same rank, but no rank number is skipped
- `LAG(column,lag) OVER([partition_by_clause] order_by_clause)`: Retreives values from a `lag` rows before, see [example with a partition here](http://www.mysqltutorial.org/mysql-window-functions/mysql-lag-function/).

### Tricks: 

- When wanting to loop and compare, one can do a join or add a subquery and compare all columns at once. [Example](https://leetcode.com/problems/department-highest-salary/discuss/53607/Three-accpeted-solutions)



# Resources

- SQL training resources;
- [vertabelo](https://academy.vertabelo.com/#courses_list_section)
- [pgexercises](https://pgexercises.com/)
- [Udacity course](https://classroom.udacity.com/courses/ud198)
- [sqlbolt](https://sqlbolt.com/lesson/select_queries_introduction)
- [Mode Analytics](https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/) HackerRank (basic select, aggregation)
- [Hacker Rank](https://www.hackerrank.com/domains/sql)
- [W3School](https://www.w3schools.com/sql/exercise.asp?filename=exercise_select1)

- Python and other coding languages:
- [HackerRank](https://www.hackerrank.com/dashboard)
- [LeetCode](https://leetcode.com/)


Overview videos: 

- Top 10 Algorithms for the Coding Interview [Part I](https://www.youtube.com/watch?v=r1MXwyiGi_U), [Part II](https://www.youtube.com/watch?v=zHczhZn-z30)










