---
title: "Behavioral Interviewing"
author: "Mac Strelioff"
date: "`r Sys.time()`"
math: true
output:
  blogdown::html_page:
    toc: true
    toc_depth: 4
menu:
  InsightStudying:
    parent: Foundations
    weight: 99
linktitle: Behavioral Interviewing
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(entropy)

# set seed for reproducability
set.seed(10201991)
```

# Principles

- Interviews are conversations, not tests
- Use stories to establish a connection and demonstrate fit for a role and company


Tell me about yourself, your academic research, why data science?; 30 second elevator pitch vs. 2 minute phone screen/on-site

Why this company? what value can you add? Tell me about a time when… 

STAR chart (Situation, Task, Action, Result)

Mock interviews: Practice, practice, practice 

# Common Behavioral Questions

## "Tell me a little about your background."

This question gives an opportunity to demonstrate clear communication, curiosity, enthusiasm, transferrable skills, and value adds. This is also an opportunity to align past experience with the current job opportunity.

Template: 

- Problem: Concepts and context
- Curiosity: Open question
- Value: Why should people care
- Project Outline: Methods, results

Example answer: 

- Open: I recently graduated from UC Irvine, where I studied statistics and cognitive science, and worked on a few lines of research. 
- Problem: Wisdom of the crowds, like the social science equivalent of ensemble learners. However, many fallacies and biases in probabilistic reasoning hove been demonstrated in lab settings. 
- Context: Ryan and I.. I was like a statistician/behavioral economist, and he was a programmer. So I'd lead algorithm developemnt and he would code and deploy.
- Curiosity: Would prices in prediction markets be good estimators of real probabilities, since they incentivise and aggregate individual estimates, or would they show the same biases as individual probabilistic judgments, since they are aggregating over biased individuals? 
- Value: Finding systematic biases could result in corrections for market bias. 
- Project Overview: 
- Trajectory: Overall, I realized that I enjoy these kinds of impactful analyses of real-world data so I decided to join Insight and bridge into a career in data science. 


To answer this, I partnered with a large prediction market provider and found evidence of mispricings consistent with individual level biases -- miscalibration and also subadativity (superaditivity)?... 

I recently graduates from UC Irvine, where I studied statistics and cognitive science. I worked on a few lines of research, the one that was most interesting to me came out of an interest in stocks and arbitrage. So prediction markets are a platform where people can buy and sell contracts on events that pay a dollar if the event occurs and nothing if it doesn't occur. So for example, one market might be Who will win the 2020 election, and contracts might be 'Bernie Sanders', 'Andrew Yang', 'Donnald Trump', ... . Since the contracts pay out $1, the theory is that the price should estimate the underlying probability of the event occuring. And since the market is aggregating information across individuals, it should be a pretty good estimate. However, individuals have shown a number of biases in probabilistic reasoning in lab studies, so I was wondering if these same biases would exist in prediction market prices. If they did, then I could make profitable trading algorithms. 
So I partnered with a large online prediction market to get access to their data, and found evidence of some biases consistent with those observed in lab studies. 
- Overall, I realized that I enjoy these kinds of impactful analyses of real-world data, moreso than theory building through laboratory studies, so I decided to join Insight and bridge into a career in data science. 


Evaluation:

- Communication: Clearly explain prediction market mechanics, wisdom of the crowds, and an individual level fallacy. 
- Enthusasism: Interest in markets and complex problems. 
- Transferrable skills: Mention some of the models used.
- Value adds: Realized prediction markets are biased close to expiration -- their signal is weaker than previously thought. Also able to profit literally by rolling out trading algorithms. 


### Child bandits: 

Bandit tasks are a common paradigm for studying individual level decision making and making claims about the way people make decisions. But in lots of contexts, the results you get when you addregate over trials can be different from the actual result on any trial. So I developed a model to infer on a trial by trial level, what decision making strategy kids were using to choose between two 'bandits' that gave out stickers. -- I have an interest in using more customized models and Bayesian inference to overcome issues that arise from aggregating data at too high a level. If you had averaged over trials, then there may have been evidence for one or another model, but the dynamic changes in decision making strategies would have gone unnoticed. 

- Similar approaches could be useful for dynamic experimental designs, OR in the context of Netflix, for personalization. If we could dynamically infer something like the strategy or emotional state of a user, then we could use that inference to personalize our recommended content or things like cover art or other aesthetic aspects of Netflix. 


## "Tell me about the project you worked on at Insight."

This question gives an opportunity to demonstrate what you'll be capable of on Day 1.

Template: 

- Open: At Insight I worked on a consulting project for an external company. This company acquired users through a free trial, after which users would subscribe.
- Purpose: They wanted to 1) identify, early on, who would become a subscriber, and 2) How successful users were using the product. 
- Methods: I usually think about a generative process. Here I thought about LDA or QDA. Later thought about other algorithms because this was primarily a prediction problem. 
- Challenges: Non-normal features (could break LDA, QDA)

How could I have used a mixed effects model here? (See Maime's blog?)

Evaluation: 

- Clarity: 
- Relevance: Do the skills add value to the company? 
- Logic: Were sensible solutions tried in a sensible order? 

## "Why are you interested in a career as a data scientist?"

This is an opportunity to show that becoming a data sceientist at the company is the logical next career move, and to demonstrate that you know what to expect in the new role. 

Outline of topics that may resonate with a hiring manager: 

- Skills, Technical: Tools, technologies, methods you have used.
- Skills, Conceptual: Your approach to understanding problems and navigating to solutions
- Interests: What are you eager to do in this next phase of your professional life?
- Interests, Broad: Knowledge of problems tackled by data professionals in this industry
- Interests, Specific: Knowledge of technical challenges that will be faced by someone in this role
- Growth, Skills: What you’re excited to learn in the next few years
- Growth, Trajectory: Relate this job to an ultimate career trajectory


Example answer: 




Evaluation: 

- Educated Enthusasiam: 
- Professional Goals: 
- Niche area: 


## "Tell me about your research / talk to me about your last role."




Evaluation: 

- Skills: 
- Relevance: Show how previous work relates to the responsibilities of the current role. 
- Clarity: 



## "Why are you interested in joining this company?"

This is an opportunity to demonstrate knowledge of and interest in the current role. 


Evaluation: 

- Industry knowledge: 
- Company knowledge: 
- Potential for impact: 

## "Talk about a time you were on a team that struggled with effective communication." 


- Situation: Where / when did this happen? What were you working on, and with whom?
- Task: What were you responsible for? What challenges did you face? 
- Action: How did you decide the appropriate response to the situation? How did you implement it?
- Result: How do you know your solution was successful? 
- Takeaways: What did you learn from this situation? What would you do the same or differently next time?


Evaluation: 

- Knowledge of company values around communication: 
- Your principles for communication: 
- Awareness of problem: 
- Initiative: 
- Lessons Learned: 


## "Tell me about a time you made a mistake at work." 



- Situation: Where/when did this happen? What were you working on, and with whom?
- Task: What were you responsible for? What challenges did you face? 
- Action: How did you decide the appropriate response to the situation? How did you implement it?
- Result: How do you know your solution was successful? 
- Takeaways: What did you learn from this situation? What would you do the same or differently next time?


Evaluation: 

- Your principles for mistakes: 
- Knowledge of company values around rapid iteration, learning through failure, and troubleshooting
- Judgment: How did you explain the mistake (misunderstanding, incomplete information, technical errors)? Was it due to carelessness. 
- Responsibility: Did you make excuses, or make solutions? 
- Wisdom: Are you likely to avoid a similar mistake in the future? Can lessons here apply more broadly? 

## "Talk about a situation that required you to explain your technical work to someone outside your industry or field."



Evaluation: 

- Ability to communicate with stakeholders: 
- Impact: Understanding of what the other party needed to know
- Adaptability: Techniques (analogy, visualization, ...) used to simply communicate ideas. How did you decide what to include. Did you clarify that the explanation made sense. 
- Attitude: Will you patiently explain your ideas? 


## "Talk about a time you were asked to manage an important project." 

Evaluation: 

- Knowledge of company values on leadership
- Trust: Why were you chosen to lead?
- Respect and responsibility: 
- Delegation: 
- People management: 
- Executive decision-making: 
- Team dynamics: 
- Potential: Strengths and weaknesses in leading.
- Interest in management roles: 



# Deep-Dives

[Deep Dive guide](https://sites.google.com/insightdatascience.com/interviewstrategies/interviews/interview-logistics/deep-dives?authuser=0)


























