---
title: "Instacart Notes"
author: "Mac Strelioff"
date: "`r Sys.time()`"
menu:
  InsightStudying:
    parent: Foundations
    weight: 99
math: yes
linktitle: Instacart Deep Dive
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(entropy)

# set seed for reproducability
set.seed(10201991)
```


# TODO: 

- Check out info from [blog](https://medium.com/acing-ai/instacart-data-science-interview-questions-e8d89bea1a34)
- Read articles on their [DS blog](https://tech.instacart.com/tagged/data-science)
- [LinkedIn application for data scientist](https://www.linkedin.com/jobs/view/748128414/?refId=aa6b5d2c-8b03-4c2d-9643-1171a9fca283&trk=d_flagship3_company)
- [Instacart posting for data scientist](https://boards.greenhouse.io/instacart/jobs/1863911)
- [LinkedIn app for analyst](https://www.linkedin.com/jobs/view/1331659318/?refId=aa6b5d2c-8b03-4c2d-9643-1171a9fca283&trk=d_flagship3_company)

# Recruiter call

"Just be prepared to share with me what you are looking for, what is exciting to you and feel free to have questions ready about the team, role, business etc"

<!-- excitement -->

- Groceries have been hard for internet companies to get right -- it's exciting to see Instacart managing this well, and I'd be excited to be a part of this technological revolution of grocery delivery

<!-- questions -->

- More about role?
- general interview at this point, then team placement later? 
- to see what product team is best fit, then match that with their priorities
- data cleaning, kpis, models
- experimentation heavy
- DS vs ml; DS models increase understanding and guide decisions
- hiring in customer - growth, retention and engagement, marketing, core product
- and in performance - delivery logistics and operations for shoppers, fulfillment, shoppers and delivery
- - surrounding shopper model incentivized by flexibility in hours, and pay structure. 
- - competitive - they could be in postmates, doordash, ...
- - incitives, earnings, ... 
- - focused on incentivizing quality rather and balancing with speed.
- - experiment with different incentive structures.. 
- and in ads platform - cupons, product promotions (buy 1 get 1 free), ... 
- - all from brand partners
- - sales drive brand partners into business
- - DS around 10 individuals
- currently have 5 products in ads now, some tools help partners decide how to spend dollars

- Specific needs or challenges?

- Instacart growing at a pace faster than others in the bay area
- DS only 25 individuals, still one head of DS
- DS highly valuable and high ownership

- Sr contributor, prioritization important. 
- Each product team is cross functional, 1DS, 1 designer, 1-8 SWE, and a product manager. Desks are organized around these. 
- Owning metrics with the product teams. 
- E.g. earnings model might be partnering with growth team and delivery logistics side
- Report into a DS leader for mentorship, collaboration, ... .
- Still have autonomy and collaboration in day to day

- variety of team members in interview to chat about different projects
- feel free to ask about their day to day

Next steps

- problem solving phone interview (45min) - business case problem from a Sr DS, high level instacart related problem. E.g. how would we gain more customers, retain more customers. Something you'd think of as a DS. ask insightful questions, setup framework correctly, back up analysis and solution over phone. Looking how you organize thoughts and pivot thinking, might have a wrench thrown. 
- statistics SQL phone interview (45min). Stats 101, SQL is a necessity so quick 15 min exercise should be straightforward. 
-- coding over shared doc? 
-- first 30min over phone, next 30min online through a link 
- Onsite interview with a lot of topics. Experimental design, live DS project with clean data. Want to see how I solve it and present answers. Multiple ways of answering prompt. 
- project in three sessions; 
- 1 framework and metrics, 2 doing the work, 3 presentation to team of DS, strengths and weaknesses and justification of choices
- experimental design, problem solving/product sense

- hiring leader on customers will be out of office starting October 7th 

- will be asked about compensition at onsite.
- DS, Sr DS, Staff DS -- depends on interviews, and determines pay range. Will get cash based and equity in RSUs and then benefits. 
- Sr range between 170-190k on cash. Look at technical contributions, level of inititive, thought leadership, 400-600k over 4 years of equity. 

# Problem solving phone interview (45min)

- business case problem from a Sr DS, high level instacart related problem. 
- E.g. how would we gain more customers, retain more customers. 
- Something you'd think of as a DS. ask insightful questions, setup framework correctly, back up analysis and solution over phone. 
- Looking how you organize thoughts and pivot thinking, might have a wrench thrown. 

- 'How do we get more customers?'
- referral bonuses, ads, ads + discount codes

- increase customers
- retain customers

- Improve predictability for shopper experience
- Inventory prediction or modeling
- Model for item substitutes (crowd source this so that orderers can specify acceptable substitutes?)
- Labor models in local areas, accounting for unions and labor laws
- Trust with person delivering produce

## My Value ads

- [personalization](https://blog.dominodatalab.com/data-science-instacart/) mentioned at 31:00 in this video. 
- My research on utility-based decision making, and on RL and learning about environments to optimize decision making could both contribute here? 
- My work on inferring what strategy a person is following could relate to inferring their utility functions?
- My work on dynamic logistic bayesian regression could offer a fast way to approximate utility functions for different users, since random utility models are similar in functional form to logistic regressions


Ads: 

- Motivation has two components: activation and direction. 
- Activation: I'm not really hungry, then I see sizzling bacon and that makes me hungry. 
- Directing: I want bacon, then I see a nice omlette and decide to get that instead. Changes the action that manifests out of the latent state. 

- From YouTube, you can advertize to viewers who watch competing channels, e.g. I'd advertize on Ben Lambert since he also has educational stats videos. 
- At Instacart, this means advertizing to customers who are searching for a substitute product.. 

- Using substitutes and complements
- Advertize to users who are searching for a substiture item (eggs from a different farm)
- Advertize to users who are searching for a complement item (eggs for someone searching bacon)
- Bigger issue -- an ad to someone who is going to buy the product anyway is wasted money.. 
- Ads should target people who would buy if they see the ad, and wouldn't if they don't.
- Showing ads to people who will buy anyway confounds the effectiveness of the ad experiments. 



# Company Visit


## Business Model, Culture, and Vision

Business model:

- Instacart brings groceries online, through stores rather than through fulfillment centers (e.g. how Amazon does it).
- Recently showed their model was profitable and sustainable
- Became economical by batching orders, taking advantage of economies of scale, ...
- Gross margin positive, implying growth will be profitable
- Tips can only go to the last person that touched order (delivery) even if they didn't put together the order (pickers). 
- Brings incremental volume to grocery retailers
- Around 50/% of grocers have same price on app as in store, others have markups
- Seen as a antidote to Amazon by supporting local business
- There's a grocerie store within 10-15min from every household
- Most valuable ads because they influence behavior right before the purchase
- Want to build AdWords for groceries

Revenue

- Subscription or delivery fee from cusomter
- Service fee partially goes towards balancing tips for delivery and picking. 
- fee from retailer
- revenue from advertisers (talked about around 29:00)
- coupons 

costs

- delivery costs, pickers and delivery (can be different people)
- credit card transaction fees

I like the impact that data scientists can have:

- Minutes saved in deliveries is /$0.25 in gross margin, which can be passed to savings for the customer

I like the enturpneural spirit: 

- 6 months after Amazon bought Wholefoods, Instacart signed partnerships with nearly every large retailer 

## Projects, Tasks, and Data

Open problems:

- Improve predictability for shopper experience
- Inventory prediction or modeling
- Model for item substitutes (crowd source this so that orderers can specify acceptable substitutes?)
- Labor models in local areas, accounting for unions and labor laws
- Trust with person delivering produce

## DS Role

Teams that are hiring: 

<!-- From recruiter -->

- ads
- customer
- performance, or incentivizing shoppers



### Discussion of past work
"Be prepared to discuss your past work involving analyzing large and complicated datasets, defending your approaches and communicating what you learned during your project."

"elaborate on related projects from your resume"

PredictIt Project:

- Situation: 
- Project: 
- Maybe sketch the fig of price for Trump win versus Republican win
- I also aggregated data based on days until expiration, and applied a linear in log odds model at each day. 
- Found the common S shaped calibration curve that comes up in lab experiments, particularly at 1-2 days before market expiration.
- Result: 
- Value to Yelp: Relates to the economic patterns maybe? 

Strategy Inference Project:

- Situation: 
- Project: 
- Children and adults might use different strategies when making decisions. 
- I worked with a friend to formalize the possible set of strategies, and then I implemented a model to infer the probability of a kid following each strategy on each trial, and applied Bayes Theorem to get a probability that the kid was following any strategy over time. 
- Result: A lot of experiments focus on which strategy best fits all data across trials -- the approach that I took allows for changes in strategies, and the exciting result was an ability to track latent decision making strategies over time. 
- Value to Yelp: At yelp, for example, a user might be choosing restaurants based primarily on value, then shift to preferring restaurants based on rating. An analogous modeling approach might be able to detect, in near real time, the features that are driving an individual user's decisions. This informaiton could then be used to modify search rankings. 
- More specifically, model click probability as a function of value and stars, estimate the coefficients online, and use the coefficients to prioritize these features in rankings. 

General interest in decision making: 

- Situation: Models of multi-alternative decision making are often applied to food preferences to see how people integrate information about price, healthyness, flavor, ... . 
- Excitement: Yelp is basically a giant experiment in multiattribute decision making. 
- Value to Yelp: Theoretical insights might help in guiding how restaurant informaiton is displayed to consumers. 

Insight Project: 

- User funnel and user flow, maybe should have started at these simpler analyses
- Learned lots about decision trees, random forests versus gradient boosting and gini impurity versus mean decreas in accuracy
- Chose gini impurity because mean decrease in accuracy labels collinear features as unimportant
- Chose random forests because it does a better job of pulling out important collinear features

### Product metrics or experimentation
"You have a good chance of getting a product metrics or experimentation question based on some actual questions Yelp is tackling at the moment."

### General questions: 


# Deep Dive

## Stakeholders and Use Cases

User experiences covered in the beginning of [this video](https://blog.dominodatalab.com/data-science-instacart/).

- Consumers: Want 
- Pickers:
- Delivery: 
- Stores: 

## User Flows and Metrics

Thinking of the broader user flow can help with identifying measurable events within that flow (metrics).
Overall, consider units of individuals (accounts, unique visitors, cookies, IPs...), units of time (daily, weekly), and referents (week over week, ...)

- good source for some key [metrics](https://www.yelp.com/knowledge)

### On Web

1. Users (IPs) arrive on Yelp, can be assigned a cookie, or associated with an account if the user creates one. 

- Growth: DAU, MAU
- Growth: monthly new users, monthly unique users
- Engagement: Reviews per user per month
- Engagement: 
- Engagement: Traffic to business pages
- Monetization: Reservations
- Monetization: Waitlist

- Performance: Wait times at restaurants
- [Some metrics for business partners](https://biz.yelp.com/)

### On Mobile


## Current issues

- Supply/Demand balancing?

## Competitors

- Amazon
- Other food delivery -- Grubhub, Uber Eats, ... 

## Areas where ML is impactful:

- Machine learning is critical for our logistics teams, where we balance supply & demand and optimize the vehicle routing problem we have to fulfill grocery deliveries. We use machine learning (and operations research) to forecast distributions of outcomes, optimize control problems, predict grocery shopping and driving times, and solve routing optimization problems. We also use machine learning to assist our shoppers in stores by sorting their shopping lists.
- Another area machine learning has had a significant impact is in our catalog. We use machine learning to predict the probability any given item will be found at a given store location, and to suggest replacements for items that might not be found. There are many applications for using machine learning to improve the catalog (remove duplicates, tag products, enrich metadata, etc.), and so we are just beginning there.
- Last, but not least, we use machine learning extensively for search & discovery. I’ll let Sharath follow-on there.
- We haven’t used machine learning to affect growth (user acquisition) much. In part that’s because we have been growing so fast, we haven’t needed to optimize our growth strategies. In part it’s because we are still rapidly iterating our growth products, and so simpler solutions have been preferable.
- On the Search and Discovery side, there is search matching and ranking, merchandising across the site and several contextual recommendations including ads targeting and repurchase modeling (this competition!), which have benefitted from machine learning techniques.
- There are others such as query understanding - query expansion, spell-correction and autocomplete - where simpler data mining style approaches (aggregation, domain knowledge etc.) have been effective. This would be one of those areas where strict latency and engineering complexity raises the bar on how much more complex models must help to justify the investment (personalized query autocompletion for eg.)


## Notes on A/B testing from Jeremy

It very much depends upon the application. If we have a rigorous way of measuring the desired impact when deployed (usually an A/B test), then black-box models that maximize predictive power are often preferred. Even then, we often seek to understand those models in order to improve them, and in order to understand where they may fail in edge cases. At times, this means building a more structured model as well purely to aid understanding.

In some cases, we cannot A/B test. This can arise because of marketplace dynamics (groups of shoppers or customers are not independent) or because we are seeking to estimate something for measurement rather than for action. In these cases we prefer more structured models, as they can be interrogated and validated and their failings are more easily understood.

We also have applications where we expect the model to be used frequently outside of the domain it was trained in. This can happen when first introducing machine learning models. You begin a product with a simple set of heuristics that preclude you from ever observing a large part of the potential data space. In these cases, simpler models may generalize better to these unobserved spaces, and we can slowly build up exposure through explore / exploit approaches.

## Some exciting things about Instacart

From [why VP of DS joined](https://medium.com/@instacart/our-new-vp-of-data-science-answers-why-i-joined-instacart-2034f467577d)

- Instacart has a very unique business model, and that is why data science is so important for our success. Instacart is in part an ecommerce marketplace, and so we have all of the same fascinating catalog, search, recommendation and community opportunities that eBay and Etsy have. But Instacart is also a real-time logistics platform. So we also have all of the same fascinating forecasting, scheduling, operations and fulfillment opportunities that Uber or Lyft have.

## Ideas, excitement, questions to ask


## Glassdoor interview questions

- How to do power analysis for an A/B test.
- SQL timed exam
- Questions about efficiency curves in the supply demand distribution of Instacart's logistics.
- 1. Applied online, got a HackerRank link with SQL question. It is supposed to be completed within 2 hours, but it usually takes 30-40 minutes to solve. 
- 2. Phone screen with recruiter. It was a bit different since the recruiter didn't ask me any of my background or job fit, but rather asked me to drive the interview with my questions. She did ask some logistical questions like location, visa status, etc. 
- 3. Got a data analytics takehome assignment. Was given 2 days to accomplish it. The assignment was related to A/B tests, and exploratory data analysis. Had to prepare presentation. 
- 4. Phone Screen with Hiring Manager. Asked me about my background, ideal job and couple of open-ended questions regarding Shoppers in Instacart. 
- 5. Onsite Round 6 interviews, which constituted analytics take home presentation, analytical problem solving, statistics, culture fit interview during lunch, engineering partnership, product partnership, and with hiring manager. I liked the rigorousness of the process but was really disappointed when no feedback was given after I was rejected after the onsite.
- Without giving away the challenge I can say that I assume they were looking for more of a linear programming algorithm then the simple arithmetic I used to solve the problem. 
- SQL query and then an employee optimization dataset.
-  The most interesting part of the process was the take-home which consists of 1 ambiguous at best question with a data set of 1 month of order data, which is less data than they open-sources. 
- The HR representative said that for the 48 hour take home most people put in 4-6 hours to complete it, but because they want a visualization board, powerpoint, or presentation medium which can take a lot of work, it can feel like just another Silicon Valley rush assignment to do a full project. 
- How would you staff the team based on delivery data?
- Estimate the demand and supply
- Code challenge, hiring manager scan and then onsite. The HRs are very professional, but the interviewers are expecting you to know their business very well and they give very vague questions without enough explanation, without any guidance. There would be three technical white boarding rounds, each rounds you will deal with two data scientists. They ask questions about the business is dealing with, but no guidance, and they explain things really poorly, even one of them didn't say a word during the whole 45 min session.??????? Excuse me???? And they will tell you the result immediately, if you don't pass, all the following interviews will be cancelled.
- All HackerRank tests. An algorithm question about a kind of thing you will NEVER do at a job, and a SQL question that was reasonable and not the usual trivial thing. Phase II if you get past that or aren't age screened out yet, is analyzing a simple data set and make a presentation about your findings.
- 1. SQL test 2.Recruiter screen 3. Data take home challenge 4. Phone screen with a data scientist 5. On site Overall it was a smooth interview process. The recruiter was very helpful. The data scientists and PM's I met seemed smart but also very serious (could sense some stress). The on site has a behavioral competent (freebie if you can communicate decently) as well as several technical interviews. They will ask about statistical techniques you would use to solve a specific scenario (monte carlo simulation, decision tree, etc.). The interview was pretty rigorous and they will gauge how advanced you are with statistical knowledge and ability to apply it to business problems. Overall I thought I did well in all interviews other than a portion of one of them (didn't know what statistical method to use to solve specific case question), and ended up getting rejected.
- 1. We are observing this trend, what are possible explanations for why? 2. Behavioral (talk about a time when...) 3. SQL. Did not have live coding, only in the initial problem and take home portion
- The first interview was to send me a data set. Given a set of training cases, you need to extract the features and train a model, to predict for the test set.
- I can't reveal them but mostly around problems in Logistics that Instacart solves on a day to day basis.
- The coding challenge was a timed test mainly on predictive modeling.
- During the phone interview it was clear the interviewer had spent time looking at my past work and asked highly detailed questions about my work, and how I may have gone about certain tasks differently.
- How might you have optimized parameters for this model differently?
- You just have to create a predictive model from a couple csv files they send you.
- How would you tune a random forest?
- He was kind enough to answer a lot of questions, and asked an open-ended yet very specific question about the shopping process they're trying to optimize. Despite the ambiguity of the problem it felt like he was looking for some particular answers he may have been familiar with. In the end he proposed to send over detailed descriptions of the problem and some actual data, and asked for the solution to be coded up and sent back.
- The problem he asked to be solved is one of their most immediate business challenges, full-blown, not a coding test or even a restricted example at all. So it was odd they'd expect you to work on something for a week that an actual employee would spend several weeks refining. I thought it was to demonstrate coding and analytics skills, and provided a succint, well-commented solution, but didn't try to overdo it. 
- Then I had an analytical case where I had to build and explain a mode. Next I had an in-person interview which was another analytical challenge, but more whiteboarding. It included a data scientist and the hiring manager, who seemed great to work with. Lastly I chatted with the CEO who was friendly and down-to-earth.
- Explored various ways of monitoring user growth and retention.
- 






















