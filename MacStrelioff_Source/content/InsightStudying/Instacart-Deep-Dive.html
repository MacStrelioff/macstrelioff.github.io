---
title: "Instacart Notes"
author: "Mac Strelioff"
date: "2019-09-25 12:34:12"
menu:
  InsightStudying:
    parent: Foundations
    weight: 99
math: yes
linktitle: Instacart Deep Dive
---



<div id="todo" class="section level1">
<h1>TODO:</h1>
<ul>
<li>Check out info from <a href="https://medium.com/acing-ai/instacart-data-science-interview-questions-e8d89bea1a34">blog</a></li>
<li>Read articles on their <a href="https://tech.instacart.com/tagged/data-science">DS blog</a></li>
<li><a href="https://www.linkedin.com/jobs/view/748128414/?refId=aa6b5d2c-8b03-4c2d-9643-1171a9fca283&amp;trk=d_flagship3_company">LinkedIn application for data scientist</a></li>
<li><a href="https://boards.greenhouse.io/instacart/jobs/1863911">Instacart posting for data scientist</a></li>
<li><a href="https://www.linkedin.com/jobs/view/1331659318/?refId=aa6b5d2c-8b03-4c2d-9643-1171a9fca283&amp;trk=d_flagship3_company">LinkedIn app for analyst</a></li>
</ul>
</div>
<div id="recruiter-call" class="section level1">
<h1>Recruiter call</h1>
<p>“Just be prepared to share with me what you are looking for, what is exciting to you and feel free to have questions ready about the team, role, business etc”</p>
<!-- excitement -->
<ul>
<li>Groceries have been hard for internet companies to get right – it’s exciting to see Instacart managing this well, and I’d be excited to be a part of this technological revolution of grocery delivery</li>
</ul>
<!-- questions -->
<ul>
<li>More about role?</li>
<li>general interview at this point, then team placement later?</li>
<li>to see what product team is best fit, then match that with their priorities</li>
<li>data cleaning, kpis, models</li>
<li>experimentation heavy</li>
<li>DS vs ml; DS models increase understanding and guide decisions</li>
<li>hiring in customer - growth, retention and engagement, marketing, core product</li>
<li>and in performance - delivery logistics and operations for shoppers, fulfillment, shoppers and delivery</li>
<li><ul>
<li>surrounding shopper model incentivized by flexibility in hours, and pay structure.</li>
</ul></li>
<li><ul>
<li>competitive - they could be in postmates, doordash, …</li>
</ul></li>
<li><ul>
<li>incitives, earnings, …</li>
</ul></li>
<li><ul>
<li>focused on incentivizing quality rather and balancing with speed.</li>
</ul></li>
<li><ul>
<li>experiment with different incentive structures..</li>
</ul></li>
<li>and in ads platform - cupons, product promotions (buy 1 get 1 free), …</li>
<li><ul>
<li>all from brand partners</li>
</ul></li>
<li><ul>
<li>sales drive brand partners into business</li>
</ul></li>
<li><ul>
<li>DS around 10 individuals</li>
</ul></li>
<li><p>currently have 5 products in ads now, some tools help partners decide how to spend dollars</p></li>
<li><p>Specific needs or challenges?</p></li>
<li>Instacart growing at a pace faster than others in the bay area</li>
<li>DS only 25 individuals, still one head of DS</li>
<li><p>DS highly valuable and high ownership</p></li>
<li>Sr contributor, prioritization important.</li>
<li>Each product team is cross functional, 1DS, 1 designer, 1-8 SWE, and a product manager. Desks are organized around these.</li>
<li>Owning metrics with the product teams.</li>
<li>E.g. earnings model might be partnering with growth team and delivery logistics side</li>
<li>Report into a DS leader for mentorship, collaboration, … .</li>
<li><p>Still have autonomy and collaboration in day to day</p></li>
<li>variety of team members in interview to chat about different projects</li>
<li><p>feel free to ask about their day to day</p></li>
</ul>
<p>Next steps</p>
<ul>
<li>problem solving phone interview (45min) - business case problem from a Sr DS, high level instacart related problem. E.g. how would we gain more customers, retain more customers. Something you’d think of as a DS. ask insightful questions, setup framework correctly, back up analysis and solution over phone. Looking how you organize thoughts and pivot thinking, might have a wrench thrown.</li>
<li>statistics SQL phone interview (45min). Stats 101, SQL is a necessity so quick 15 min exercise should be straightforward. – coding over shared doc?</li>
<li><ul>
<li>no, first 30min over phone, next 30min online through a link</li>
</ul></li>
<li>Onsite interview with a lot of topics. Experimental design, live DS project with clean data. Want to see how I solve it and present answers. Multiple ways of answering prompt.</li>
<li>project in three sessions;</li>
<li>1 framework and metrics, 2 doing the work, 3 presentation to team of DS, strengths and weaknesses and justification of choices</li>
<li><p>experimental design, problem solving/product sense</p></li>
<li><p>hiring leader on customers will be out of office starting October 7th</p></li>
<li>will be asked about compensition at onsite.</li>
<li>DS, Sr DS, Staff DS – depends on interviews, and determines pay range. Will get cash based and equity in RSUs and then benefits.</li>
<li><p>Sr range between 170-190k on cash. Look at technical contributions, level of inititive, thought leadership, 400-600k over 4 years of equity.</p></li>
</ul>
</div>
<div id="problem-solving-phone-interview-45min" class="section level1">
<h1>Problem solving phone interview (45min)</h1>
<ul>
<li>business case problem from a Sr DS, high level instacart related problem.</li>
<li>E.g. how would we gain more customers, retain more customers.</li>
<li>Something you’d think of as a DS.</li>
<li>ask insightful questions,</li>
<li>setup framework correctly,</li>
<li>back up analysis and solution over phone</li>
<li><p>Looking how you organize thoughts and pivot thinking, might have a wrench thrown.</p></li>
<li>‘How do we get more customers?’</li>
<li><p>referral bonuses, ads, ads + discount codes</p></li>
<li>increase customers</li>
<li><p>retain customers</p></li>
</ul>
<!-- Possible topics -->
<ul>
<li>Improve predictability for shopper experience</li>
<li>Inventory prediction or modeling</li>
<li>Model for item substitutes (crowd source this so that orderers can specify acceptable substitutes?)</li>
<li>Labor models in local areas, accounting for unions and labor laws</li>
<li>Trust with person delivering produce</li>
</ul>
<!-- Insight Mock Qs -->
<ul>
<li><p>Instacart (a grocery delivery app) implemented a pickup option at a subset of grocery stores that partner with the company. The subset of grocery stores that got the pickup option was not randomly assigned. How would you figure out whether the revenue from pickup is incremental to delivery? In other words, is pickup cannibalizing delivery?</p></li>
<li><p>At Instacart, if you order 1-7 items, the delivery window is 1 hour. If you order 8-24 items, the window is 2 hours. If you order 25+ items, the window is 4 hours. Why is this approach problematic?</p></li>
<li><p>Imagine Instacart is rolling out a program which allows grocery stores to reduce wait times for pickups. Design an experiment for this program.</p></li>
<li>Brett</li>
<li><p>fulfillment side: shopper success</p></li>
<li>Customer side has ads, growth, and core</li>
<li>bus</li>
<li><p>falls under customers catelogue team</p></li>
</ul>
<div id="from-video-on-hiring-practices" class="section level2">
<h2>From video on hiring practices</h2>
<ul>
<li>objective, assumptions, scope</li>
<li>reliable, readable, flexible</li>
<li>logically sound and complete</li>
<li>clear description of work and sharp Q&amp;A</li>
</ul>
</div>
</div>
<div id="technical-phone-interview" class="section level1">
<h1>Technical Phone Interview</h1>
<p>Interviewer: <a href="https://www.linkedin.com/in/gregxrenner/">Gregory Renner</a></p>
<ul>
<li>Growth team</li>
<li>Started on people analytics team</li>
<li>Previously: Airforce, stats teacher, optimization and operations research</li>
</ul>
<div id="stats" class="section level2">
<h2>Stats:</h2>
</div>
<div id="sql" class="section level2">
<h2>SQL:</h2>
<div id="howard-advice" class="section level3">
<h3>Howard advice</h3>
</div>
<div id="framework" class="section level3">
<h3>Framework</h3>
<ul>
<li><p>Instacart delivers groceries online and on app</p></li>
<li><p>online - cookie assignment issue..</p></li>
<li>assume people order all groceries from one shop</li>
<li>Instacart dispatches shoppers to fulfill order</li>
<li>shoppers (picker+delivery) or picker and deliverer</li>
<li>customers fill out their cart, then see available delivery times</li>
<li>times in blocks of an hour</li>
<li>marketplace involves stores who give catelogues and sometimes pay</li>
<li><p>and goods companies place ads in app to have product come up</p></li>
<li>aim to deliver asap, don’t always have enough shoppers to meet demand.</li>
<li>Turn off timeslot if unavailable</li>
<li>lets say we have busy pricing to combat this, so just charge more instead of turning slot off</li>
<li>can increase up to 4x, usually just by a few dollars</li>
<li></li>
<li>Goals: how would you know if surege pricing is a good idea? What next?</li>
<li>Metrics:</li>
<li><ul>
<li>moving demand?</li>
</ul></li>
<li>see regular prices as baseline</li>
<li>see surge prices</li>
<li><ul>
<li>higher revenue?</li>
</ul></li>
<li>Interventions</li>
<li>Incentives for each stakeholder (what if we optimize for this)</li>
<li><p>Models: assumptions, estimators</p></li>
</ul>
</div>
<div id="metrics" class="section level3">
<h3>Metrics:</h3>
<p>many from <a href="https://www.slideshare.net/JagannathPutrevu/supply-optimization-instacartslideshare">this presentation</a></p>
<p>note when looking at product in video</p>
<ul>
<li>efficiency = delivery time / active time * active time / total time = active efficiency * utilization</li>
</ul>
<p>Shoppers:</p>
<ul>
<li>Driving time: batching, proximity to store, traffic</li>
<li>Picking time: speed of shopper, shopping list ordering, checkout times</li>
<li>Bags pickup time: staging area layout, numeber of bags being picked up</li>
<li>Delivery time: Traffic, order time/space density, routing algorithm efficiency</li>
<li>Idle time: Supply/Demand equilibrium, variance in cancellations, variance in shifts</li>
</ul>
<p>Process:</p>
<ul>
<li>Demand forecasts</li>
<li>Space/time density</li>
<li>Store Locations</li>
<li>Shopper pool or staffing</li>
<li>Traffic</li>
<li>Weather</li>
<li>Shopper ability (speed, precision)</li>
<li>Fulfillment times</li>
<li>Cancellation probability</li>
</ul>
<p>Constraints:</p>
<ul>
<li>handoff vs full-service</li>
<li>idleness vs efficiency vs lost delivery</li>
<li>store timings</li>
<li>shift length requirement</li>
<li>business rules</li>
</ul>
<p>Costs:</p>
<ul>
<li>idle hours</li>
<li>lost deliveries</li>
<li>lost efficiency</li>
</ul>
<p>Outputs:</p>
<ul>
<li>number of shoppers required</li>
<li>percent of volume done through handoff</li>
<li>estimated efficiency and utilization</li>
</ul>
</div>
<div id="complications" class="section level3">
<h3>Complications</h3>
<p>For ad experiments;</p>
<ul>
<li>Users go on vacation, (W=1,T=0,Y=0)</li>
<li>Competition bids more</li>
<li>Ad targeting biases sample</li>
<li>Algorithms for routing shoppers can’t be tested within the same geography since routes for T shoppers would influence the routes for C shoppers</li>
</ul>
</div>
</div>
<div id="my-value-ads" class="section level2">
<h2>My Value ads</h2>
<ul>
<li><a href="https://blog.dominodatalab.com/data-science-instacart/">personalization</a> mentioned at 31:00 in this video.</li>
<li>My research on utility-based decision making, and on RL and learning about environments to optimize decision making could both contribute here?</li>
<li>My work on inferring what strategy a person is following could relate to inferring their utility functions?</li>
<li>My work on dynamic logistic bayesian regression could offer a fast way to approximate utility functions for different users, since random utility models are similar in functional form to logistic regressions</li>
</ul>
<p>Ads:</p>
<ul>
<li>Motivation has two components: activation and direction.</li>
<li>Activation: I’m not really hungry, then I see sizzling bacon and that makes me hungry.</li>
<li><p>Directing: I want bacon, then I see a nice omlette and decide to get that instead. Changes the action that manifests out of the latent state.</p></li>
<li>From YouTube, you can advertize to viewers who watch competing channels, e.g. I’d advertize on Ben Lambert since he also has educational stats videos.</li>
<li><p>At Instacart, this means advertizing to customers who are searching for a substitute product..</p></li>
<li>Using substitutes and complements</li>
<li>Advertize to users who are searching for a substiture item (eggs from a different farm)</li>
<li>Advertize to users who are searching for a complement item (eggs for someone searching bacon)</li>
<li>Bigger issue – an ad to someone who is going to buy the product anyway is wasted money..</li>
<li>Ads should target people who would buy if they see the ad, and wouldn’t if they don’t.</li>
<li><p>Showing ads to people who will buy anyway confounds the effectiveness of the ad experiments.</p></li>
</ul>
<div id="discussion-of-past-work" class="section level3">
<h3>Discussion of past work</h3>
<p>“Be prepared to discuss your past work involving analyzing large and complicated datasets, defending your approaches and communicating what you learned during your project.”</p>
<p>“elaborate on related projects from your resume”</p>
<p>PredictIt Project:</p>
<ul>
<li>Situation:</li>
<li>Project:</li>
<li>Maybe sketch the fig of price for Trump win versus Republican win</li>
<li>I also aggregated data based on days until expiration, and applied a linear in log odds model at each day.</li>
<li>Found the common S shaped calibration curve that comes up in lab experiments, particularly at 1-2 days before market expiration.</li>
<li>Result:</li>
<li>Value to Yelp: Relates to the economic patterns maybe?</li>
</ul>
<p>Strategy Inference Project:</p>
<ul>
<li>Situation:</li>
<li>Project:</li>
<li>Children and adults might use different strategies when making decisions.</li>
<li>I worked with a friend to formalize the possible set of strategies, and then I implemented a model to infer the probability of a kid following each strategy on each trial, and applied Bayes Theorem to get a probability that the kid was following any strategy over time.</li>
<li>Result: A lot of experiments focus on which strategy best fits all data across trials – the approach that I took allows for changes in strategies, and the exciting result was an ability to track latent decision making strategies over time.</li>
<li>Value to Yelp: At yelp, for example, a user might be choosing restaurants based primarily on value, then shift to preferring restaurants based on rating. An analogous modeling approach might be able to detect, in near real time, the features that are driving an individual user’s decisions. This informaiton could then be used to modify search rankings.</li>
<li>More specifically, model click probability as a function of value and stars, estimate the coefficients online, and use the coefficients to prioritize these features in rankings.</li>
</ul>
<p>General interest in decision making:</p>
<ul>
<li>Situation: Models of multi-alternative decision making are often applied to food preferences to see how people integrate information about price, healthyness, flavor, … .</li>
<li>Excitement: Yelp is basically a giant experiment in multiattribute decision making.</li>
<li>Value to Yelp: Theoretical insights might help in guiding how restaurant informaiton is displayed to consumers.</li>
</ul>
<p>Insight Project:</p>
<ul>
<li>User funnel and user flow, maybe should have started at these simpler analyses</li>
<li>Learned lots about decision trees, random forests versus gradient boosting and gini impurity versus mean decreas in accuracy</li>
<li>Chose gini impurity because mean decrease in accuracy labels collinear features as unimportant</li>
<li>Chose random forests because it does a better job of pulling out important collinear features</li>
</ul>
</div>
</div>
</div>
<div id="deep-dive" class="section level1">
<h1>Deep Dive</h1>
<div id="business-model-culture-and-vision" class="section level2">
<h2>Business Model, Culture, and Vision</h2>
<p>Business model:</p>
<ul>
<li>Instacart brings groceries online, through stores rather than through fulfillment centers (e.g. how Amazon does it).</li>
<li>Recently showed their model was profitable and sustainable</li>
<li>Became economical by batching orders, taking advantage of economies of scale, …</li>
<li>Gross margin positive, implying growth will be profitable</li>
<li>Tips can only go to the last person that touched order (delivery) even if they didn’t put together the order (pickers).</li>
<li>Brings incremental volume to grocery retailers</li>
<li>Around 50/% of grocers have same price on app as in store, others have markups</li>
<li>Seen as a antidote to Amazon by supporting local business</li>
<li>There’s a grocerie store within 10-15min from every household</li>
<li>Most valuable ads because they influence behavior right before the purchase</li>
<li>Want to build AdWords for groceries</li>
</ul>
<p>Delivery Models;</p>
<ul>
<li>Handoff model: in-store pickers fulfill orders and stage groceries for pickup, drivers pickup groceries and deliver them</li>
<li>Full service: a single shopper picks and delivers</li>
</ul>
<p>Revenue</p>
<ul>
<li>Subscription or delivery fee from cusomter</li>
<li>Service fee partially goes towards balancing tips for delivery and picking.</li>
<li>fee from retailer</li>
<li>revenue from advertisers (talked about around 29:00)</li>
<li>coupons</li>
</ul>
<p>costs</p>
<ul>
<li>delivery costs, pickers and delivery (can be different people)</li>
<li>credit card transaction fees</li>
</ul>
<p>I like the impact that data scientists can have:</p>
<ul>
<li>Minutes saved in deliveries is /$0.25 in gross margin, which can be passed to savings for the customer</li>
</ul>
<p>I like the enturpneural spirit:</p>
<ul>
<li>6 months after Amazon bought Wholefoods, Instacart signed partnerships with nearly every large retailer</li>
</ul>
</div>
<div id="projects-tasks-and-data" class="section level2">
<h2>Projects, Tasks, and Data</h2>
<p>Open problems:</p>
<ul>
<li>Improve predictability for shopper experience</li>
<li>Inventory prediction or modeling</li>
<li>Model for item substitutes (crowd source this so that orderers can specify acceptable substitutes?)</li>
<li>Labor models in local areas, accounting for unions and labor laws</li>
<li>Trust with person delivering produce</li>
</ul>
</div>
</div>
<div id="deep-dive-1" class="section level1">
<h1>Deep Dive</h1>
<div id="stakeholders-and-use-cases" class="section level2">
<h2>Stakeholders and Use Cases</h2>
<p>User experiences covered in the beginning of <a href="https://blog.dominodatalab.com/data-science-instacart/">this video</a>.</p>
<ul>
<li>Customer: Want to search and pick groceries for delivery, paritcularly items they are loyal to, possibly from stores that they are loyal to</li>
<li>Pickers: Part time employees with hourly pay and incentive structures go to stores, find and scan items from a customer’s list.</li>
<li>Delivery: Contractors with incentive based pay deliver items from picker to customer. These are contract workers</li>
<li>Stores: Want their store to be chosen by customer</li>
<li><p>Advertisers: Want to increase demand possibly through ads</p></li>
<li>Instacart doesn’t tell shoppers where to find an item if a store is out of inventory. One reason is to maintain relationships with stores, rather than products.</li>
<li><p>Adding other types of retailers to the platform, but don’t want to canibalize the relationship with current retailers</p></li>
</ul>
</div>
<div id="metrics-1" class="section level2">
<h2>Metrics</h2>
<p>Ideas from <a href="https://www.youtube.com/watch?v=-Y8GGgT4Qf8">this video</a>,</p>
<p>Customers:</p>
<ul>
<li>User funnel; store search, item search, checkout, delivery screen</li>
<li>Delivery page views might indicate demand</li>
<li>Bounce before delivery screen might indicate browsing without intent</li>
<li><p>Bounces at delivery screen might indicate a decision to go to the store instead of use instacart</p></li>
<li>Browsing metrics</li>
<li>Checkout metrics: can check out (convert), get to checkout screen and see no delivery times then decide to go to store on their own (lost sale), or not go to check out screen (just browsing). Neglecting the lost sales could negatively impact staffing decisions, e.g. fewer delivery slots -&gt; fewer shoppers needed -&gt; fewer delivery slots -&gt; … -&gt; no more business.</li>
<li>Log every exposure to availability</li>
<li>Model probability of a checkout given customer-store-geography-hour. Then go back and model the probability of a checkout if the past customers had seen available checkouts. Demand models like this help with staffing decisions, and identifying undre staffed areas.</li>
<li>Demand = p(convert | 100% supply)</li>
<li><p>CI methods for inferring demand if there had been supply? Can compare demand in similar regions that have sufficient supply (nearly no bounces from checkout page)</p></li>
</ul>
<p>Pickers:</p>
<ul>
<li>time between scans on barcodes (time between picking items)</li>
</ul>
<p>Delivery:</p>
<ul>
<li>Goals: 1 match demand to maximize conversions 2 efficiency for good unit economics</li>
<li>Delays in delivery could indivate holidays, bad weather, regional traffic events</li>
</ul>
<p>For profitable unit economics;</p>
<ul>
<li>More efficient deliveries; more deliveries per shopper (picker, delivery) hour</li>
<li>Number of deliveries / number of labor hours</li>
<li>Can improve if shoppers are better utilized (less idle) or faster (more efficient, less time spent searching for items)</li>
<li>Improve operational organization</li>
<li>Improve incentives and training for shoppers to reduce</li>
<li>Part time employees in store</li>
<li>Contractors who deliver</li>
</ul>
</div>
<div id="monetization" class="section level2">
<h2>Monetization</h2>
<ul>
<li><ul>
<li>delivery fees from customers</li>
</ul></li>
<li><ul>
<li>Service Fees and Tips from customers for shoppers</li>
</ul></li>
<li><ul>
<li>Product partnerships from advertisers for ads</li>
</ul></li>
<li><ul>
<li>Retail partners subsidize delivery to get more customers</li>
</ul></li>
<li><ul>
<li>transaction costs, driver insurance</li>
</ul></li>
<li><ul>
<li>time driving and shopping, can cost more than service fees and tips</li>
</ul></li>
</ul>
<p>Instacart ads are highly valuable because of opportunities to measure intent and influence behavior at the point of sale.</p>
</div>
<div id="user-flows-and-metrics" class="section level2">
<h2>User Flows and Metrics</h2>
<p>Thinking of the broader user flow can help with identifying measurable events within that flow (metrics). Overall, consider units of individuals (accounts, unique visitors, cookies, IPs…), units of time (daily, weekly), and referents (week over week, …)</p>
<p>From <a href="https://www.youtube.com/watch?v=-Y8GGgT4Qf8">Jeremy Stanley small talk</a></p>
<p>Customer Experience</p>
<ul>
<li>Select store</li>
<li>Shop by selecting items</li>
<li>Checkout</li>
<li>Select delivery time</li>
<li>Return</li>
</ul>
<p>Shoppers</p>
<ul>
<li>Accept order</li>
<li>Drive to store, get list of groceries</li>
<li>Scan bar codes</li>
<li><p>Delivery</p></li>
<li><p>‘buy it again model’ sorts items shown to users based on how likely it is they’ll buy them again</p></li>
</ul>
</div>
<div id="data-science-work" class="section level2">
<h2>Data Science work</h2>
<p>From <a href="https://www.youtube.com/watch?v=-Y8GGgT4Qf8">video</a></p>
<p>Forecasting demand and supply (bounces from checkout and idle shoppers)</p>
<ul>
<li>Different time series models perform better or worse at different times of year, so the team uses different models depending on time of year. Could this be optimized with bayesian model averaging? Or would that lag the changes in the data?</li>
<li>Brain following habitual (model-free) vs goal-directed (model-based) strategies and shifts between these strategies depending on outcome variance. At instacart, a similar modeling approach that automates changes between forecasting models or models for staffing shoppers might be more efficient than a current method?</li>
</ul>
<p>Balancing supply and demand (changing delivery prices based on capacity)</p>
<ul>
<li>Charge more for delivery when estimated capacity drops</li>
<li>Incentivise people to place orders where it will be most efficient by offering cheaper prices</li>
<li>Account for consumers feeling gouged? 1) UX team can think about how this pricing influenced customers satisfaction, 2) AB testing, 3) models of longer term behavior of users exposed to higher surge prices to see causal effects of price strategies on longer term behavior</li>
</ul>
<p>Fulfuillment timeliness (fulfillment speed, probability deliver on time, chance shopper gets all items, customer happiness)</p>
<ul>
<li>Customers happiest near the beginning of time window, either before or after beginning of time window</li>
<li>Could start with Google API, but this breaks at scale</li>
<li>Instacart models outperform Google API estimates</li>
<li>Shoppers pick and then stage orders</li>
<li>Then drivers go to stores and pick up orders, then deliver them</li>
<li>Use quantile regression to model variance, which is important because of all the steps being modeled (picking each order, driver picking up each order and delivering each order)</li>
<li>(XGBoost?) Gradient boosting machines for comples time and space features and for scale</li>
<li><p>Account for picker variance? Design app to minimize picker veriance?</p></li>
<li>cost of idle hour (know shopper hourly pay)</li>
<li>cost of being late, know how much it affects customer happines, can relate to customer retention</li>
<li>guard rail metrics: probability of being late,</li>
<li>Netflix heuristically doubles value of customers for network effects to account for 1 other friend</li>
<li>understanding queues is crucial for efficency</li>
<li><p>having staff that can pick or deliver enables efficency of handoff model where pickers stage orders for delivery, or can deliver themselves</p></li>
</ul>
<p>Capacitized vehicle route planning with time windows:</p>
<ul>
<li>computational infeasibility e.g. O orders, D deliveries, N shoppers leads to O choose D * N options</li>
<li>pick subset such that orders in only one batch, orders delivered on time, shoppers move as fast as possible</li>
<li>impossible problem…</li>
<li>use greedy heuristics; for each unassigned order, assign to shopper that can do fastest, find other orders they can do quickly, … .</li>
</ul>
<p>Shopper efficency:</p>
<ul>
<li>Shopper speed (items per minute) vs batch size (items on list)</li>
<li>Control: sort departments randomly, then sort items within departments alphabetically. Shoppers got faster as batch size increases because item density increases (more adjacent items) and fewer unencountered items in unknown locations</li>
<li>Human sorting: people curate the orderings</li>
<li>Travling salesman solution: graph of items penalized by observed times between pickups. Ignores things like cold items parishing</li>
<li>Deep learning solution: outperforms human curation and travling salesman solution at large batch sizes.</li>
<li>Problem: In a store, just pickes item a, need a model to suggest which item to pick next that would maximize efficency (RL problem with markov state space determined by which item was just picked!)</li>
<li>Estimate P(next=item A | last = item B, candidates = unpicked items in list)</li>
<li>Deep learning structure - embed products, shoppers, stores, account for candidate set, predict next item, penalize from cross entropy loss function</li>
<li>Make predictions either for individual shopper or for best shopper at a store location</li>
<li>see article on ‘deep learning with emojis’</li>
<li></li>
</ul>
<p>Driving basket sizes:</p>
<ul>
<li>important way to increase revenue</li>
</ul>
<p>Considerations;</p>
<ul>
<li>long tail, ie storing lots of items</li>
<li>parishability, storing items for limited time</li>
<li>timeliness, physical pickups need to be close to dropoffs</li>
<li>cost</li>
<li>human errors;</li>
<li>pick wrong item (protected by scanning UPC code)</li>
<li>flag item as not there, when it was just not found</li>
</ul>
<p>Product Discovery</p>
<ul>
<li>Discovery in stores based on laying out items in a way that forces users to walk past new items</li>
<li>At instacart, deep learning from image to see how similar item is to one that users may have bought</li>
</ul>
<div id="on-web" class="section level3">
<h3>On Web</h3>
<ol style="list-style-type: decimal">
<li>Users (IPs) arrive on Yelp, can be assigned a cookie, or associated with an account if the user creates one.</li>
</ol>
<ul>
<li>Growth: DAU, MAU</li>
<li>Growth: monthly new users, monthly unique users</li>
<li>Engagement: Reviews per user per month</li>
<li>Engagement:</li>
<li>Engagement: Traffic to business pages</li>
<li>Monetization: Reservations</li>
<li><p>Monetization: Waitlist</p></li>
<li>Performance: Wait times at restaurants</li>
<li><p><a href="https://biz.yelp.com/">Some metrics for business partners</a></p></li>
</ul>
</div>
<div id="on-mobile" class="section level3">
<h3>On Mobile</h3>
</div>
</div>
<div id="current-issues" class="section level2">
<h2>Current issues</h2>
<ul>
<li>Supply/Demand balancing?</li>
</ul>
</div>
<div id="competitors" class="section level2">
<h2>Competitors</h2>
<ul>
<li>Amazon</li>
<li>Other food delivery – Grubhub, Uber Eats, …</li>
</ul>
</div>
<div id="areas-where-ml-is-impactful" class="section level2">
<h2>Areas where ML is impactful:</h2>
<ul>
<li>Machine learning is critical for our logistics teams, where we balance supply &amp; demand and optimize the vehicle routing problem we have to fulfill grocery deliveries. We use machine learning (and operations research) to forecast distributions of outcomes, optimize control problems, predict grocery shopping and driving times, and solve routing optimization problems. We also use machine learning to assist our shoppers in stores by sorting their shopping lists.</li>
<li>Another area machine learning has had a significant impact is in our catalog. We use machine learning to predict the probability any given item will be found at a given store location, and to suggest replacements for items that might not be found. There are many applications for using machine learning to improve the catalog (remove duplicates, tag products, enrich metadata, etc.), and so we are just beginning there.</li>
<li>Last, but not least, we use machine learning extensively for search &amp; discovery. I’ll let Sharath follow-on there.</li>
<li>We haven’t used machine learning to affect growth (user acquisition) much. In part that’s because we have been growing so fast, we haven’t needed to optimize our growth strategies. In part it’s because we are still rapidly iterating our growth products, and so simpler solutions have been preferable.</li>
<li>On the Search and Discovery side, there is search matching and ranking, merchandising across the site and several contextual recommendations including ads targeting and repurchase modeling (this competition!), which have benefitted from machine learning techniques.</li>
<li>There are others such as query understanding - query expansion, spell-correction and autocomplete - where simpler data mining style approaches (aggregation, domain knowledge etc.) have been effective. This would be one of those areas where strict latency and engineering complexity raises the bar on how much more complex models must help to justify the investment (personalized query autocompletion for eg.)</li>
</ul>
</div>
<div id="notes-on-ab-testing-from-jeremy" class="section level2">
<h2>Notes on A/B testing from Jeremy</h2>
<p>It very much depends upon the application. If we have a rigorous way of measuring the desired impact when deployed (usually an A/B test), then black-box models that maximize predictive power are often preferred. Even then, we often seek to understand those models in order to improve them, and in order to understand where they may fail in edge cases. At times, this means building a more structured model as well purely to aid understanding.</p>
<p>In some cases, we cannot A/B test. This can arise because of marketplace dynamics (groups of shoppers or customers are not independent) or because we are seeking to estimate something for measurement rather than for action. In these cases we prefer more structured models, as they can be interrogated and validated and their failings are more easily understood.</p>
<p>We also have applications where we expect the model to be used frequently outside of the domain it was trained in. This can happen when first introducing machine learning models. You begin a product with a simple set of heuristics that preclude you from ever observing a large part of the potential data space. In these cases, simpler models may generalize better to these unobserved spaces, and we can slowly build up exposure through explore / exploit approaches.</p>
</div>
<div id="some-exciting-things-about-instacart" class="section level2">
<h2>Some exciting things about Instacart</h2>
<p>From <a href="https://medium.com/@instacart/our-new-vp-of-data-science-answers-why-i-joined-instacart-2034f467577d">why VP of DS joined</a></p>
<ul>
<li>Instacart has a very unique business model, and that is why data science is so important for our success. Instacart is in part an ecommerce marketplace, and so we have all of the same fascinating catalog, search, recommendation and community opportunities that eBay and Etsy have. But Instacart is also a real-time logistics platform. So we also have all of the same fascinating forecasting, scheduling, operations and fulfillment opportunities that Uber or Lyft have.</li>
</ul>
</div>
<div id="ideas-excitement-questions-to-ask" class="section level2">
<h2>Ideas, excitement, questions to ask</h2>
</div>
<div id="glassdoor-interview-questions" class="section level2">
<h2>Glassdoor interview questions</h2>
<ul>
<li>How to do power analysis for an A/B test.</li>
<li>SQL timed exam</li>
<li>Questions about efficiency curves in the supply demand distribution of Instacart’s logistics.</li>
<li><ol style="list-style-type: decimal">
<li>Applied online, got a HackerRank link with SQL question. It is supposed to be completed within 2 hours, but it usually takes 30-40 minutes to solve.</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Phone screen with recruiter. It was a bit different since the recruiter didn’t ask me any of my background or job fit, but rather asked me to drive the interview with my questions. She did ask some logistical questions like location, visa status, etc.</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Got a data analytics takehome assignment. Was given 2 days to accomplish it. The assignment was related to A/B tests, and exploratory data analysis. Had to prepare presentation.</li>
</ol></li>
<li><ol start="4" style="list-style-type: decimal">
<li>Phone Screen with Hiring Manager. Asked me about my background, ideal job and couple of open-ended questions regarding Shoppers in Instacart.</li>
</ol></li>
<li><ol start="5" style="list-style-type: decimal">
<li>Onsite Round 6 interviews, which constituted analytics take home presentation, analytical problem solving, statistics, culture fit interview during lunch, engineering partnership, product partnership, and with hiring manager. I liked the rigorousness of the process but was really disappointed when no feedback was given after I was rejected after the onsite.</li>
</ol></li>
<li>Without giving away the challenge I can say that I assume they were looking for more of a linear programming algorithm then the simple arithmetic I used to solve the problem.</li>
<li>SQL query and then an employee optimization dataset.</li>
<li>The most interesting part of the process was the take-home which consists of 1 ambiguous at best question with a data set of 1 month of order data, which is less data than they open-sources.</li>
<li>The HR representative said that for the 48 hour take home most people put in 4-6 hours to complete it, but because they want a visualization board, powerpoint, or presentation medium which can take a lot of work, it can feel like just another Silicon Valley rush assignment to do a full project.</li>
<li>How would you staff the team based on delivery data?</li>
<li>Estimate the demand and supply</li>
<li>Code challenge, hiring manager scan and then onsite. The HRs are very professional, but the interviewers are expecting you to know their business very well and they give very vague questions without enough explanation, without any guidance. There would be three technical white boarding rounds, each rounds you will deal with two data scientists. They ask questions about the business is dealing with, but no guidance, and they explain things really poorly, even one of them didn’t say a word during the whole 45 min session.??????? Excuse me???? And they will tell you the result immediately, if you don’t pass, all the following interviews will be cancelled.</li>
<li>All HackerRank tests. An algorithm question about a kind of thing you will NEVER do at a job, and a SQL question that was reasonable and not the usual trivial thing. Phase II if you get past that or aren’t age screened out yet, is analyzing a simple data set and make a presentation about your findings.</li>
<li><ol style="list-style-type: decimal">
<li>SQL test 2.Recruiter screen 3. Data take home challenge 4. Phone screen with a data scientist 5. On site Overall it was a smooth interview process. The recruiter was very helpful. The data scientists and PM’s I met seemed smart but also very serious (could sense some stress). The on site has a behavioral competent (freebie if you can communicate decently) as well as several technical interviews. They will ask about statistical techniques you would use to solve a specific scenario (monte carlo simulation, decision tree, etc.). The interview was pretty rigorous and they will gauge how advanced you are with statistical knowledge and ability to apply it to business problems. Overall I thought I did well in all interviews other than a portion of one of them (didn’t know what statistical method to use to solve specific case question), and ended up getting rejected.</li>
</ol></li>
<li><ol style="list-style-type: decimal">
<li>We are observing this trend, what are possible explanations for why? 2. Behavioral (talk about a time when…) 3. SQL. Did not have live coding, only in the initial problem and take home portion</li>
</ol></li>
<li>The first interview was to send me a data set. Given a set of training cases, you need to extract the features and train a model, to predict for the test set.</li>
<li>I can’t reveal them but mostly around problems in Logistics that Instacart solves on a day to day basis.</li>
<li>The coding challenge was a timed test mainly on predictive modeling.</li>
<li>During the phone interview it was clear the interviewer had spent time looking at my past work and asked highly detailed questions about my work, and how I may have gone about certain tasks differently.</li>
<li>How might you have optimized parameters for this model differently?</li>
<li>You just have to create a predictive model from a couple csv files they send you.</li>
<li>How would you tune a random forest?</li>
<li>He was kind enough to answer a lot of questions, and asked an open-ended yet very specific question about the shopping process they’re trying to optimize. Despite the ambiguity of the problem it felt like he was looking for some particular answers he may have been familiar with. In the end he proposed to send over detailed descriptions of the problem and some actual data, and asked for the solution to be coded up and sent back.</li>
<li>The problem he asked to be solved is one of their most immediate business challenges, full-blown, not a coding test or even a restricted example at all. So it was odd they’d expect you to work on something for a week that an actual employee would spend several weeks refining. I thought it was to demonstrate coding and analytics skills, and provided a succint, well-commented solution, but didn’t try to overdo it.</li>
<li>Then I had an analytical case where I had to build and explain a mode. Next I had an in-person interview which was another analytical challenge, but more whiteboarding. It included a data scientist and the hiring manager, who seemed great to work with. Lastly I chatted with the CEO who was friendly and down-to-earth.</li>
<li>Explored various ways of monitoring user growth and retention.</li>
<li></li>
</ul>
</div>
<div id="insight-alum-mock-questions" class="section level2">
<h2>Insight Alum Mock Questions</h2>
<ul>
<li><p>Instacart (a grocery delivery app) implemented a pickup option at a subset of grocery stores that partner with the company. The subset of grocery stores that got the pickup option was not randomly assigned. How would you figure out whether the revenue from pickup is incremental to delivery? In other words, is pickup cannibalizing delivery?</p></li>
<li><p>At Instacart, if you order 1-7 items, the delivery window is 1 hour. If you order 8-24 items, the window is 2 hours. If you order 25+ items, the window is 4 hours. Why is this approach problematic?</p></li>
<li><p>Imagine Instacart is rolling out a program which allows grocery stores to reduce wait times for pickups. Design an experiment for this program.</p></li>
</ul>
</div>
<div id="insight-from-jeremy-on-kaggle" class="section level2">
<h2>Insight from Jeremy on Kaggle</h2>
<p>from <a href="https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/34200#latest-262904">here</a></p>
<p>How is time spent?</p>
<ul>
<li>5% getting the data (if working with a new data source, this is higher)</li>
<li>10% analyzing the data (understand context, build intuition)</li>
<li>10% manipulating the data (combining many sources, manipulating in non-trivial ways)</li>
<li>25% modeling R&amp;D (trying out different algorithms, backtesting)</li>
<li>25% putting into production (scalability, testing, app integration)</li>
<li>5% documenting (making it easy for future self and / or others to follow)</li>
<li>5% A/B test setup (setting up key metrics for success, resolving design decisions)</li>
<li>10% deployment (flipping a switch and then dealing with any issues)</li>
<li>5% maintenance (if not immediately iterating, ongoing maintenance for other changes)</li>
</ul>
<p>How are projects evaluated?</p>
<ul>
<li>Metric impact. If we moved target metric by Y, how much would it matter to the business?</li>
<li>User influence. If we changed the product, would it affect the users and drive the metric?</li>
<li>Product leverage. If we built X, could we change the product to affect users?</li>
<li>Data availability. Do we have the data needed? (If not, let’s collect it!)</li>
<li>Algorithm feasibility. Is it feasible to solve, do we have a best practice, can it scale?</li>
</ul>
</div>
</div>
