---
title: "Machine Learning"
author: "Mac Strelioff"
date: "2019-08-23 08:44:49"
math: true
output:
  blogdown::html_page:
    toc: true
menu:
  InsightStudying:
    parent: Foundations
    weight: 25
linktitle: Machine Learning
---


<div id="TOC">
<ul>
<li><a href="#considerations">Considerations</a><ul>
<li><a href="#bias-variance-trade-off">Bias-variance trade-off</a></li>
<li><a href="#overfitting-and-underfitting">Overfitting and Underfitting</a></li>
<li><a href="#cost-functions-and-metrics">Cost Functions and Metrics</a></li>
<li><a href="#feature-engineering">Feature Engineering</a><ul>
<li><a href="#seperability">Seperability</a></li>
<li><a href="#assumptions-about-form-of-relationship">Assumptions about form of relationship</a></li>
</ul></li>
</ul></li>
<li><a href="#unsupervised">Unsupervised</a><ul>
<li><a href="#clustering">Clustering</a><ul>
<li><a href="#k-means">k-means</a></li>
<li><a href="#agglomerative">Agglomerative</a></li>
<li><a href="#devisive">Devisive</a></li>
</ul></li>
<li><a href="#matrix-decomposition">Matrix Decomposition</a><ul>
<li><a href="#pca-principle-components-analysis">PCA Principle Components Analysis</a></li>
<li><a href="#svd-singular-value-decomposition">SVD Singular Value Decomposition</a></li>
</ul></li>
<li><a href="#text-based">Text-based</a><ul>
<li><a href="#lda-latent-direchilote-analysis">LDA Latent Direchilote Analysis</a></li>
<li><a href="#lsa-latent-semantic-analysis">LSA Latent Semantic Analysis</a></li>
</ul></li>
</ul></li>
<li><a href="#supervised">Supervised</a><ul>
<li><a href="#regression">Regression</a><ul>
<li><a href="#linear">Linear</a></li>
<li><a href="#support-vector-machine-svm">Support Vector Machine (SVM)</a></li>
</ul></li>
<li><a href="#classification">Classification</a><ul>
<li><a href="#naive-bayes">Naive Bayes</a></li>
<li><a href="#discriminant-analysis">Discriminant Analysis</a></li>
<li><a href="#knn">KNN</a></li>
<li><a href="#logistic-regression">Logistic Regression</a></li>
</ul></li>
</ul></li>
<li><a href="#ensemble-methods">Ensemble Methods</a><ul>
<li><a href="#trees-and-forests">Trees and Forests</a><ul>
<li><a href="#regression-1">Regression</a></li>
<li><a href="#classification-1">Classification</a></li>
</ul></li>
</ul></li>
<li><a href="#open-ended-template">Open ended Template</a><ul>
<li><a href="#raw-data-structure">Raw data structure?</a></li>
<li><a href="#define-target-variable">Define target variable</a></li>
<li><a href="#preprocession">Preprocession,</a></li>
<li><a href="#feature-engineering-1">Feature engineering</a></li>
<li><a href="#performance-metrics-and-how-they-apply">Performance metrics and how they apply</a></li>
<li><a href="#cautions">Cautions:</a></li>
<li><a href="#imagine-rolling-the-model-out">Imagine rolling the model out</a></li>
<li><a href="#model-explainability">Model explainability</a><ul>
<li><a href="#shapely-additive">Shapely additive</a></li>
<li><a href="#locally-linear">Locally linear</a></li>
<li><a href="#limitations">Limitations</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="considerations" class="section level1">
<h1>Considerations</h1>
<div id="bias-variance-trade-off" class="section level2">
<h2>Bias-variance trade-off</h2>
</div>
<div id="overfitting-and-underfitting" class="section level2">
<h2>Overfitting and Underfitting</h2>
<p>Cross Validation; Classification</p>
<p>Assess by comparing a performance metric on training and testing data.</p>
</div>
<div id="cost-functions-and-metrics" class="section level2">
<h2>Cost Functions and Metrics</h2>
<p>Modeling: Validation metrics,</p>
<p>metrics (precision, recall, F1)</p>
<p>R squared, RMSE</p>
<p>Likelihood</p>
<p>regularisation (ridge, lasso),</p>
</div>
<div id="feature-engineering" class="section level2">
<h2>Feature Engineering</h2>
<div id="seperability" class="section level3">
<h3>Seperability</h3>
</div>
<div id="assumptions-about-form-of-relationship" class="section level3">
<h3>Assumptions about form of relationship</h3>
<p>Process: feature selection, data cleaning / imputation with common pitfalls, model training, bias-variance trade-off</p>
</div>
</div>
</div>
<div id="unsupervised" class="section level1">
<h1>Unsupervised</h1>
<div id="clustering" class="section level2">
<h2>Clustering</h2>
<div id="k-means" class="section level3">
<h3>k-means</h3>
</div>
<div id="agglomerative" class="section level3">
<h3>Agglomerative</h3>
</div>
<div id="devisive" class="section level3">
<h3>Devisive</h3>
</div>
</div>
<div id="matrix-decomposition" class="section level2">
<h2>Matrix Decomposition</h2>
<div id="pca-principle-components-analysis" class="section level3">
<h3>PCA Principle Components Analysis</h3>
</div>
<div id="svd-singular-value-decomposition" class="section level3">
<h3>SVD Singular Value Decomposition</h3>
</div>
</div>
<div id="text-based" class="section level2">
<h2>Text-based</h2>
<div id="lda-latent-direchilote-analysis" class="section level3">
<h3>LDA Latent Direchilote Analysis</h3>
</div>
<div id="lsa-latent-semantic-analysis" class="section level3">
<h3>LSA Latent Semantic Analysis</h3>
</div>
</div>
</div>
<div id="supervised" class="section level1">
<h1>Supervised</h1>
<div id="regression" class="section level2">
<h2>Regression</h2>
<div id="linear" class="section level3">
<h3>Linear</h3>
</div>
<div id="support-vector-machine-svm" class="section level3">
<h3>Support Vector Machine (SVM)</h3>
</div>
</div>
<div id="classification" class="section level2">
<h2>Classification</h2>
<div id="naive-bayes" class="section level3">
<h3>Naive Bayes</h3>
</div>
<div id="discriminant-analysis" class="section level3">
<h3>Discriminant Analysis</h3>
<div id="lda" class="section level4">
<h4>LDA</h4>
<p>When to use:</p>
<ul>
<li></li>
</ul>
<p>Pros:</p>
<ul>
<li></li>
</ul>
<p>Cons:</p>
<ul>
<li></li>
</ul>
</div>
<div id="qda" class="section level4">
<h4>QDA</h4>
<p>When to use:</p>
<ul>
<li></li>
</ul>
<p>Pros:</p>
<ul>
<li></li>
</ul>
<p>Cons:</p>
<ul>
<li></li>
</ul>
</div>
</div>
<div id="knn" class="section level3">
<h3>KNN</h3>
<p>When to use:</p>
<ul>
<li></li>
</ul>
<p>Pros:</p>
<ul>
<li></li>
</ul>
<p>Cons:</p>
<ul>
<li></li>
</ul>
</div>
<div id="logistic-regression" class="section level3">
<h3>Logistic Regression</h3>
<p>When to use:</p>
<ul>
<li></li>
</ul>
<p>Pros:</p>
<ul>
<li></li>
</ul>
<p>Cons:</p>
<ul>
<li></li>
</ul>
</div>
</div>
</div>
<div id="ensemble-methods" class="section level1">
<h1>Ensemble Methods</h1>
<p>boosting, bagging</p>
<p>XGBoost, NLP (bag of words, vector-space models, sentiment analysis), Rec systems, Collab filtering, Optimization, XGBoost</p>
<div id="trees-and-forests" class="section level2">
<h2>Trees and Forests</h2>
<p>Gini Impurity: <span class="math display">\[
\begin{aligned}
m:&amp;\text{ Region} \\
k:&amp; \text{ Class} \\
G =&amp; \Sigma_k \hat{p}_{m,k}(1-\hat{p}_{m,k})
\\=&amp; 1 - \Sigma_k \hat{p}_{m,k}^2
\end{aligned}
\]</span></p>
<p>Decrease in Impurity <span class="math display">\[
\begin{aligned}
t:&amp;\text{ Node} \\
N_t:&amp;\text{ Samples at node }t \\
s_t:&amp;\text{ Split }t \text{ into } t_L,t_R\\
\Delta i(s_t,t)=&amp; i(t) - \frac{N_L}{N_t} i(t_L) - \frac{N_R}{N_t} i(t_R)
\end{aligned}
\]</span></p>
<p>Mean Decrease in Impurity: <span class="math display">\[
\begin{aligned}
T:&amp; \text{Trees} \\
N_T:&amp; \text{Number of trees} \\
t:&amp;\text{ Nodes} \\
s_t:&amp;\text{ Split }t \text{ into } t_L,t_R\\
v(s_t):&amp;\text{Variable split on at } s_t \\
p(t):&amp; \text{Proportion of total samples at node } t \\
Imp(X_m)=&amp;\frac{1}{N_T} \Sigma_{T}\Sigma_{t\in T:v(s_t)\in X_m} p(t) \Delta i(s_t,t)
\end{aligned}
\]</span></p>
<p><a href="https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e">Good blog on analysis of feature importance</a></p>
<p>Also see <a href="https://github.com/slundberg/shap">SHAP</a> for interpreting predictions from tree models!</p>
<p>Benefits of trees over OLS</p>
<p><a href="https://www.quora.com/How-does-a-random-forest-fix-regression-problems-non-normality-heteroscedasticity-multicollinearity-outliers-missing-values-and-categorical-variables" class="uri">https://www.quora.com/How-does-a-random-forest-fix-regression-problems-non-normality-heteroscedasticity-multicollinearity-outliers-missing-values-and-categorical-variables</a></p>
<div id="regression-1" class="section level3">
<h3>Regression</h3>
</div>
<div id="classification-1" class="section level3">
<h3>Classification</h3>
<p>Deep learning, Rec systems, Content and collaborative filtering, Optimization, Probabalistic programming</p>
<div id="assessment" class="section level4">
<h4>Assessment</h4>
<p>Confusion matrix, F1, precision-recall curve</p>
<p>ROC, AUC</p>
</div>
</div>
</div>
</div>
<div id="open-ended-template" class="section level1">
<h1>Open ended Template</h1>
<div id="raw-data-structure" class="section level2">
<h2>Raw data structure?</h2>
<ul>
<li>Table of information about consumer</li>
<li>Table of transaction history</li>
</ul>
</div>
<div id="define-target-variable" class="section level2">
<h2>Define target variable</h2>
<p>e.g. Fraud would be if a consumer calls and labels a transaction as fraud.</p>
</div>
<div id="preprocession" class="section level2">
<h2>Preprocession,</h2>
<ul>
<li>EDA - distributions, correlations</li>
</ul>
</div>
<div id="feature-engineering-1" class="section level2">
<h2>Feature engineering</h2>
</div>
<div id="performance-metrics-and-how-they-apply" class="section level2">
<h2>Performance metrics and how they apply</h2>
<ul>
<li>Precision</li>
<li>Recall</li>
<li>…</li>
</ul>
</div>
<div id="cautions" class="section level2">
<h2>Cautions:</h2>
<ul>
<li>Don’t mention models you aren’t familiar with</li>
</ul>
</div>
<div id="imagine-rolling-the-model-out" class="section level2">
<h2>Imagine rolling the model out</h2>
<ul>
<li>What issues might arise?</li>
<li>What actions do you take in production?</li>
</ul>
</div>
<div id="model-explainability" class="section level2">
<h2>Model explainability</h2>
<div id="shapely-additive" class="section level3">
<h3>Shapely additive</h3>
</div>
<div id="locally-linear" class="section level3">
<h3>Locally linear</h3>
<ul>
<li>eg <a href="https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime">here</a></li>
</ul>
</div>
<div id="limitations" class="section level3">
<h3>Limitations</h3>
<p>Limitations described a little in the FLowcast paper <a href="https://flowcast.ai/Flowcast_whitepaper_-_Explainability.pdf">here</a></p>
<ul>
<li>biased for collinear features?</li>
</ul>
</div>
</div>
</div>
