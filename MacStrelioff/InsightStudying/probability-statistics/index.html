<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.2.5">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Mac Strelioff">

  
  
  
    
  
  <meta name="description" content="Sources / Alternatives TODO: Intro Bandit Algorithms Problem Formalization Use Cases and Evaluation Criteria Type I Error False Discovery Rate Regret  Uniform Policy Greedy Policies \(\epsilon\)-Greedy Policy Softmax Policy  Upper Confidence Bound (UCB) Policy Thompson Sampling Policy  Policy Comparisons   Sources / Alternatives  Netflix Experimentation and Sequential Testing Optamizely Google Analytics   TODO: redo in Python, make an agent that uses each strategy as a method.">

  
  <link rel="alternate" hreflang="en-us" href="/MacStrelioff/insightstudying/probability-statistics/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="rgba(0,130,160,1)">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/MacStrelioff/css/academic.min.9c3a903cc870878595d69f08d98aa322.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-140153670-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/MacStrelioff/site.webmanifest">
  <link rel="icon" type="image/png" href="/MacStrelioff/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/MacStrelioff/img/icon-192.png">

  <link rel="canonical" href="/MacStrelioff/insightstudying/probability-statistics/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@macstrelioff">
  <meta property="twitter:creator" content="@macstrelioff">
  
  <meta property="og:site_name" content="Mac Strelioff">
  <meta property="og:url" content="/MacStrelioff/insightstudying/probability-statistics/">
  <meta property="og:title" content="Probability and Statistics | Mac Strelioff">
  <meta property="og:description" content="Sources / Alternatives TODO: Intro Bandit Algorithms Problem Formalization Use Cases and Evaluation Criteria Type I Error False Discovery Rate Regret  Uniform Policy Greedy Policies \(\epsilon\)-Greedy Policy Softmax Policy  Upper Confidence Bound (UCB) Policy Thompson Sampling Policy  Policy Comparisons   Sources / Alternatives  Netflix Experimentation and Sequential Testing Optamizely Google Analytics   TODO: redo in Python, make an agent that uses each strategy as a method."><meta property="og:image" content="/MacStrelioff/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  
  
  

  

  

  <title>Probability and Statistics | Mac Strelioff</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/MacStrelioff/">Mac Strelioff</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/MacStrelioff/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/MacStrelioff/data-science/">
            
            <span>Data Science</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/MacStrelioff/video-lectures/">
            
            <span>Videos</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/MacStrelioff/cv/">
            
            <span>Resume</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/MacStrelioff/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>



<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      


Please define menu items named `[menu.InsightStudying]` in your InsightStudying/Probability-Statistics.html front matter or define `[[menu.InsightStudying]]` in `config.toml`.


<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" id="search-query" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
</nav>

    </div>

    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Probability and Statistics</h1>

          <div class="article-style" itemprop="articleBody">
            

<div id="TOC">
<ul>
<li><a href="#sources-alternatives">Sources / Alternatives</a></li>
<li><a href="#todo">TODO:</a></li>
<li><a href="#intro">Intro</a></li>
<li><a href="#bandit-algorithms">Bandit Algorithms</a><ul>
<li><a href="#problem-formalization">Problem Formalization</a></li>
<li><a href="#use-cases-and-evaluation-criteria">Use Cases and Evaluation Criteria</a><ul>
<li><a href="#type-i-error">Type I Error</a></li>
<li><a href="#false-discovery-rate">False Discovery Rate</a></li>
<li><a href="#regret">Regret</a></li>
</ul></li>
<li><a href="#uniform-policy">Uniform Policy</a></li>
<li><a href="#greedy-policies">Greedy Policies</a><ul>
<li><a href="#epsilon-greedy-policy"><span class="math inline">\(\epsilon\)</span>-Greedy Policy</a></li>
<li><a href="#softmax-policy">Softmax Policy</a></li>
</ul></li>
<li><a href="#upper-confidence-bound-ucb-policy">Upper Confidence Bound (UCB) Policy</a></li>
<li><a href="#thompson-sampling-policy">Thompson Sampling Policy</a></li>
</ul></li>
<li><a href="#policy-comparisons">Policy Comparisons</a></li>
</ul>
</div>

<div id="sources-alternatives" class="section level1">
<h1>Sources / Alternatives</h1>
<ul>
<li><a href="https://medium.com/netflix-techblog/improving-experimentation-efficiency-at-netflix-with-meta-analysis-and-optimal-stopping-d8ec290ae5be">Netflix Experimentation and Sequential Testing</a></li>
<li>Optamizely</li>
<li>Google Analytics</li>
</ul>
</div>
<div id="todo" class="section level1">
<h1>TODO:</h1>
<ol style="list-style-type: decimal">
<li>redo in Python, make an agent that uses each strategy as a method. Build the agent throughout the script.</li>
</ol>
<!---
See: 
For Insight Bandit blogpost:
https://blog.insightdatascience.com/multi-armed-bandits-for-dynamic-movie-recommendations-5eb8f325ed1d

For Air BNB experimentation dashboard:
https://medium.com/airbnb-engineering/experiment-reporting-framework-4e3fcd29e6c0
--->
</div>
<div id="intro" class="section level1">
<h1>Intro</h1>
<p>Scientists and business students are trained in decision making from an outdated perspective – classical decision making based on p-values.</p>
<p>(make a case against p-values – inflated error rates, incoherence, difficulty integrating with expected value)</p>
</div>
<div id="bandit-algorithms" class="section level1">
<h1>Bandit Algorithms</h1>
<p>Much of this is from <a href="https://sudeepraja.github.io/Bandits/">this blog</a>.</p>
<p>Here I evaluate different algorithms for bandit problems similar to those anticipated in industry or testing settings. Criteria of consideration are;</p>
<div id="problem-formalization" class="section level2">
<h2>Problem Formalization</h2>
<p>Bandit tasks can be cast as a Markov Decision Process.</p>
<p><span class="math display">\[
\begin{aligned}
t &amp;\in \{1,...,T\} \\
a_t &amp;\in \mathcal{A} \\
s_t &amp;\in \mathcal{S} \\
r_t &amp;= R(s_{t+1}|a_t,s_t) = v(s_{t+1}|a_t,s_t) \\
T(s_{t+1}|a_t,s_t) &amp;= p(s_{t+1}|a_t,s_t) \\
\pi(s_t)&amp;=p(a_t|s_t)
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\pi\)</span> is referred to as a policy or decision rule. Mathematically, it is a probability distribution over actions – a funciton that maps from states to actions.</p>
<p>The decision maker’s goal here is to learn a policy (<span class="math inline">\(\pi\)</span>) that is optimal for some criteria. A variety of possible criteria are discussed and evaluated below. This objective is considered when chooseing the value function <span class="math inline">\(v(s_{t+1}|a_t,s_t)\)</span>.</p>
<p>Objective is to maximize <span class="math display">\[
E\left(\sum_t r_t\right)=\sum_tE(r_t)
\]</span></p>
<p>In a typical testing scenario, the policy replaces the assignment mechanism. Hence, I treat assignment mechanisms as policies here.</p>
</div>
<div id="use-cases-and-evaluation-criteria" class="section level2">
<h2>Use Cases and Evaluation Criteria</h2>
<p>Bandit problems arise across many theoretical and applied fields. Everything from industry A/B testing, medical clinical trials, experimental lab studies, and toy problems for reinforcement learning algorithms can be cast as a bandit task. These different domains generally have different goals. A/B tests are conducted to find evidence for an advantage of one version of a product over another while emphasizing classical statistical objectives like minimizing type I error rates or false discovery rates. The goal of clinical experiments is to quickly discover the best treatment so that patient lives can be improved or saved. In simulation settings, bandit problems have been used to benchmark a variety of algorithms in terms of regret. Here I conduct similar benchmarks, while also evaluating standard ‘best proctices’ in terms of type I error rates and false discovery rates.</p>

<div id="type-i-error" class="section level3">
<h3>Type I Error</h3>
<p>Among situations where there is no difference, how often is a difference detected?</p>
<p>Type I error occurs when a null hypothesis is reongly rejected – so when a difference in outcomes of arms is detected when none actually exists.</p>
</div>
<div id="false-discovery-rate" class="section level3">
<h3>False Discovery Rate</h3>
<p>Among detected differences, how many are real?</p>
<p>A false discovery occurs when an arm is selected but is not the actual optimal arm.</p>
<p>I’ll consider this on a trial-by-trial level as well as the result of the overall experiment.</p>
</div>
<div id="regret" class="section level3">
<h3>Regret</h3>
<p>Regret is the difference between the reward that would have been obtained had the optimal action been chosen, and the reward that was actually obtained from the chosen action.</p>
<p><span class="math display">\[
\begin{aligned}
E(Regret) &amp;= \sum_t E(r^*_{t}-r_t)
\end{aligned}
\]</span></p>
</div>
</div>
<div id="uniform-policy" class="section level2">
<h2>Uniform Policy</h2>
<p>This corresponds to a simple random sample type of assignment mechanism – the gold standard for causal inference from experimental data.</p>
<p><span class="math display">\[
\begin{aligned}
\pi(s_t) &amp;= \frac{1}{|\mathcal{A}|} \\
E(Regret) &amp;= TE(r^*_t) - \sum_t E(r_t|\pi) \\
&amp;= T(E(r^*_t) - E(r_t)) \\
\end{aligned}
\]</span></p>
<p>The expected regret on each trial is the difference between the maximal reward and mean reward across actions.</p>
</div>
<div id="greedy-policies" class="section level2">
<h2>Greedy Policies</h2>
<div id="epsilon-greedy-policy" class="section level3">
<h3><span class="math inline">\(\epsilon\)</span>-Greedy Policy</h3>
</div>
<div id="softmax-policy" class="section level3">
<h3>Softmax Policy</h3>
<p>Might be good for parameter estimation while also reducing regret.</p>
<pre class="r"><code>na=5      # Number of arms
as=1:na   # action IDs
beta = 5
R = runif(na) # arm probabilities
#R[1]=1; R[2]=.5; R[3]=0
T = 1500   # Number of trials
q=rep(0,na) 

pis = c()
qs = c()
ats = c()
rts = c()
regret = c()
regrett= 0;

for(ti in 1:T){
# select action
pi = exp(beta*q)/sum(exp(beta*q))
at = rmultinom(n=1,size=as,prob=pi)
at = which(at==1)
# observe outcome  
rt = rbinom(1,size=1,prob=R[at])
# save stats
pis = rbind(pis,pi)
ats = c(ats,at)
rts = c(rts,rt)
# update action values
q[at] = q[at] + .2 * (rt - q[at])
qs = rbind(qs,q)
# regret
regrett= regrett+max(R)-R[at]
regret = c(regret,regrett)
}</code></pre>
<pre class="r"><code>plot(regret,type=&quot;l&quot;)</code></pre>
<p><img src="/MacStrelioff/data-science/Probability-Statistics_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>cols = rainbow(na,s=1,v=.7)
for(ai in as){
if( ai&gt;1){par(new=TRUE)}
plot(qs[,ai],type=&quot;l&quot;,ylim=c(0,1),col=cols[ai],
     main=&quot;Estimation&quot;,
     ylab=&quot;Q-value&quot;,
     xlab=&quot;Trial&quot;)
abline(h=R[ai],col=cols[ai],lty=2)
}</code></pre>
<p><img src="/MacStrelioff/data-science/Probability-Statistics_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<pre class="r"><code>for(ai in as){
if( ai&gt;1){par(new=TRUE)}
plot(pis[,ai],type=&quot;l&quot;,ylim=c(0,1),col=cols[ai],
     main=&quot;Action Probabilities&quot;,
     ylab=&quot;Policy&quot;,
     xlab=&quot;Trial&quot;)
#abline(h=R[ai],col=cols[ai],lty=2)
}</code></pre>
<p><img src="/MacStrelioff/data-science/Probability-Statistics_files/figure-html/unnamed-chunk-1-3.png" width="672" /></p>
<pre class="r"><code>ent = 0
ps=c()
for(ai in as){
p = sum(ats==ai)/length(ats)
ent = ent + p*(-log2(p))
ps=c(ps,p)
}
c(ent,ps)</code></pre>
<pre><code>## [1] 1.41206826 0.01533333 0.68200000 0.03400000 0.14333333 0.12533333</code></pre>
<pre class="r"><code>c(entropy.empirical(table(ats),unit=&quot;log2&quot;),freqs.empirical(table(ats)))</code></pre>
<pre><code>##                     1          2          3          4          5 
## 1.41206826 0.01533333 0.68200000 0.03400000 0.14333333 0.12533333</code></pre>
</div>
</div>
<div id="upper-confidence-bound-ucb-policy" class="section level2">
<h2>Upper Confidence Bound (UCB) Policy</h2>
</div>
<div id="thompson-sampling-policy" class="section level2">
<h2>Thompson Sampling Policy</h2>
<pre class="r"><code>#na=5      # Number of arms
#as=1:na   # action IDs
#beta = 5
# keeps same as those above
# R = runif(na) # arm probabilities
#T = 5000   # Number of trials
#priors: rows: actions, col1:alpha, col2:beta
prior = matrix(1,nrow=na,ncol=2)

aposts=c()
bposts=c()
thompsonSamples = c()
ats = c()
rts = c()
regret = c()
regrett= 0;

for(ti in 1:T){
# select action
thompsonSample=c()
for(ai in as){
thompsonSample = c(thompsonSample,rbeta(1,prior[ai,1],prior[ai,2]))
}
at = which.max(thompsonSample)
# observe outcome
rt = rbinom(1,size=1,prob=R[at])
# save stats
thompsonSamples = rbind(thompsonSamples,thompsonSample)
ats = c(ats,at)
rts = c(rts,rt)
# update beta distributions
prior[at,1]=prior[at,1]+rt
prior[at,2]=prior[at,2]+(1-rt)
# save posterior parameters
aposts=rbind(aposts,prior[,1])
bposts=rbind(bposts,prior[,2])
# regret
regrett= regrett+max(R)-R[at]
regret = c(regret,regrett)
}</code></pre>
<pre class="r"><code>plot(regret,type=&quot;l&quot;,
     main=&quot;Regret = max E(reward) -  E(reward|choice)&quot;,
     ylab=&quot;Cumulative Regret&quot;,
     xlab=&quot;Trial&quot;)</code></pre>
<p><img src="/MacStrelioff/data-science/Probability-Statistics_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># something might be wrong with rbeta(x,vec1,vec2)

cols = rainbow(na,s=1,v=.7)
for(ai in as){
if( ai&gt;1){par(new=TRUE)}
plot(aposts[,ai]/(aposts[,ai]+bposts[,ai]),type=&quot;l&quot;,ylim=c(0,1),col=cols[ai],
     main=&quot;Reward Probability Estimation&quot;,
     ylab=&quot;Posterior Means&quot;,
     xlab=&quot;Trial&quot;)
abline(h=R[ai],col=cols[ai],lty=2)
}
legend(1100,.8,c(&quot;Estimate&quot;,&quot;True&quot;),lty=c(1,2))</code></pre>
<p><img src="/MacStrelioff/data-science/Probability-Statistics_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre class="r"><code>for(ai in as){
if( ai&gt;1){par(new=TRUE)}
plot(thompsonSamples[,ai],type=&quot;l&quot;,ylim=c(0,1),col=cols[ai],
     main=&quot;Posterior Samples&quot;,
     #ylab=expression(&#39;Sampled Value -- Policy=argmax&#39;[&#39;a&#39;]*&#39;(sample&#39;[&#39;a&#39;]*&#39;)&#39;),
     ylab=expression(&#39;Sampled Value&#39;),
     xlab=&quot;Trial&quot;)
#abline(h=R[ai],col=cols[ai],lty=2)
}</code></pre>
<p><img src="/MacStrelioff/data-science/Probability-Statistics_files/figure-html/unnamed-chunk-2-3.png" width="672" /></p>
<pre class="r"><code>ent = 0
ps=c()
for(ai in as){
p = sum(ats==ai)/length(ats)
ent = ent + p*(-log2(p))
ps=c(ps,p)
}
c(ent,ps)</code></pre>
<pre><code>## [1] 0.109426242 0.001333333 0.988666667 0.003333333 0.001333333 0.005333333</code></pre>
<pre class="r"><code>c(entropy.empirical(table(ats),unit=&quot;log2&quot;),freqs.empirical(table(ats)))</code></pre>
<pre><code>##                       1           2           3           4           5 
## 0.109426242 0.001333333 0.988666667 0.003333333 0.001333333 0.005333333</code></pre>
</div>
</div>
<div id="policy-comparisons" class="section level1">
<h1>Policy Comparisons</h1>
</div>

          </div>

          



          
        </div>

        <div class="body-footer">
          Last updated on Jan 1, 0001
        </div>

      </article>

      <footer class="site-footer">
  
  <p class="powered-by">
    <a href="/MacStrelioff/files/privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>

    

    
    
    
    <script src="/MacStrelioff/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//@macstrelioff.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/MacStrelioff/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/MacStrelioff/js/academic.min.d813ae958640746e240f434cafc95afb.js"></script>

  </body>
</html>


