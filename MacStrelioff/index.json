[{"authors":["admin"],"categories":null,"content":"I’m interested in optimizing discovery and decision making processes. This lead me to pursue a PhD in an Experimental Psychology lab and a concurrent MS in Statistics. In graduate school, I designed experiments to investigate how context and feedback influence subsequent choices and developed statistical models to emulate and infer a person\u0026rsquo;s decision making strategy.\nI also enjoy diving into new areas and learning new tools through consulting work and hobby projects. I am constantly looking for new ways to apply my skills \u0026ndash; Feel free to reach out if you have any opportunities!\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/MacStrelioff/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/authors/admin/","section":"author","summary":"I’m interested in optimizing discovery and decision making processes. This lead me to pursue a PhD in an Experimental Psychology lab and a concurrent MS in Statistics. In graduate school, I designed experiments to investigate how context and feedback influence subsequent choices and developed statistical models to emulate and infer a person\u0026rsquo;s decision making strategy.\nI also enjoy diving into new areas and learning new tools through consulting work and hobby projects.","tags":null,"title":"Mac Strelioff","type":"author"},{"authors":null,"categories":null,"content":"Use the menu on the left to navigate to articles on particular topics.\n","date":1580032586,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1580032586,"objectID":"debf13c740a20e259bcf8fe4a7ff2d2e","permalink":"/MacStrelioff/data-science/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/data-science/","section":"data-science","summary":"Use the menu on the left to navigate to articles on particular topics.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" Overview Use the menu on the left to change topics, and the menu on the right to find videos within topics. A complete list of my videos can be found on my youtube channel.\nI started making videos while I was a Teaching Assistant at UC Irvine for students who couldn\u0026rsquo;t make my discussion sections. Later I noticed a dearth of materials focused specifically on interview preparation for data scientists. I started making videos again to address this shortfall.\n","date":1536476400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536476400,"objectID":"51191988497a9d0164009b2b4425bf82","permalink":"/MacStrelioff/video-lectures/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/video-lectures/","section":"video-lectures","summary":"Overview Use the menu on the left to change topics, and the menu on the right to find videos within topics. A complete list of my videos can be found on my youtube channel.\nI started making videos while I was a Teaching Assistant at UC Irvine for students who couldn\u0026rsquo;t make my discussion sections. Later I noticed a dearth of materials focused specifically on interview preparation for data scientists.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":" true  Made as test\n","date":1536476400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536476400,"objectID":"e9a4998af0f4b3e05ada18a63d838e92","permalink":"/MacStrelioff/tutorial2/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/tutorial2/","section":"tutorial2","summary":"true  Made as test","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536476400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536476400,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/MacStrelioff/tutorial/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"title","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906574400,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/MacStrelioff/talk/example/","publishdate":"2017-01-01T00:00:00-08:00","relpermalink":"/MacStrelioff/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"  Probability Foundations Probability Rules Probability Functions Transformations of Random Variables Expectation Variance Information Theory Causal Graphs  Causal Inference Framework Key Assumptions Common Methods Diff in Diff Synthetic Control and Causal Impact Synthetic Controls IV Analysis Regression Discontinuity Fixed Effects Regression First differences Random Effects Propensity Score Matching Microsoft DoWhy   Efficient Inference Efficient Sampling Efficient Designs Efficient Models  Experiment Design Foundations Concerns Treatment Units Generative Model and Adjustment Variables Common Designs Assignment Mechanism Duration Integrety Checks Maximum Likelihood versus Bayes’ Estimators  GLMs Common Tests t-test ANOVA Linear Model Z test for proportions Chi-Square Logistic Regression Likelihood Ratio and Bayes Factors always valid p-values (ck optimizely white paper)  Different Estimands For CI more on variance Emperical Variance Estimation Mixed Effects Models Effiencicy or Variance Reduction GLMs  Causal Inference Methods Difference in Differences Causal Impact Synthetic Controls Propensity Score Matching Fixed Effects Regression Instrumental variables Regression Discontinuity    Probability Foundations A random variable is a variable with an unknown value, but known possible values. An event is an observed value of a random variable. An event space contains all possible values of the random variable. Probabilities are values assigned to each event in an event space which represent how likely each event is relative to all other events in the event space.\nI’ll use \\(p(e)\\) to represent the probability of an event. Some special probabilities include the probability of any event in the event space, which is 1. And the probability of any event other than \\(e\\), also called the compliment of \\(e\\) which I’ll denote with \\(\\neg e\\). \\(p(\\neg e)\\) is defined as;\n\\[ p(\\neg e) = 1 - p(e) \\]\nThat is, the probability of any event other than \\(e\\) (\\(p(\\neg e)\\)) is what’s left of the probability of any event (\\(1\\)) after removing the probability of event \\(e\\) (\\(p(e)\\)).\nProbability Rules A joint event refers to two or more events occurring together. They are colloquially talked about as one event ‘and’ another event occurring together. More formally, joint events are called intersections (represented with the \\(\\cap\\) symbol) between events. For events \\(e_1\\) and \\(e_2\\), the probability of their joint event will be represented with \\(p(e_1 \\cap e_2)\\). The probability of an intersection of events is the same regardless of which event is considered first;\n\\[ p(e_1 \\cap e_2) = p(e_2 \\cap e_1) \\]\nFor two events, \\(e_1\\) and \\(e_2\\), their intersection is found by; \\[ p(e_1 \\\u0026amp; e_2) = p(e_1\\cap e_2) = p(e_1|e_2)p(e_2) \\] where \\(p(e_1|e_2)\\) is a conditional probability, discussed in the next section.\nConditional events refer to one event, \\(e_1\\), after another event, \\(e_2\\), is known. \\(p(e_1|e_2)\\) represents the probability of \\(e_1\\) given, or after knowing, \\(e_2\\). These can be defined by rearranging the multiplication rule as follows; \\[ p(e_1|e_2)p(e_2)=p(e_1\\cap e_2) \\Rightarrow p(e_1|e_2)= \\frac{p(e_1\\cap e_2)}{p(e_2)} \\]\nNoting that, by the reflexively of joint events and the definition of the multiplication rule, \\(p(e_1 \\cap e_2) = p(e_2 \\cap e_1)= p(e_2 | e_1) p(e_1)\\), and so the above equation becomes; \\[ p(e_1|e_2)=\\frac{p(e_2 | e_1) p(e_1)}{p(e_2)} \\] This equation is known as Bayes’ Theorem or Bayes’ Rule.\nA union (represented with the \\(\\cup\\) symbol) of events refers to at least one of multiple events occurring. For events, \\(e_1\\) and \\(e_2\\), their union would include the probability that \\(e_1\\) occurs, the probability that or \\(e_2\\) occurs, and the probability that both \\(e_1\\) and \\(e_2\\) occur. Colloquially this is talked about the probability of \\(e_1\\) ‘or’ \\(e_2\\). Formally this is expressed and computed as; \\[ p(e_1\\text{ or } e_2) = p(e_1 \\cup e_2) = p(e_1) + p(e_2) - p(e_1 \\cap e_2) \\]\nWhere \\(p(e_1 \\cap e_2)\\) is a joint probability.\nIndependence is a common assumption in many statistical techniques. Statisticians assume independence primarily because it simplifies the computation of certain probabilities. Events are said to be independent if knowing one event does not change the probability of the other event. Formally, if events \\(e_1\\) and \\(e_2\\) are independent, this would mean that; \\[ \\begin{aligned} p(e_1|e_2) \u0026amp;= p(e_1) \\\\ p(e_2|e_1) \u0026amp;= p(e_2) \\end{aligned} \\]\nIf \\(e_1\\) and \\(e_2\\) are independent, then their joint probability simplifies as so; \\[ p(e_1 \\cap e_2) = p(e_1|e_2)p(e_2) = p(e_1)p(e_2) \\] Where the last equality is only true if \\(e_1\\) and \\(e_2\\) are independent (i.e. \\(p(e_1|e_2)=p(e_1)\\)).\nThen the probability of their union simplifies to; \\[ \\begin{aligned} p(e_1 \\cup e_2) \u0026amp;= p(e_1) + p(e_2) - p(e_1|e_2)p(e_2) \\\\ \u0026amp;= p(e_1) + p(e_2) - p(e_1)p(e_2) \\end{aligned} \\] Where again, the last part of this equality is only true if \\(e_1\\) and \\(e_2\\) are independent.\nEvents \\(e_1\\) and \\(e_2\\) are said to be mutually exclusive if the occurrence of either event precludes the occurrence of the other event. Formally mutual exclusivity means that; \\[ p(e_1 | e_2) = 0 \\text{ and } p(e_2 | e_1) = 0 \\]\nIf two events are mutually exclusive, then the probability of their joint event is; \\[ \\begin{aligned} p(e_1 \\cap e_2) \u0026amp;= p(e_1|e_2)p(e_2) \\\\ \u0026amp;= 0*p(e_2) \\\\ \u0026amp;= 0 \\end{aligned} \\]\nAnd the probability of their union simplifies to; \\[ \\begin{aligned} p(e_1 \\cup e_2) \u0026amp;= p(e_1) + p(e_2) - p(e_1 \\cap e_2) \\\\ \u0026amp;= p(e_1) + p(e_2) - 0 \\\\ \u0026amp;=p(e_1) + p(e_2) \\end{aligned} \\]\n Probability Functions Here I’ll describe the properties and use cases for probability functions and cumulative probability functions. Conventionally, use \\(f(x)\\) is used represent a probability function, and \\(F(x)\\) to represent a cumulative probability function. \\(f(x)\\) is commonly called a probability mass function (pmf) if \\(x\\) is discrete, and a probability density function (pdf) if \\(x\\) is continuous. \\(f(x)\\) and \\(F(x)\\) are related through integration:\n\\[ \\begin{aligned} f(x) \u0026amp;= \\frac{d}{dx}F(x) \\\\ F(x) \u0026amp;= \\int_{-\\infty}^{\\infty} f(x) d_{x} \\end{aligned} \\]\nFor discrete variables, the probability function represents the probability that \\(X\\) takes a specific value \\(x\\): \\(f(x) = p(X=x)\\). For continuous variables, the probability that the variable \\(X\\) takes any particular value is technically \\(0\\); \\(p(X=x)=0\\). However, \\(p(x)\\) is still related to probability functions \\(f(x)\\) through areas. For an arbitrarily small \\(\\epsilon\\) the probability that \\(X\\) takes a value between \\(x-\\epsilon\\) and \\(x+\\epsilon\\) is the area of the distribution over that range;\n\\[ \\begin{aligned} p( x - \\epsilon\u0026lt; x \u0026lt; x+\\epsilon) \u0026amp;= F(x+\\epsilon) - F(x-\\epsilon) \\\\ \u0026amp;= \\int_{-\\infty}^{(x-+\\epsilon)}f(x)d_{x} - \\int_{-\\infty}^{(x-\\epsilon)}f(x)d_{x} \\end{aligned} \\]\n Transformations of Random Variables Given \\(x\\sim F_X(x)\\) and \\(y=g(x)\\)\n\\[ \\begin{aligned} F_Y(y) = \\begin{cases} F_X(g^{-1}(y)), \u0026amp; \\text{ if g is increasing wrt x}\\\\ 1-F_X(g^{-1}(y)), \u0026amp; \\text{ if g is decreasing wrt x} \\end{cases} \\end{aligned} \\]\nBy the chain rule, the pdf is;\n\\[ \\begin{aligned} f_Y(y)=\\frac{d}{dy}F_y(y) = f_X(g^{-1}(y))\\left| \\frac{d}{dy} g^{-1}(y) \\right| \\end{aligned} \\]\nA special case of this is the probability integral transformation;\n\\[ \\begin{aligned} x\u0026amp;\\sim F_X(x) \\\\ Y\u0026amp;=F_X(x) \\\\ P(Y\\leq y) \u0026amp;= P(F_X(X)\\leq y) \\\\ \u0026amp;= P(F^{-1}_X(F_X^{-1}(X))\\leq F_X^{-1}(y)) \\\\ \u0026amp;= P(X \\leq F_X^{-1}(y)) \\\\ \u0026amp;= F_X(F_X^{-1}(y)) \\\\ \u0026amp;= y \\end{aligned} \\]\nWhich shows the relationship between a uniform random variable and the CDF of any other random variable.\n Expectation For any functions of a random variable, \\(g(x)\\), the expectation of that function is;\n\\[ E_{x}(g(x))=\\int_{-\\infty}^{\\infty}g(x)f(x)d_{x} \\]\nFor discrete random variables, \\(E(x)=\\sum_xxp(x)\\). For continuous random variables, \\(f(x)dx\\) is conceptually \\(p(x)\\) since it is the area under an infinately small segment of the probability function if \\(f(x)\\) represents the height and \\(dx\\) represents an infinately small width.\nExpectation is a linear operator, so for constants \\(a\\), \\(b\\), and \\(c\\) and random variables \\(x\\) and \\(y\\); \\(E(ax+by+c) = aE(x)+bE(y)+c\\).\nExpectation for joint random variables \\[ E_{x,y}(g(x,y))=\\int_{s=x}\\int_{t=y}g(s,t)f(s,t)d_{s}d_{t} \\]\nMarginalizing a distribution from a joint probability function (\\(f(x,y)\\)) or a conditional probability function (\\(f(x|y)\\)): \\[ \\begin{aligned} f_x(x)\u0026amp;=\\int_yf_{x,y}(x,y)d_{y}\\\\ \u0026amp;=\\int_y f_{x|y}(x|y)f_y(y)d_{y}\\\\ \u0026amp;=E_y(f(x|y)) \\end{aligned} \\]\nLaw of total expectation, and rough proof\n\\[ \\begin{aligned} E_{x}(x)\u0026amp;=E_{y}(E_{x|y}(x|y))\\\\ \u0026amp;=\\int_y\\int_{x}xf_{x|y}(x|y)d_{x}f(y)d_{y} \\\\ \u0026amp;=\\int_{x}x\\int_{y}f_{x|y}(x|y)f(y)d_{y}d_{x} \\\\ \u0026amp;=\\int_{x}xf(x)d_{x}\\\\ \u0026amp;=E_{x}(x) \\end{aligned} \\]\nThe last steps reflect that the internal integral is just marginalizing across y; \\(f_x(x)=\\int_y f_{x|y}(x|y)f_y(y)d_{y}\\).\n Variance Covariance and variance\n\\[ \\begin{aligned} Cov(X,Y)\u0026amp;=E_{x,y}((X-E_{x}(X))(Y-E_{y}(Y)))\\\\ Var(X)\u0026amp;=Cov(X,X)=E_{x}((X-E_{x}(X))^2) \\\\ \u0026amp;= E(X^2)-E(X)^2 \\end{aligned} \\]\nThe Bias-Variance tradeoff decomposes the theoretical variance obtained when estimating a function \\(g(x)\\) with a model \\(\\hat{g}(x)\\) into three components that can be used to motivated changes to the model. Specifically, the Bias-Variance tradeoff is a decomposition of the expected prediction error; \\(g(x)-\\hat{g}(x)\\). To see it’s relation to variance, first rearrange the variance equation above:\n\\[ \\begin{aligned} Var(X)= E(X^2)-E(X)^2 \\\\ \\Rightarrow E(X^2) = Var(X)+E(X)^2 \\\\ \\end{aligned} \\]\nThen define the random variable \\(X\\) to be the errors of the model;\n\\[ \\begin{aligned} E((g(x)-\\hat{g}(x))^2) \u0026amp;= Var((g(x)-\\hat{g}(x))^2)+E((g(x)-\\hat{g}(x)))^2 \\\\ \u0026amp;= (g(x)-E(\\hat{g}(x)))^2 + E((E(\\hat{g}(x))-\\hat{g}(x))^2) + Var(g(x))\\\\ \u0026amp;= Bias(\\hat{g}(x))^2 + Var(\\hat{g}(x)) + Var(g(x)) \\end{aligned} \\]\nHere bias represents the squared error between the true function \\(g(x)\\) and the expected model \\(E(\\hat{g}(x))\\). Variance represents the squared error between the expected model and the obtained model. And \\(Var(g(x))\\) represents the true noise or irreducible error in the process \\(g(x)\\).\nVariance of linear combinations of random variables:\n\\[ Var(aX+bY+c)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y) \\]\nVariance is also crucial for designing experiments, for example if \\(a\\) or \\(b\\) have different signs and \\(Cov(X,Y)\u0026gt;0\\), then the variance between is reduced because the covariance is subtracted off. This is a justification for within-participant designs, where \\(X\\) represents the first measurement, \\(Y\\) represents a future measurement, \\(a=-1\\) and \\(b=1\\) to reflect a difference comparing the second and first measurements (\\(Y-X\\)), and since the measurements come from the same person here, it is reasonable to assume they are correlated (\\(Cov(X,Y)\u0026gt;0\\)). In this case, \\(Var(X,Y)=Var(X)+Var(Y)-Cov(X,Y)\\), which is not larger than the variance that would be obtained if the measurements were from independent samples.\nLaw of total variance: The variance of a variable \\(X\\) can be decomposed into the variation in the variable that remains when \\(Y\\) is known or irreducible error (\\(E(Var(X|Y))\\)), and the variation that carries through from the uncertainty in the model estimation \\(Y\\) (\\(Var(E(X|Y)\\)). \\[ \\begin{aligned} Var(X)\u0026amp;=E(Var(X|Y))+Var(E(X|Y)) \\end{aligned} \\]\nThis arises in hierarchical models and prediction intervals.\n\\[ \\begin{aligned} x \u0026amp;\\sim N(\\mu,\\sigma)\\\\ E(x) \u0026amp;=\\mu\\\\ Var(x) \u0026amp;=\\sigma^2\\\\ \\hat{\\mu}_n \u0026amp;\\sim N\\left(\\mu,\\frac{\\sigma}{\\sqrt{n}}\\right)\\\\ E(\\hat{\\mu}_n) \u0026amp;=\\mu\\\\ Var(\\hat{\\mu}_n)\u0026amp;=\\frac{\\sigma^2}{n}\\\\ E(x_{n+1}) \u0026amp;= E(E(x_{n+1}|\\hat{\\mu}_n))= E(\\hat{\\mu}_n)=\\mu \\\\ Var(x_{n+1}) \u0026amp;=E(Var(x_{n+1})) + Var(E(x_{n+1}|\\mu_{n})\\\\ \u0026amp;=\\sigma^2+\\frac{\\sigma^2}{n}\\\\ (100-\\alpha)PI: \u0026amp; E(x_{n+1}|\\hat{\\mu}_n) \\pm T_\\alpha \\sqrt{Var(x_{n+1})}\\\\ \\end{aligned} \\]\n Information Theory Information or Surprise is a measure of how unexpected an event was: \\[ I(x)=-log(f(x))=log\\left(\\frac{1}{f(x)} \\right) \\]\nEntropy is the expected surprise – higher entropy relates to more uncertainty: \\[ H(X)=E(I(x)) = E(-log(f(x))) = \\int_X f(x)I(x)dx = -\\int_X f(x)log(f(x))d_x \\]\nK-L Divergance, or relative entropy, is the expected distance between distributions with respect to one of the distributions: \\[ \\begin{aligned} D_{KL}(f_{x}(x);f_{y}(x)) \u0026amp;= \\int_{X} f_{x}(x)log\\left(\\frac{f_{y}(x)}{f_{x}(x)} \\right)d_x\\\\ \u0026amp;= \\int_X f_{x}(x)(log(f_{y}(x))-log(f_{x}(x))d_x \\\\ \\end{aligned} \\]\nDivergance is an important concept in machine learning, because it can be a loss function when we are estimating a distribution \\(f(x)\\) with a model \\(\\hat{f}(x)\\). From a Bayesian perspective, Divergance between a prior and posterior measures the information gained by observing the data. Bayesian experimental design focuses on collecting data that maximizes the divergance between the posterior and prior, i.e. the most informative data.\nMutual Information is the divergance from the joint distribution \\(f_{x,y}(x,y)\\) to the joint when independence is assumed \\(f_x(x)f_y(y)\\) – i.e. a measure of non-independence; \\[ I(x;y)=\\int_{y} \\int_{x} f_{x,y}(x,y)log\\left(\\frac{f(x,y)}{f(x)f(y)} \\right)d_yd_x \\]\n Causal Graphs  Expressions of dependence between random variables Add some info from Judeal Pearl papers relevant to experimentation and inference?    Causal Inference The ultimate goal of most statistical work is to discover the causes of some outcome so that the outcome can be controlled. Hence, it is important to understand when causality can be inferred.\nFrom this perspective, there is a treatment assignment \\(T\\) and an outcome of interest that depends on the treatment \\(Y(T)\\). Ideally, we would be able to compute the expected treatment effeoct for any individual \\(E(Y_i(T=1)-Y_i(T=0))\\), but it is impossible to assign an individual to both variants of the treatment under the exact same conditions – e.g. one must be done at a later time than the other. Causal inference approaches specify the assumptions, models, and designs neeed to make causal statements.\nMost methods like t-tests and ANOVAs compare the observed outcomes in the treatment group to the observed outcomes in the control group. These methods are based on correlations but can be interpreted causally if additional assumptions are made. Framework The general setting I’ll refer to a causal graph where individuals \\(i\\) are assigned to a particular condition indicated with \\(Z_i\\), they experience a condition indicated by \\(W_i\\), and an observed outcome for a level of the assigned and experienced condition \\(Y_i(Z_i,W_i)\\).\nThe causal craph is;\n\\[ Z_i \\rightarrow W_i \\rightarrow Y_i(Z_i,W_i) \\]\nWhere the assignment and experience of a treatment or control condition are represented with;\n\\[ \\begin{aligned} Z_i \u0026amp;= \\begin{cases} 1, \u0026amp; \\text{Assigned to treatment} \\\\ 0 \u0026amp; \\text{Assigned to control} \\end{cases} \\\\ W_i \u0026amp;= \\begin{cases} 1, \u0026amp; \\text{Experienced treatment} \\\\ 0 \u0026amp; \\text{Experienced control} \\end{cases} \\end{aligned} \\]\nAnd there are potential outcomes \\(Y\\) under any combination of assigned and experienced conditions;\n\\[ \\begin{aligned} Y_i(Z_i,W_i) \u0026amp;= \\begin{cases} Y_i(0,0), \u0026amp; \\text{Outcome when assigned C and experienced C}\\\\ Y_i(0,1), \u0026amp; \\text{Outcome when assigned C and experienced T} \\\\ Y_i(1,0), \u0026amp; \\text{Outcome when assigned T and experienced C} \\\\ Y_i(1,1) \u0026amp; \\text{Outcome when assigned T and experienced T} \\end{cases} \\end{aligned} \\]\nIn most lab studies this setup simplifies because \\(Z_i=W_i\\) since there is no possibility that a lab participant does not experience the condition they are assigned to. However, in online experimentation users can often opt out of a treatment condition, and users assigned to a control condition could end up getting access to features of the treatment condition. Methods to address these complications are discussed below.\n Key Assumptions  Exclusion: \\(Y(0,W_i)=Y(1,W_i)=Y(W_i)\\), or probabilistically \\(p(Y_i(Z_i,W_i)|Z_i,W_i)=p(Y_i(Z_i,W_i)|W_i)\\). The treatment assignment \\(Z_i\\) influences the outcome only through the experienced condition \\(W_i\\), i.e. conditional on the experienced condition, the observed outcome \\(Y_i\\) is independent of the assigned condition.  To simplify notation, I’ll assume exclusion and refer to observed outcomes as \\(Y_i(W_i)\\).\n Stable units: units experience one version of the treatment one unit’s assignment doesn’t influence another unit’s outcome\n Endogeneity refers to a relationship between covariates and the error terms, e.g. through unobserved confounds. Back door exclusion, or no endogeniety, i.e. no direct \\(Z\\rightarrow Y\\) link.\n Unconfoundedness: \\(Y_i(0),Y_i(1) \\perp Z_i | X_i\\). Conditional on observed covariates (\\(X_i\\)), assignments (\\(Z_i\\)) and potential outcomes (\\(Y(W_i)\\)) are independent.\n  If unconfoundedness isn’t satisfied, i.e. the distributions of \\(X_i\\) differs between levels of \\(W_i\\), then the overlap assumption can be made to allow for the use of propensity scores.\n Overlap: \\(0\u0026lt; p(W_i|X_i) \u0026lt; 1\\), \\(\\forall X_i\\): For all levels of the covariates \\(X_i\\), the probability of experiencing treatment is nonzero, and the probability of experiencing control is nonzero.  This assumption allows the use of propensity scores \\(\\hat{p}(W_i|X_i)\\), which are estimates of \\(p(W_i|X_i)\\) that are used to match units with similar propensity, or to reweight observed outcomes to account for propensity.\n Common Methods Some summarized in this Medium Post\nDiff in Diff Contexts:\n A treatment group and a comperable control group can be observed before and after the treatment is applied.  Assumptions and requirements:\n Requires observed data on a control group pre and post treatment Parallel trends: Assumes the trend in the control group is an appropriate proxy for the trend in the treatment group, had the treatment not occurred. This way the mean difference can be accounted for without accounting for triend other than through the control group.  Model:\n\\[ \\begin{aligned} I_{T}\u0026amp;= \\begin{cases} 0, \u0026amp; \\text{Experienced Control} \\\\ 1, \u0026amp; \\text{Experienced Treatment} \\end{cases}\\\\ I_{Post}\u0026amp;= \\begin{cases} 0, \u0026amp;\\text{Before Time of Treatment}\\\\ 1, \u0026amp;\\text{After Time of Treatment} \\end{cases}\\\\ Y \u0026amp;= \\beta_0 + \\beta_1 I_{T} + \\beta_2 I_{Post} + \\beta_3 I_{T} I_{Post} \\end{aligned} \\]\nHere \\(\\beta_3\\) captures the treatment effect, \\(\\beta_0\\) captures the mean of the control group before the treatment was applied, \\(\\beta_1\\) captures the difference between the mean of the treatment group and the mean of the control group before treatment was applied, \\(\\beta_2\\) captures the difference in the control group mean after the treatment was applied due to confounds that are assumed to influence the control and treatment groups equivalently.\n Synthetic Control and Causal Impact Synthetic control approaches build a model of the counterfactual. Causal impact is a specific method for building a synthetic control, and was developed by Google – docs here.\nContext:\n Want to estimate the counterfactual for an observed timeseries, pre and post treatment.  Assumptions and requirements:\n Requires other time series related to the target time series Assumes the other time series are not influenced by the treatment, generally good candidates include; google trends time series, the weather, other countries or markets where no action was taken, unemployment indecies, stock prices, … .  Model:\n In pre period, train any kind of model to estimate the target time series as a function of the other time series. The model used in the Causal Impact package is a Bayesian structural time series model. Google’s Causal Impact method uses Bayesian structural time series to construct a counterfactual group – an estimate of what the time series would have looked like if the treatment had not been assigned. The method is described in this video. The method estimates a counterfactual using other related time series that were not influenced by the treatment. BSTS uses spike and slab prior for feature selection. In post period, use the model to estimate a counterfactual time series (i.e. synthetic control). Independent Python implementation here.  Benefits:\n Provides pointwise estimates of the causal effect over time, as well as a cumulative estimate (summing up the pointwise estimates) Bayesian approach, provides credible intervals   Synthetic Controls Context:\nAssumptions and requirements:\n Requires multiple related time series Assumes a linear combination of the related time sereis is a good proxy for the counterfactual  Model:\n Regress target time series on related time series Use estimates from this model as the counterfactual  When to use vs causal impact:\n The other time series are more conceptually identical - e.g. observed outcomes in untreated market segments subject to the same plausiable confounds – e.g. different nearby counties in a state. Causal impact might be better if the time series are thought to be components of the target – stock price, unemployment, page impressions, google trends, … .   IV Analysis More from Ben Lambert, good explanation here, part II. Case study using quarter and years of education as \\(Z\\) in place of education as the instrument [here](https://www.youtube.com/watch?v=pI9YGSJ2qPk, relation to 2SLS.\nMostly from Gelman chapter “Causal inference with more complicated observational designs” chapter from Gina.\nContext:\n Goal is to find the causal effect of \\(x\\rightarrow y\\). Issue: \\(Cov(x,\\epsilon)\\neq 0\\), a feature is correlated to unobserved confounds, so \\(\\hat{\\beta}_{OLS}\\) is unbiased and inconsistent.  Assumptions and Requirements:\n An instrument \\(z\\) is measured so it can be included in the model. \\(Cov(z,x)\\neq 0\\), the instrumental variable is related to \\(x\\). \\(Cov(z,\\epsilon)=0\\), the instrument is not correlated with unobserved confounds.  Model, 2 stage least squares:\nDone to address bias in \\(\\hat{\\beta}_{OLS}\\)\n\\[ \\begin{aligned} \\hat{x}\u0026amp;=\\gamma z + u \\\\ \\hat{y}\u0026amp;=\\beta_{IV} \\hat{x} + \\epsilon \\\\ \\beta_{IV} \u0026amp;= (Z^TX)^{-1}Z^TY = \\frac{Cov(Z,Y)}{Cov(Z,X)} \\end{aligned} \\]\nLimitation:\n \\(\\beta_{IV}\\) can still be biased, but is at least consistent (\\(\\beta_{IV}\\overset{p}{\\rightarrow} \\beta\\)).  This relates to the intent to treat (ITT) estimate, where the effect of assignment to the treatment group is consided \\(Z\\), but the effect of actually being treated \\(X\\) may not be known or estimated.\n Regression Discontinuity Context:\nSome systematic mechanism forces a discontinuity in what would be expected to be a regression line.\n E.g. 1: Yelp rounds star ratings so that businesses close in underlying rating (4.49 and 4.5 stars) are assigned to different conditions (4 and 4.5 starts). E.g. 2: Schools might filter on exam scores, so that students who are very similar in underlying ability or test score (1 point below the threshold vs at the threshold) might be assigned to different universities.   Fixed Effects Regression Context:\n Unobserved heterogineity \\(\\alpha_i\\) that is related to features, \\(Cov(\\alpha_i,x_{i,t})\\neq 0\\) Issue: \\(Cov(\\alpha_i,x_{i,t})\\neq 0\\), this implies that \\(\\hat{\\beta}\\) isn’t consistent for \\(\\beta\\), i.e. the sampling distribution of \\(\\hat{\\beta}\\) doesn’t converge to \\(\\beta\\).  Assumptions and Requirements:\n \\(Cov(x_{i,t},u_[i,t])=0\\), i.e. weak exogeniety No perfect correlation between \\(x\\). These assumptions imply the fixed effects estimates (\\(\\beta_{FE}\\)) are consistent.  Model, from here:\nThe procedure is to average over time to get \\(\\bar{y}_i\\), and subtract this off, taking advantage of \\(\\alpha_i=\\bar{\\alpha}_i\\) where the later is averaged across time.\n\\[ \\begin{aligned} \\alpha_i \u0026amp;: \\text{unobserved hetergenity} \\\\ Cov(\\alpha_i,x_{i,t}) \u0026amp;\\neq 0 \\\\ u_{i,t} \u0026amp;: \\text{error} \\\\ y_{i,t}\u0026amp;=\\beta x_{i,t} + \\alpha_i + u_{i,t}\\\\ \\bar{y}_{t}\u0026amp;=\\beta \\bar{x}_{i} + \\bar{\\alpha}_i + \\bar{u}_{i} \\\\ y_{i,t}-\\bar{y}_{t}\u0026amp;=\\beta_{FE} (x_{i,t}-\\bar{x}_{i}) + (\\alpha_i - \\bar{\\alpha}_i)+ u_{i,t} - \\bar{u}_{i} \\\\ \u0026amp;= \\beta_{FE} (x_{i,t}-\\bar{x}_{i}) + u_{i,t} - \\bar{u}_{i} \\\\ \\end{aligned} \\]\nLimitations:\n removes anything that is constant over time, meaning effects of any time-constant variables can’t be estimated   First differences Context:\n similar to fixed effects, but less asymptotically efficient if there are serially uncorrelated errors see this vid   Random Effects description in this video.\nContext:\nAssumptions and requirements:\nModel:\n Propensity Score Matching Context:\nTreatment assignment is non-random and might be related to the relationship between treatment and outcome. So you match people on their propensity to be assigned to treatment.\n Microsoft DoWhy  see docs     Efficient Inference More efficient studies require fewer resources (time, data) to reach a conclusion.\n Methods to reduce variance, Assessing the variance of estimators Efficient models  Efficient Sampling  Assigning at a point proximal to the experimental manipulation (see blogs in pinterest deep dive) …   Efficient Designs  Independent samples matching repeated measures   Efficient Models  Precision variables Estimands Wald test vs LRT vs Bayes vs Score test    Experiment Design Foundations  Hypotheses Treatment and control conditions assumptions (including CI assumptions, SUTVA, …?)   Concerns  network effects: front-end, it could be from different interactions, back-end it could be from changes in algorithm behavior for units in C based on different behavior from units in T – e.g. if a new recommender for units in T influences them to watch more of x, then x may also get recommended more to those in C. learning effects (change aversion, novelty seeking) early adopters Non-compliance: Those assicned to treatment may not actually experience the treatment. Crossover: Those assigned to control might gain access to the treatment. Treatment inhomogenaity: Some user segments might respond differently than others.   Treatment Units What is the unit at which we assign treatments?\nIdeally independent individuals, but online it is hard to know who is visiting a webpage, or crucial to keep experiences comparable across devices. Also, in networks, individuals are not independent and it is important to keep user experience consistent across connected individuals.\nProxies for individuals include;\n User ID or account – most clearly tied to a user, but cookies – device and browser specific, so these could differ across a user’s browsers or devices. IP address (device request return address) – device specific, so a user’s experience might differ across devices.  In networks, loosely connected clusters of individuals can be used as experimental units (see unofficial google data science blog post on this).\n a solution to SUTVA violations, but decreases sample size and power dramatically cluster-based, stratified, serial, balanced, … propensity scores and matching   Generative Model and Adjustment Variables  Specify the hypothesized generative process Confounds Precision Neusance   Common Designs A/B testing\nA/A testing to estimate variation\nVariance reduction designs (paired designs, matching, …)\nBandits for limited data or maximizing an objective\n Assignment Mechanism  maps samples (xi,yi) into treatment or control conditions. randomized control trials ideal, not always possible other options, …? test assignment validity, could use propensity scores or maybe chi square.   Duration  learning effects: initial exploration or novelty seeking learning effects: initial change aversion power analysis for sample size time to run to mitigate   Integrety Checks  check that those assigned to treatment received it check that stratifications were implemented correctly Check demographics across buckets, if randomization worked then demographics should be approximately equally represented in the buckets.   Maximum Likelihood versus Bayes’ Estimators likelihood is one term in Bayes’ Theorem\n  GLMs Again about the variance – this time it takes a form other than normal.\nlikelihood, score, fisher information, robust veriance, …?\n Common Tests t-test  different variance formulations. one-sample two independent sampels two dependent samples   ANOVA  Linear Model  Z test for proportions Binary data\n Chi-Square  Logistic Regression  Likelihood Ratio and Bayes Factors  always valid p-values (ck optimizely white paper)   Different Estimands For CI  Average treatment effect Treatment on treated   more on variance Emperical Variance Estimation bootstrapping\nA/A testing\n Mixed Effects Models  Maime’s consulting project? Other use cases?   Effiencicy or Variance Reduction  look up variance reduction in A/B tests, a common method might be to incorporate precision variables like demographic data or user data such as device or browser.  e.g. with a two sample t-test, \\(Y_t - Y_{t-1} = \\beta_0\\), versus a model \\(Y_t = \\beta_0 + \\beta_1 Y_{t-1}\\)\n get table for different tests of means from soc sci 10 notes.   GLMs Stats: descriptive, R-squared, chi-squared;\nProbability: distributions, CLT, sampling distributions, p-value,\nStats: k-s, Q-Q plot, hypothesis testing, experimentation;\nProbability: Bayes, bootstrap\nProbability: maximum likelihood estimation; time series analysis (ARIMA models), granger causality\nDynamic experimentation (multi-armed bandits)\nUnit testing; EDA visualization (seaborn, Plotly, Bokeh)\n  Causal Inference Methods Good medium blog post here\nFor each mention the assumptions and the model.\nDifference in Differences  Causal Impact  Synthetic Controls  Propensity Score Matching  Fixed Effects Regression  Instrumental variables  Regression Discontinuity   ","date":1580032586,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580032586,"objectID":"43df0444d46eec733f47693a8bf6992f","permalink":"/MacStrelioff/data-science/probability-statistics/","publishdate":"2020-01-26T09:56:26Z","relpermalink":"/MacStrelioff/data-science/probability-statistics/","section":"data-science","summary":"Probability Foundations Probability Rules Probability Functions Transformations of Random Variables Expectation Variance Information Theory Causal Graphs  Causal Inference Framework Key Assumptions Common Methods Diff in Diff Synthetic Control and Causal Impact Synthetic Controls IV Analysis Regression Discontinuity Fixed Effects Regression First differences Random Effects Propensity Score Matching Microsoft DoWhy   Efficient Inference Efficient Sampling Efficient Designs Efficient Models  Experiment Design Foundations Concerns Treatment Units Generative Model and Adjustment Variables Common Designs Assignment Mechanism Duration Integrety Checks Maximum Likelihood versus Bayes’ Estimators  GLMs Common Tests t-test ANOVA Linear Model Z test for proportions Chi-Square Logistic Regression Likelihood Ratio and Bayes Factors always valid p-values (ck optimizely white paper)  Different Estimands For CI more on variance Emperical Variance Estimation Mixed Effects Models Effiencicy or Variance Reduction GLMs  Causal Inference Methods Difference in Differences Causal Impact Synthetic Controls Propensity Score Matching Fixed Effects Regression Instrumental variables Regression Discontinuity    Probability Foundations A random variable is a variable with an unknown value, but known possible values.","tags":null,"title":"Probability and Statistics (DRAFT)","type":"data-science"},{"authors":null,"categories":null,"content":"  Important Features Pre-approval Places I like   Important Features  Proximity to Pinterest, 505 Brannan St, San Francisco, CA 94107 In unit washer and dryer Wood floors   Pre-approval  Places I like  888 7th street\n Possibly 766 Harrison Street, Apt 405\n   ","date":1574947638,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574947638,"objectID":"018b3eb58c70de91544f4a475e807685","permalink":"/MacStrelioff/unlisted/home_buying/","publishdate":"2019-11-28T13:27:18Z","relpermalink":"/MacStrelioff/unlisted/home_buying/","section":"Unlisted","summary":"  Important Features Pre-approval Places I like   Important Features  Proximity to Pinterest, 505 Brannan St, San Francisco, CA 94107 In unit washer and dryer Wood floors   Pre-approval  Places I like  888 7th street\n Possibly 766 Harrison Street, Apt 405\n   ","tags":null,"title":"Buying a Condo","type":"Unlisted"},{"authors":null,"categories":null,"content":"  Background and Setup Twitter Data Pulling Data from Twitter’s API Working with Twitter Status objects Embed a Status Convert a Status to a dict Access Status Attributes (How I accessed the data used below)  Poisson Process Assumptions Specification and Properties Checking the Homogeneity Assumption Checking the exponential distribution of intervals  Model of Tweet Fequency Using Conjugacy Inference On Tweet Rate \\(\\lambda\\) Over Time  Predicting Number Of Tweets In Interval \\(s\\) Summary   Background and Setup In this notebook I focus on explaining Poisson processes and conjugacy applied to my Twitter activity.\nTo get started, I followed directions from three main sources that walked through the twitter and python-twitter libraries, and described how to apply for Twitter API access and use the keys;\npython-twitter: Blogpost here tweepy: Blogpost here and docs here Additional information on obtaining API keys and authenticating Twitter connections in a blogpost here  I include my code to import the required libraries and set up API access keys, though the data used here were pulled and saved before writing the notebook. The main focus is on understanding Poisson processes and adaptive modeling of such processes using conjucacy.\nlibrary(reticulate) ## Warning: package \u0026#39;reticulate\u0026#39; was built under R version 3.5.2 # Setup # for working with timestamps import pandas as pd from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() # for basic math import numpy as np # for plotting import matplotlib.pyplot as plt import seaborn as sns # for working with distributions from scipy.stats import expon,gamma,poisson,nbinom # for general web data pulling import requests # for pulling tweets from Twitter API import twitter # keys for twitter API # (removed for this public document) api = twitter.Api(consumer_key=\u0026#39;\u0026#39;, consumer_secret=\u0026#39;\u0026#39;, access_token_key=\u0026#39;\u0026#39;, access_token_secret=\u0026#39;\u0026#39;) # for saving and loading Python objects like dicts import pickle def save_obj(obj, name): with open(name + \u0026#39;.pkl\u0026#39;, \u0026#39;wb\u0026#39;) as f: pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL) def load_obj(name): with open(name + \u0026#39;.pkl\u0026#39;, \u0026#39;rb\u0026#39;) as f: return pickle.load(f)  Twitter Data Pulling Data from Twitter’s API First I pulled data using the code below. For this code to work, your API keys will need to be specified in the setup above. To conceil my keys, I ran the commented code below earlier and saved the timeline object. The uncommented code loads my timeline and looks at the first element. The timeline is represented as a list of Status objects like the one output by the code below.\n# # Twitter handel to pull data from # handle = \u0026#39;@macstrelioff\u0026#39; # # # get timeline # timeline=api.GetUserTimeline(screen_name = handle, # count=200, # 200 is maximum # include_rts=True, # trim_user=True, # exclude_replies=False) # # # save timeline object # save_obj(timeline,\u0026#39;timeline_macstrelioff_20190406\u0026#39;) # load timeline object timeline=load_obj(\u0026#39;timeline_macstrelioff_20190406\u0026#39;) timeline[0] # most recent tweet status object \u0026gt;\u0026gt;\u0026gt; Status(ID=1113860296458756097, ScreenName=None, Created=Thu Apr 04 17:46:03 +0000 2019, Text=\u0026quot;@vboykis df.dropna(how=\u0026#39;brute force\u0026#39;) https://t.co/QOULUc5a0u\u0026quot;)  Working with Twitter Status objects I cover three ways to work with Status objects. 1. display the Status as a tweet! 2. Convert the Status to a dictionary and access values from keys 3. Access values directly as attributes of the Status\n Embed a Status First, many the Status attributes (created_at, favorite_count, text, …) can be cleanly displayed as a tweet embedded in a notebook. Below I create function that takes a username and tweet ID then, using Twitter’s embedding API, displayes the tweet as it would be seen on Twitter. (Note: this will only work properly if the Python kernel is trusted)\n# for displaying tweets based on username and tweet_id class disp_tweet(object): def __init__(self, user_name, tweet_id): # see: https://dev.twitter.com/web/embedded-tweets api = \u0026#39;https://publish.twitter.com/oembed?url=https://twitter.com/\u0026#39;+ \\ user_name + \u0026#39;/status/\u0026#39; + tweet_id response = requests.get(api) self.text = response.json()[\u0026quot;html\u0026quot;] def _repr_html_(self): return self.text disp_tweet(user_name=\u0026#39;macstrelioff\u0026#39;,tweet_id=\u0026#39;981338927419109376\u0026#39;) \u0026gt;\u0026gt;\u0026gt; \u0026lt;__main__.disp_tweet object at 0x1a26d06710\u0026gt; If run from a Jupyter notebook, this should embed a tweet as below;\nMy desk is covered in random papers. It is the support of a stationery distribution. — mac strelioff (@macstrelioff) April 4, 2018    Convert a Status to a dict Status objects have a bound method, .AsDict(), that will convert them to a Python dictionary. This way the structure of the information is easily seen. In the code below, I convert the first status to a dictionary and output it contents.\nprint(timeline[0].AsDict()) \u0026gt;\u0026gt;\u0026gt; {\u0026#39;created_at\u0026#39;: \u0026#39;Thu Apr 04 17:46:03 +0000 2019\u0026#39;, \u0026#39;favorite_count\u0026#39;: 20, \u0026#39;hashtags\u0026#39;: [], \u0026#39;id\u0026#39;: 1113860296458756097, \u0026#39;id_str\u0026#39;: \u0026#39;1113860296458756097\u0026#39;, \u0026#39;in_reply_to_screen_name\u0026#39;: \u0026#39;vboykis\u0026#39;, \u0026#39;in_reply_to_status_id\u0026#39;: 1113822568211996672, \u0026#39;in_reply_to_user_id\u0026#39;: 19304217, \u0026#39;lang\u0026#39;: \u0026#39;da\u0026#39;, \u0026#39;media\u0026#39;: [{\u0026#39;display_url\u0026#39;: \u0026#39;pic.twitter.com/QOULUc5a0u\u0026#39;, \u0026#39;expanded_url\u0026#39;: \u0026#39;https://twitter.com/macstrelioff/status/1113860296458756097/photo/1\u0026#39;, \u0026#39;id\u0026#39;: 1113860285566046210, \u0026#39;media_url\u0026#39;: \u0026#39;http://pbs.twimg.com/tweet_video_thumb/D3U6BzqUUAIwYEC.jpg\u0026#39;, \u0026#39;media_url_https\u0026#39;: \u0026#39;https://pbs.twimg.com/tweet_video_thumb/D3U6BzqUUAIwYEC.jpg\u0026#39;, \u0026#39;sizes\u0026#39;: {\u0026#39;thumb\u0026#39;: {\u0026#39;w\u0026#39;: 150, \u0026#39;h\u0026#39;: 150, \u0026#39;resize\u0026#39;: \u0026#39;crop\u0026#39;}, \u0026#39;large\u0026#39;: {\u0026#39;w\u0026#39;: 250, \u0026#39;h\u0026#39;: 198, \u0026#39;resize\u0026#39;: \u0026#39;fit\u0026#39;}, \u0026#39;medium\u0026#39;: {\u0026#39;w\u0026#39;: 250, \u0026#39;h\u0026#39;: 198, \u0026#39;resize\u0026#39;: \u0026#39;fit\u0026#39;}, \u0026#39;small\u0026#39;: {\u0026#39;w\u0026#39;: 250, \u0026#39;h\u0026#39;: 198, \u0026#39;resize\u0026#39;: \u0026#39;fit\u0026#39;}}, \u0026#39;type\u0026#39;: \u0026#39;animated_gif\u0026#39;, \u0026#39;url\u0026#39;: \u0026#39;https://t.co/QOULUc5a0u\u0026#39;, \u0026#39;video_info\u0026#39;: {\u0026#39;aspect_ratio\u0026#39;: [125, 99], \u0026#39;variants\u0026#39;: [{\u0026#39;bitrate\u0026#39;: 0, \u0026#39;content_type\u0026#39;: \u0026#39;video/mp4\u0026#39;, \u0026#39;url\u0026#39;: \u0026#39;https://video.twimg.com/tweet_video/D3U6BzqUUAIwYEC.mp4\u0026#39;}]}}], \u0026#39;retweet_count\u0026#39;: 2, \u0026#39;source\u0026#39;: \u0026#39;\u0026lt;a href=\u0026quot;http://twitter.com/download/android\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter for Android\u0026lt;/a\u0026gt;\u0026#39;, \u0026#39;text\u0026#39;: \u0026quot;@vboykis df.dropna(how=\u0026#39;brute force\u0026#39;) https://t.co/QOULUc5a0u\u0026quot;, \u0026#39;urls\u0026#39;: [], \u0026#39;user\u0026#39;: {\u0026#39;id\u0026#39;: 70255183, \u0026#39;id_str\u0026#39;: \u0026#39;70255183\u0026#39;}, \u0026#39;user_mentions\u0026#39;: [{\u0026#39;id\u0026#39;: 19304217, \u0026#39;id_str\u0026#39;: \u0026#39;19304217\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Vicki Boykis\u0026#39;, \u0026#39;screen_name\u0026#39;: \u0026#39;vboykis\u0026#39;}]} {\u0026#39;created_at\u0026#39;: \u0026#39;Thu Apr 04 17:46:03 +0000 2019\u0026#39;, \u0026#39;favorite_count\u0026#39;: 20, \u0026#39;hashtags\u0026#39;: [], \u0026#39;id\u0026#39;: 1113860296458756097, \u0026#39;id_str\u0026#39;: \u0026#39;1113860296458756097\u0026#39;, \u0026#39;in_reply_to_screen_name\u0026#39;: \u0026#39;vboykis\u0026#39;, \u0026#39;in_reply_to_status_id\u0026#39;: 1113822568211996672, \u0026#39;in_reply_to_user_id\u0026#39;: 19304217, \u0026#39;lang\u0026#39;: \u0026#39;da\u0026#39;, \u0026#39;media\u0026#39;: [{\u0026#39;display_url\u0026#39;: \u0026#39;pic.twitter.com/QOULUc5a0u\u0026#39;, \u0026#39;expanded_url\u0026#39;: \u0026#39;https://twitter.com/macstrelioff/status/1113860296458756097/photo/1\u0026#39;, \u0026#39;id\u0026#39;: 1113860285566046210, \u0026#39;media_url\u0026#39;: \u0026#39;http://pbs.twimg.com/tweet_video_thumb/D3U6BzqUUAIwYEC.jpg\u0026#39;, \u0026#39;media_url_https\u0026#39;: \u0026#39;https://pbs.twimg.com/tweet_video_thumb/D3U6BzqUUAIwYEC.jpg\u0026#39;, \u0026#39;sizes\u0026#39;: {\u0026#39;thumb\u0026#39;: {\u0026#39;w\u0026#39;: 150, \u0026#39;h\u0026#39;: 150, \u0026#39;resize\u0026#39;: \u0026#39;crop\u0026#39;}, \u0026#39;large\u0026#39;: {\u0026#39;w\u0026#39;: 250, \u0026#39;h\u0026#39;: 198, \u0026#39;resize\u0026#39;: \u0026#39;fit\u0026#39;}, \u0026#39;medium\u0026#39;: {\u0026#39;w\u0026#39;: 250, \u0026#39;h\u0026#39;: 198, \u0026#39;resize\u0026#39;: \u0026#39;fit\u0026#39;}, \u0026#39;small\u0026#39;: {\u0026#39;w\u0026#39;: 250, \u0026#39;h\u0026#39;: 198, \u0026#39;resize\u0026#39;: \u0026#39;fit\u0026#39;}}, \u0026#39;type\u0026#39;: \u0026#39;animated_gif\u0026#39;, \u0026#39;url\u0026#39;: \u0026#39;https://t.co/QOULUc5a0u\u0026#39;, \u0026#39;video_info\u0026#39;: {\u0026#39;aspect_ratio\u0026#39;: [125, 99], \u0026#39;variants\u0026#39;: [{\u0026#39;bitrate\u0026#39;: 0, \u0026#39;content_type\u0026#39;: \u0026#39;video/mp4\u0026#39;, \u0026#39;url\u0026#39;: \u0026#39;https://video.twimg.com/tweet_video/D3U6BzqUUAIwYEC.mp4\u0026#39;}]}}], \u0026#39;retweet_count\u0026#39;: 2, \u0026#39;source\u0026#39;: \u0026#39;\u0026lt;a href=\u0026quot;http://twitter.com/download/android\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter for Android\u0026lt;/a\u0026gt;\u0026#39;, \u0026#39;text\u0026#39;: \u0026quot;@vboykis df.dropna(how=\u0026#39;brute force\u0026#39;) https://t.co/QOULUc5a0u\u0026quot;, \u0026#39;urls\u0026#39;: [], \u0026#39;user\u0026#39;: {\u0026#39;id\u0026#39;: 70255183, \u0026#39;id_str\u0026#39;: \u0026#39;70255183\u0026#39;}, \u0026#39;user_mentions\u0026#39;: [{\u0026#39;id\u0026#39;: 19304217, \u0026#39;id_str\u0026#39;: \u0026#39;19304217\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Vicki Boykis\u0026#39;, \u0026#39;screen_name\u0026#39;: \u0026#39;vboykis\u0026#39;}]}  Access Status Attributes (How I accessed the data used below) Since I’m interested in modeling expected number of tweets in a week, the most relevant attribute is the timestamps in the created_at attribute. These attributes can be accessed directly from the Status object. Below I make a list of the times at which each tweet was created and check the first element of that list;\n# get list of time stamps times = [pd.Timestamp(tweet.created_at) for tweet in timeline] times.reverse() # sort s.t. times[0] is lowest, times[-1] is highest times[0] \u0026gt;\u0026gt;\u0026gt; Timestamp(\u0026#39;2018-11-01 05:56:58+0000\u0026#39;, tz=\u0026#39;tzutc()\u0026#39;) This creates a list of timestamps. By default, times from the twitter API are localized to the UTC timezone. Below I convert these to my local time in California;\ntimes = [time.tz_convert(\u0026quot;America/Los_Angeles\u0026quot;) for time in times] times[0] \u0026gt;\u0026gt;\u0026gt; Timestamp(\u0026#39;2018-10-31 22:56:58-0700\u0026#39;, tz=\u0026#39;America/Los_Angeles\u0026#39;) Now we have a list of timestamps in local time! To get a sense of the duration over which this data spans, below I compute the time difference between the frist and last timestamp;\ntimes[-1]-times[0] \u0026gt;\u0026gt;\u0026gt; Timedelta(\u0026#39;154 days 11:49:05\u0026#39;) Woah, almost 155 days of my twitter activity!\n  Poisson Process A Poisson process is a common framework for modeling events that occurr in time or space. In this context, tweets are being created over time and we are interested in modeling the rate at which tweets are created in order to predict how many tweets will be created in a week.\nAssumptions No more than one event can occur at a single point in time.  This can be violated when a user publishes a thread of multiple tweets at once. This can be fixed by recoding threads as a single status.  Independence: The interval lengths for each event are not influenced by any other event.  This can be violated if, instead of using Twitter’s thread option, a user ends a tweet with “…” to indicate that they will soon create another tweet. In this case, there are some tweets that imply a shorter interval before the next tweet.  Homogeneity: The distribution of intervals is the same throughout the entire process.  I probe this assumption in depth below, and it almost certainly violated. There are methods for modeling inhomogeneous Poisson processes, but I ignore those here.    Specification and Properties In this context tweet events are occurring across time. I index tweets with \\(i\\in\\{1,...,N\\}\\), where \\(N\\) is the total number of tweets observed. Each tweet is created at a time, \\(t_i\\), and the next tweet is observed after an interval \\(s_{i}\\). That is, if tweet \\(i\\) is created at time \\(t_{i-1}\\) then tweet \\(i+1\\) is created at time \\(t_{i}=t_{i-1}+s_{i}\\). The interval between each tweet is \\(s_i = t_{i}-t_{i-1} = (t_{i-1}+s_i)-t_{i-1}\\). The assumptions of a Poisson process permit the following distributions for three interesting features of this scenario.\nThe distribution of time between events, \\(s_i\\), is exponential; \\(s_i\\sim Expo(\\lambda) \\Rightarrow p(s_i|\\lambda) = \\lambda e^{-\\lambda s_i}\\)  Here \\(\\lambda\\) is a parameter that describes the tweet rate.  Given an interval of length \\(s\\), the distribution of the count of events in that interval, \\(c|s\\), is Poisson; \\(c|s\\sim Poisson(\\lambda s) \\Rightarrow p(c|s,\\lambda) = \\frac{(\\lambda s)^{c}e^{-\\lambda s}}{c!}\\)  The count of events, \\(c\\), in a fixed interval depends both on the rate of the events, \\(\\lambda\\), and the duration of the interval, \\(s\\).  The distribution of the total interval required for \\(c\\) events, \\(s|c\\), is gamma; \\(s|c \\sim Gamma(c,\\lambda) \\Rightarrow p(s|c,\\lambda) = \\frac{\\lambda^c}{\\Gamma(c)}(s)^{c-1}e^{-\\lambda s}\\)  The interval, \\(s\\), required for a fixed number of events depends on both the rate of the events, \\(\\lambda\\), and the number of events, \\(c\\).   More information on these three kinds of distributions, and ways to implement them in Python, can be found in the scipy documentation on statistical functions. General information on each of these distributions can be found on the Wikipedia page for the exponential, Poisson, or gamma distribution. A key difference between the standard uses of these distributions and their roles in a Poisson process is that the rate parameter \\(\\lambda\\) is also scaled by the duration of an interval \\(s\\) when constructing a distribution for the count of events in interval \\(s\\) (2, above) or the duration of the interval required for \\(c\\) events (3, above).\n Checking the Homogeneity Assumption The homogeneity assumption strictly requires that tweet rates are constant across time. This would generate data that are uniform across meaningful intervals such as time in a week or time in a day. To check homogeneity, below I convert the timestamps into the hour within a week, minute within a day, and minute within an hour, and plot tweet counts across these representations of time.\n# convert to hours in a week hour_of_week = [t.weekday()*24+t.hour+t.minute/60 for t in times] minute_of_day = [t.hour*60+t.minute+t.second/60 for t in times] minute_of_hour = [t.minute+t.second/60 for t in times] plt.figure(figsize=(10,4)); plt.hist(hour_of_week,bins=80); plt.title(\u0026quot;My Tweet Counts By Hour Of Week\u0026quot;); plt.ylabel(\u0026quot;Count\u0026quot;); plt.xlabel(\u0026quot;Hour In Week\u0026quot;); The histogram above indicates that there might be some hours of the week that have a higher rate than others. For example, I don’t seem to tweet much early on Sunday (hours 0-5), but I do seem to tweet a lot during the day on Sunday (around hours 6-20). Below I use rug plots, which represent a tweet event with a vertical line near the x-axis, and an imposed kernel density estimate, which is a continuous version of a histogram. I remake this plot in terms of hours within a week, minutes within a day, and minutes within an hour. If the tweet rate (\\(\\lambda\\)) were homogeneous, then the kernel density estimate would be approximately flat.\ndef rug_plot_and_density(dat,bw,xlab,xlim): # rug plot + density plt.figure(figsize=(10,4)) sns.distplot(dat, hist = False, kde = True, rug = True, color = \u0026#39;darkblue\u0026#39;, kde_kws={\u0026#39;linewidth\u0026#39;: 3,\u0026quot;bw\u0026quot;:bw}, rug_kws={\u0026#39;color\u0026#39;: \u0026#39;black\u0026#39;}) # formatting plt.title(\u0026#39;Tweet Density By \u0026#39;+xlab) plt.xlabel(xlab) plt.ylabel(\u0026#39;Kernel Density\u0026#39;) plt.xlim(xlim); plt.show() # data and plot formatting arguments dats = (hour_of_week,minute_of_day,minute_of_hour) xlabs=(\u0026#39;Hour of Week\u0026#39;,\u0026#39;Minute of Day\u0026#39;,\u0026#39;Minute of Hour\u0026#39;) xlims=([0,24*7],[0,24*60],[0,60]); bws = (4,40,4) # make plots for dat,xlab,xlim,bw in zip(dats,xlabs,xlims,bws): rug_plot_and_density(dat=dat,bw=bw,xlab=xlab,xlim=xlim) Are very sensitive to the choice of the bandwidth parameter that determines the window over which to aggregate events (similar to bin size when using a histogram). I’m using these plots to demonstrate possible violations of homogeneity that I would follow up on in a real analysis, but will not follow up on here.\nFrom the top plot, there seems to be two patterns. First, a series of peaks and troughs that roughly correspond to daytime and night-time hours. I probably tweet with a higher frequency when I am awake, rather than asleep – meaning that \\(\\lambda\\) may depend on time within a day. Second, a generally lower kernel density estimate during the middle than the edges. I may tweet more during the weekends (edge hours) than week days (middle hours).\nFrom the middle plot that displays tweet frequencies by minutes within a day, there again seem to be two trends. First, I rarely tweet before minute 400 (around 6:40AM). Second, I have peaks around minute 600 (10:00AM), 1000 (4:40PM), and 1350 (10:00PM). This might be related to the times that I take a break from working. I generally take a break around 5:00PM, and usually take another break before bed around 9:00-10:00PM.\nThe bottom plot displays tweet frequencies by minutes within an hour. This seems more flat overall longer periods of time, but I may strangely tend to tweet more during the first half of hours.\nOverall, there are many reasons that the homogeneity assumption may be violated. For cases like this, the tweet rate \\(\\lambda\\) can be modeled as a function of time. However, to keep this example simple, I’ll ignore possible violations and proceede as if \\(\\lambda\\) were a constant with respect to time.\n Checking the exponential distribution of intervals Let’s the distribution of the time between tweets, \\(s_i\\). If the assumptions of the Poisson process were satisfied, then the intervals between tweets would follow an exponential distribution. Below I compute the number of seconds between tweets and display each value as a black dash on the x-axis. I overlay a histogram, a kernel density, and a exponential density based on the observed mean interval.\n# compute intervals between tweets ss = [times[i]-times[i-1] for i in range(1,len(times))]; # convert from Timedelta to total time in seconds ss = [si.total_seconds() for si in ss] # histogram and density plot plt.figure(figsize=(10,4)) sns.distplot(ss, hist = True, kde = True, rug = True, color = \u0026#39;darkblue\u0026#39;, bins=100, hist_kws={\u0026#39;color\u0026#39;:[0,.7,.5,.5],\u0026#39;label\u0026#39;:\u0026#39;Histogram\u0026#39;}, kde_kws={\u0026#39;linewidth\u0026#39;: 3,\u0026quot;bw\u0026quot;:60*60,\u0026#39;label\u0026#39;:\u0026#39;Kernel Density\u0026#39;}, rug_kws={\u0026#39;color\u0026#39;: \u0026#39;black\u0026#39;}) plt.xlim([0,680000]); plt.title(\u0026#39;Distribution of intervals between tweets\u0026#39;) plt.xlabel(\u0026#39;Seconds\u0026#39;) plt.ylabel(\u0026#39;Frequency\u0026#39;) # overlay an exponential density tmp_rate=np.mean(ss) tmpx = np.linspace(0,680000,680000*5) tmpy = expon.pdf(tmpx,scale=tmp_rate) plt.plot(tmpx,tmpy,color=[.7,0,0,1],linewidth=3,label=\u0026#39;Exponential Density\u0026#39;); # add legend plt.legend(); Based on the relative heights of the kernel density and the exponential density, there seem to be more short intervals, fewer moderate length intervals, and more long intervals relative to the exponential distribution. The mean and standard deviation of an exponential distribution should be the same value. Below I check the standard deviation and mean of the observed intervals.\n# check standard deviation np.std(ss),np.mean(ss),np.std(ss)/np.mean(ss) \u0026gt;\u0026gt;\u0026gt; (90150.9122414953, 67076.1055276382, 1.3440093388300445) The observed standard deviation is about 1.34 times larger (variance is about 1.80 times larger) than it would be if the data were exponentially distributed with the observed mean. While this could be accounted for with an overdispersion parameter, I will ignore this issue here for the sake of having a simple and fast online model.\n  Model of Tweet Fequency Using Conjugacy First, I’ll assume (despite the overdispersion) that the intervals between tweets follow an exponential distribution;\n\\[ \\begin{aligned} s_i|\\lambda \u0026amp;\\sim Expo(\\lambda) \\\\ \\Rightarrow p(s_i|\\lambda) \u0026amp;= \\lambda e^{-s_i \\lambda} \\end{aligned} \\]\nTo account for uncertainty in \\(\\lambda\\), I’ll use a Gamma distribution with shape \\(\\alpha\\) and rate \\(\\beta\\);\n\\[ \\begin{aligned} \\lambda \u0026amp;\\sim Gamma(\\alpha,\\beta) \\\\ \\Rightarrow p(\\lambda|\\alpha,\\beta) \u0026amp;= \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha-1}e^{-\\lambda \\beta} \\end{aligned} \\]\nThe choice of a Gamma distribution allows for fast updates using conjugacy between the prior beliefs about \\(\\lambda\\) based on data observed up to time \\(t\\) and the exponential likelihood for the interval observed at time \\(t\\);\n\\[ \\begin{aligned} \\lambda | s_t \u0026amp;\\sim Gamma(\\alpha_t,\\beta_t) \\\\ p(s_{t+1}|\\lambda) \u0026amp;= \\lambda e^{-s_{t+1} \\lambda} \\\\ p(\\lambda|\\alpha_t,\\beta_t,s_{t+1}) \u0026amp;\\propto p(s_{t+1}|\\lambda) p(\\lambda|\\alpha_t,\\beta_t) \\\\ \u0026amp;= \\lambda e^{-s_{t+1} \\lambda} \\frac{\\beta_t^{\\alpha_t}}{\\Gamma(\\alpha_t)} \\lambda^{\\alpha_t-1}e^{-\\lambda \\beta_t} \\\\ \u0026amp;= \\lambda^{\\alpha_t} e^{-\\lambda(s_{t+1}+\\beta_t)} \\\\ \\Rightarrow \\lambda | s_{t+1} \u0026amp;\\sim Gamma(\\alpha_t+1,\\beta_t+s_{t+1}) \\end{aligned} \\]\nThis implies the following update rules for computing the parameters of the posterior over \\(\\lambda\\);\n\\[ \\begin{aligned} \\alpha_{t+1} \u0026amp;\\leftarrow \\alpha_t +1 \\\\ \\beta_{t+1} \u0026amp;\\leftarrow \\beta_t + s_{t+1} \\\\ \\end{aligned} \\]\nTo answer the question of how many tweets might be observed in a period of time, I’ll assume that the count of tweets \\(c\\) is Poisson distributed with rate \\(\\lambda\\). Then the number of tweets expected in an interval of length \\(s\\) would be;\n\\[ \\begin{aligned} \\theta \u0026amp;= s\\lambda \\\\ c|\\theta \u0026amp;\\sim Poisson(\\theta) \\\\ \\Rightarrow p(c|\\theta) \u0026amp;= \\frac{\\theta^c e^{-\\theta}}{c!} \\end{aligned} \\]\nThis means that, rather than \\(\\lambda\\), we are actually interested in the distribution of \\(\\theta=s\\lambda\\). I derive this below using a change of vairables;\n\\[ \\begin{aligned} \\theta = s\\lambda \u0026amp;\\Rightarrow \\lambda = \\frac{\\theta}{s} = \\theta s^{-1} \\\\ p_\\theta(\\theta | \\lambda,s) \u0026amp;= p_\\lambda\\left(\\theta s^{-1} | s,\\alpha,\\beta\\right) \\left| \\frac{d \\lambda}{d \\theta}\\right|\\\\ \u0026amp;= \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\left(\\frac{\\theta}{s}\\right)^{\\alpha-1}e^{-\\frac{\\theta}{s}\\beta} \\left|s^{-1}\\right| \\\\ \u0026amp;= \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\theta^{(\\alpha-1)}s^{-({\\alpha-1})-1}e^{-\\frac{\\theta}{s}\\beta} \\\\ \\Rightarrow p(\\theta|s,\\alpha,\\beta)\u0026amp;= \\frac{\\left(\\frac{\\beta}{s}\\right)^\\alpha}{\\Gamma(\\alpha)} \\theta^{(\\alpha-1)}e^{-\\theta\\frac{\\beta}{s}}\\\\ \\end{aligned} \\]\nNow we can find the distribution of \\(c\\) that accounts for uncertainty in \\(\\theta\\) through the prior on \\(\\lambda\\);\n\\[ \\begin{aligned} p(c|s,\\alpha,\\beta) \u0026amp;= \\int_\\theta p(c|\\theta)p(\\theta|s,\\alpha,\\beta)d\\theta \\\\ \u0026amp;=\\int_\\theta \\frac{\\theta^c e^{-\\theta}}{c!} \\frac{\\left(\\frac{\\beta}{s}\\right)^\\alpha}{\\Gamma(\\alpha)} \\theta^{(\\alpha-1)}e^{-\\theta\\frac{\\beta}{s}} d\\theta \\\\ \u0026amp;= \\frac{\\left(\\frac{\\beta}{s}\\right)^\\alpha}{c!\\Gamma(\\alpha)} \\int_\\theta \\theta^c e^{-\\theta} \\theta^{(\\alpha-1)}e^{-\\theta\\frac{\\beta}{s}} d\\theta \\\\ \u0026amp;=\\frac{\\left(\\frac{\\beta}{s}\\right)^\\alpha}{c!\\Gamma(\\alpha)} \\int_\\theta \\theta^{c+\\alpha-1} e^{-\\theta\\left(\\frac{\\beta+s}{s}\\right)} d\\theta \\\\ \u0026amp;=\\frac{\\left(\\frac{\\beta}{s}\\right)^\\alpha}{c!\\Gamma(\\alpha)} \\frac{\\Gamma(c+\\alpha)}{\\left(\\frac{\\beta+s}{s}\\right)^{c+\\alpha}} \\\\ \u0026amp;=\\frac{\\Gamma(c+\\alpha)}{c!\\Gamma(\\alpha)} \\beta^\\alpha s^{-\\alpha} s^{c+\\alpha} (\\beta+s)^{-(c+\\alpha)} \\\\ \u0026amp;=\\frac{\\Gamma(c+\\alpha)}{\\Gamma(c+1)\\Gamma(\\alpha)} \\left(\\frac{s}{\\beta+s}\\right)^c \\left(\\frac{\\beta}{\\beta+s}\\right)^\\alpha \\\\ \\end{aligned} \\]\nSince a Poisson Process assumes that no more than one event can occur in an interval, intervals can be treated as discrete Bernoulli trials in which an event either occurs or does not occur. In this discrete setting, the distribution of the count of intervals with an event \\(k\\) for a given number of intervals without the event \\(r\\) and a probability of the event in each interval \\(p\\) will follow a negative binomial distribution;\n\\[ \\begin{aligned} k \u0026amp;\\sim NegBino(r,p) \\\\ \\Rightarrow p(k|r,p) \u0026amp;= \\frac{(k+r-1)!}{r! (k-1)!}p^{k}(1-p)^{r} \\\\ \u0026amp;= \\frac{\\Gamma(k+r)}{\\Gamma(r+1) \\Gamma(k)}p^{k}(1-p)^{r} \\\\ \\end{aligned} \\]\nCombining the two results above, we see that the count \\(c\\) in an interval \\(s\\) will follow a negative binomial distribution such that \\(\\alpha\\) fixes the number of intervals in which no event occurs, and \\(\\frac{s}{\\beta+s}\\) captures the probability of an event in any unit length interval;\n\\[ \\begin{aligned} c \u0026amp;\\sim NegBino\\left(\\alpha,\\frac{s}{\\beta+s}\\right) \\\\ \\Rightarrow p(c|s,\\alpha,\\beta) \u0026amp;= \\frac{\\Gamma(c+\\alpha)}{\\Gamma(c+1)\\Gamma(\\alpha)} \\left(\\frac{s}{\\beta+s}\\right)^c \\left(\\frac{\\beta}{\\beta+s}\\right)^\\alpha \\\\ \\end{aligned} \\]\nIn summary, the key components of this model are the exponential likelihood and gamma priors which allow for the fast and simple updating rules to compute the posterior over \\(\\lambda\\), and the negative binomial predictive distribution which accounts for the uncertainty in \\(\\lambda\\). So the applicable information from above is;\n\\[ \\begin{aligned} \\lambda \u0026amp;\\sim Gamma(\\alpha_t,\\beta_t) \\\\ s_{t+1} \u0026amp;\\sim Expo(\\lambda) \\\\ \\alpha_{t+1} \u0026amp;\\leftarrow \\alpha_t + 1 \\\\ \\beta_{t+1} \u0026amp;\\leftarrow \\beta_t + s_{t+1} \\\\ c|s,\\alpha,\\beta \u0026amp;\\sim NegBino\\left(\\alpha,\\frac{s}{\\beta+s}\\right) \\\\ \\end{aligned} \\]\nHere I investigate posterior predictive intervals for tweets over a period of time \\(s\\) while using different components of this model. In the code below, I compute all values of \\(\\alpha\\) and \\(\\beta\\) based on the update rules derived above from conjugacy.\n# initialize alpha,beta as 0 alpha,beta = 0,0 alphas,betas = list(),list() # for each observed interval in ss, for si in ss: si = si/(60*60*24) # si s/1 * 1/60 m/s * 1/60 h/m * 1/24 d/h convert to days alpha+=1 # increment alpha by 1 beta+=si # increment beta by the interval length # save parameters for analysis alphas.append(alpha) betas.append(beta) The code above converts intervals from seconds to days and comptutes \\(\\alpha\\) and \\(\\beta\\) for all intervals in my dataset. This gives the parameters for posterior beliefs over \\(\\lambda\\) as each tweet is observed. Below I check the final parameters and some statistics from the last posterior.\na,b,mode,median,mean=(alpha,beta,(alpha-1)/beta,gamma.ppf(.5,a=alpha,scale=1/beta),alpha/beta) print( \u0026#39;alpha : \u0026#39;+str(a)+ \u0026#39;\\nbeta : \u0026#39;+str(b)+ \u0026#39;\\nmode : \u0026#39;+str(mode)+ \u0026#39;\\nmedian: \u0026#39;+str(median)+ \u0026#39;\\nmean : \u0026#39;+str(mean)) \u0026gt;\u0026gt;\u0026gt; alpha : 199 \u0026gt;\u0026gt;\u0026gt; beta : 154.49241898148153 \u0026gt;\u0026gt;\u0026gt; mode : 1.2816162845099446 \u0026gt;\u0026gt;\u0026gt; median: 1.2859321345366828 \u0026gt;\u0026gt;\u0026gt; mean : 1.2880890940276715 The value of \\(\\alpha\\) correctly indicates 199 observed intervals, and the \\(\\beta\\) of 154.59 also correctly reflects the time difference in days that was computed in the first section. Lastly the ordinal relationship of the mode, median, and mean is consistent with that of a gamma distribution.\nInference On Tweet Rate \\(\\lambda\\) Over Time In the code below, I compute the maximum a posteriori (MAP) estimate, or posterior mode, across time. I plot this across time with the 97.5\\(^{th}\\) and 2.5\\(^{th}\\) percentiles as a shaded region representing the 95% credible interval.\n# get MAP lambda lambda_map = [(alpha-1)/beta for alpha,beta in zip(alphas,betas)] # get CI upper and lower bounds lambda_upper = [gamma.ppf(.975,a=alpha,scale=1/beta) for alpha,beta in zip(alphas,betas)] lambda_lower = [gamma.ppf(.025,a=alpha,scale=1/beta) for alpha,beta in zip(alphas,betas)] # plot over time plt.figure(figsize=(10,4)) plt.plot(times[1:],lambda_map,color=[0,0,1],label=\u0026#39;MAP\u0026#39;); plt.fill_between(times[1:], lambda_lower, lambda_upper,color=[0,0,1,.1],label=\u0026#39;95% CI\u0026#39;) #sns.distplot(times[1:], hist = False, kde = False, rug = True, # color = \u0026#39;darkblue\u0026#39;, # rug_kws={\u0026#39;color\u0026#39;: \u0026#39;black\u0026#39;}); plt.ylabel(\u0026#39;Posterior on Lambda (tweets/day)\u0026#39;) plt.xlabel(\u0026#39;Time\u0026#39;) plt.title(\u0026#39;Summary of the posterior over $\\lambda$ across time\u0026#39;) plt.legend(); The posterior seems to tighten dramatically around the mode during the first month, and the mode seems to stabalize after about that much time. However, this method seems slow to adjust to the slower rate of tweets in 2019. One way to address this might be to add weights to the parameter updates such that \\(\\alpha\\) and \\(\\beta\\) are more sensitive to recent data than past data. These weights (or stepsize or learning rates) can be based on the surprisal, or likelihood, of a new tweet under the posterior. If the new interval was well anticipated, then little updating is needed, but if the new interval was very surprising or unlikely, then a sharpe change in \\(\\alpha\\) and \\(\\beta\\) might be warrented.\n  Predicting Number Of Tweets In Interval \\(s\\) Now I’ll visually compare predictions for the count of tweets in a week based on estimates of \\(\\lambda\\) after the first 20 tweets and using all 200 tweets, using two models;\nA Poisson using \\(\\theta=s\\lambda_{MAP}\\) The negative binomial derived in the model section above  First, an issue with the parameterization of the negative binomial has to be addressed. In my derivation, I ended with a negative binomial parameterized as;\n\\[ \\begin{aligned} k\u0026amp;:\\text{Number of successes} \\\\ r\u0026amp;:\\text{Number of failures} \\\\ p\u0026amp;:\\text{Probability of failure} \\\\ p(k|r,p) \u0026amp;= \\frac{(k+r-1)!}{r! (k-1)!}p^{k}(1-p)^{r} \\\\ \\end{aligned} \\]\nThe Scipy.stats.nbinom function defines a negative binomial with;\n\\[ \\begin{aligned} k\u0026amp;:\\text{Number of failures} \\\\ n\u0026amp;:\\text{Number of successes} \\\\ p\u0026amp;:\\text{Probability of success} \\\\ p(k|n,p) \u0026amp;= \\frac{(k+n-1)!}{(n-1)!k!} p^{n}(1-p)^{k} \\end{aligned} \\]\nRecall in my derivation that the parameter corresponding to probability of failure was \\(p=\\frac{s}{\\beta+s}\\). The differences in parameterization can be accounted for by supplying the nbinom function with \\(p=1-\\frac{s}{\\beta+s}=\\frac{\\beta}{\\beta+s}\\).\nThe code below plots predictive densities based on the two approaches above from estimates of \\(\\lambda\\) based only on the first 20 observations.\n# for the first 20 tweets # parameters cs = range(20) s = 7 index = 19 theta = s*lambda_map[index] plt.figure(figsize=(10,4)) # plot the Poisson density plt.scatter(cs,poisson.pmf(cs,theta)) plt.plot( cs,poisson.pmf(cs,theta),label=\u0026#39;Poisson\u0026#39;) # plot the negative binomial density plt.scatter(cs,nbinom.pmf(cs,n=alphas[index],p=betas[index]/(s+betas[index]))) plt.plot( cs,nbinom.pmf(cs,n=alphas[index],p=betas[index]/(s+betas[index])),label=\u0026#39;Negative Binomial\u0026#39;); # labels plt.ylabel(\u0026#39;Mass\u0026#39;) plt.xlabel(\u0026#39;Count\u0026#39;) plt.title(\u0026#39;Predictions for Tweet Counts in a Week, Using 20 Observations\u0026#39;) plt.legend(); With a small amount of data, the uncertainty in the estimate of tweet rates carries through the negative binomial model, which gives more mass to a wider range of counts relative to the Poisson model that discards uncertainty when by \\(\\lambda_{MAP}\\).\n# Using all data # parameters index = 198 theta = s*lambda_map[index] plt.figure(figsize=(10,4)) # plot the Poisson density plt.scatter(cs,poisson.pmf(cs,theta)) plt.plot( cs,poisson.pmf(cs,theta),label=\u0026#39;Poisson\u0026#39;) # plot the negative binomial density plt.scatter(cs,nbinom.pmf(cs,n=alphas[index],p=betas[index]/(s+betas[index]))) plt.plot( cs,nbinom.pmf(cs,n=alphas[index],p=betas[index]/(s+betas[index])),label=\u0026#39;Negative Binomial\u0026#39;); # labels plt.ylabel(\u0026#39;Mass\u0026#39;) plt.xlabel(\u0026#39;Count\u0026#39;) plt.title(\u0026#39;Predictions for Tweet Counts in a Week, Using All Data\u0026#39;) plt.legend(); With a larger amount of data and predicting the tweet count over a short interval (7 days), the predictive distribution from the negative binomial and Poisson models are nearly indistinguishable. Below I compare the predictions of these model for an interval of 1 year (365 days), again using all data.\n# Using all data # parameters cs=range(350,600) s = 365 index = 198 theta = s*lambda_map[index] plt.figure(figsize=(10,4)) # plot the Poisson density plt.scatter(cs,poisson.pmf(cs,theta)) plt.plot( cs,poisson.pmf(cs,theta),label=\u0026#39;Poisson\u0026#39;) # plot the negative binomial density plt.scatter(cs,nbinom.pmf(cs,n=alphas[index],p=betas[index]/(s+betas[index]))) plt.plot( cs,nbinom.pmf(cs,n=alphas[index],p=betas[index]/(s+betas[index])),label=\u0026#39;Negative Binomial\u0026#39;); # labels plt.ylabel(\u0026#39;Mass\u0026#39;) plt.xlabel(\u0026#39;Count\u0026#39;) plt.title(\u0026#39;Predictions for Tweet Counts in a Year, Using All Data\u0026#39;) plt.legend(); When considering a longer period of time, The uncertainty in \\(\\lambda\\) again carries through the negative binomial model, but is discarded in the Poisson model that uses \\(\\lambda_{MAP}\\).\n Summary This was a beefy notebook!\nFirst I showed how to pull tweets as Status objects from Twitter’s API. Given Status objects, I then showed how to embed them in a notebook, view them as a dictionary, and otherwise access their attributes to construct a list of tweet timestamps. I then described Poisson Processes as they may apply to modeling user tweet rates and tweet counts over periods of time. I used kernel densities to check assumptions of a Poisson Process and found possible violations of homogeneity, and of the result that intervals between tweets should follow an exponential distribution.\nPunting these violations, I developed a model of tweet frequency using conjugacy between Gamma priors and Exponential likelihoods. To predict tweet counts over a period of time, I derived a negative binomial predictive distribution that accounted for uncertainty in a user’s tweet rate. I compared this distribution to a Poisson distribution that ignored uncertainty by taking only the maximum a posteriori estimate of a user’s tweet rate.\nOverall the model that discards posterior uncertainty attributes less mass to fringe counts, especially when there is little data or when the interval over which counts are being predicted is long. Incorporating posterior uncertainty broadens the predictive distribution to reflect uncertainty in the underlying tweet rate. That uncertainty exists regardless of the modeling approach – excluding it from predictive distributions only leads to narrow, overconfident predictions. This general principle of propagating uncertainty through a statistical process is one strong advantage of the Bayeian modeling approach that I developed and applied here.\n ","date":1571336498,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571336498,"objectID":"0b4907df5df827ce35a063ba893b6eb6","permalink":"/MacStrelioff/data-science/twitter-poisson-processes-and-conjugacy/","publishdate":"2019-10-17T18:21:38Z","relpermalink":"/MacStrelioff/data-science/twitter-poisson-processes-and-conjugacy/","section":"data-science","summary":"Background and Setup Twitter Data Pulling Data from Twitter’s API Working with Twitter Status objects Embed a Status Convert a Status to a dict Access Status Attributes (How I accessed the data used below)  Poisson Process Assumptions Specification and Properties Checking the Homogeneity Assumption Checking the exponential distribution of intervals  Model of Tweet Fequency Using Conjugacy Inference On Tweet Rate \\(\\lambda\\) Over Time  Predicting Number Of Tweets In Interval \\(s\\) Summary   Background and Setup In this notebook I focus on explaining Poisson processes and conjugacy applied to my Twitter activity.","tags":null,"title":"Twitter, Poisson Processes, and Conjugacy","type":"docs"},{"authors":null,"categories":null,"content":"  Planned Videos “About Me” Channel Video Data Science Interview Walkthrough Series “Data Scientist Interview Walkthrough: Intro” Data Scientist Interview Walkthrough: Probability Question Set 4 Why do you want this role?  Current Topics in Data Science Explain some research at Pintrest  Data Science Topics and Concepts What is Probability and What is a Probability Function? What is a Power Analysis? (Explained at 3 levels of difficulty) What is a sampling distribution?  A/B testing versus bandits How I Get Free Bitcoin With This Simple Python Script (And you can too!) Behavioral question series Probability Distributions Series ML algorithm series What Data Scientists Do 100-Rejection challenge  General Strategies and Guides Meta SEO Keywords Title: Description Tags Higher Ranking  CTR Thumbnails Brand Consistency  Within Videos Duration Hook and Intro Content End Screen General tips   Finished: Data Scientist Interview Walkthrough: Probability, Part 1 Data Scientist Interview Walkthrough: Probability, Part 2 Data Scientist Interview Walkthrough: Probability Question Set 3    Planned Videos “About Me” Channel Video Why?\n Make a landing video for my website that builds credibility (PhD, masters, multiple projects) and likability (goal is to empower people to break down barriers)  Behavioral, “Tell me about yourself”:\nWhat they’re looking for:\n get from Lacy’s pages, and from Deniz’s youtube videos  About Me:\n PhD.. , masters in statistics (borrow from cover letters?) Through grad school I pursued any project that was interesting to me – It was my time to develop valuable skills and learn what I wanted to do. fast list of projects (decision making, prediction markets, statistics, AI and models of the mind, … ) relate to this job at this company talk about YouTube channel and growth strategy demonstrate the value that I add to produce positions decision making, so studying people and the patterns or experiences that shape their behavior Amazed to learn that there’s a huge interplay between psychology and computer science – reinforcement learning Skinner in the 30’s, turned into a plethora of models in computer science, which are now being used to explain human behavior, and neural correlates of key values in those models are being discovered. Overall I was more interested in naturally occurring datasets, and experimental design – how we structude and verify our beliefs, and then use those beliefs to guide our actions. So here at X that might look like using naturally occurring user data to develop and validate models that inform choices about product design. I really like diving into a new theory or model and gaining an redicovering the intuition from some first principles. I also love finding connections between seemingly desparate fields or ideas. This is one of the reasons I was drawn to math and statistics – the same formal patterns and expressions are manifested in so many diverse applications. During graduate school I contributed to a number of projects (behavioral econ, strategy inference, RL, … ) and learned about theories that have real applications – how people make decisions with tradeoffs, how specific ways of delivering reward can influence behavior. I’m also deeply interested in the right way to justify a decision or belief – this is something that propelled my interest in experimentation, Bayesian statistics, and causal inference.\n My mission is to break down barriers, mainly by democratizing education. About me: UCI, recorded lectures for students, stats masters, data scientist, … About this channel: I’ll primarily use this channel to publish educational resources on statistics and programming, mainly for aspiring data scientists. I’ll also use this channel as a platform to discuss hobby projects related to data science.\n   Data Science Interview Walkthrough Series I realized there was a lot of material to help prepare for software engineering videos, but very little for data scientist interviews. So I’m compiling videos of interview questions my firends and I have been asked in data sicence interviews, and questions that I’ve gotten from data scientists who are currently interviewing.\n Target Audience: People who want to know more about data scientist interviews Marketing: Post on Facebook, LinkedIn data science interest groups  Value:\n “I have a masters in statistics and a PhD in cognitive science” (can I add results to this?) My credability: Do an ‘about me’ video where I talk about my work at UCI, masters degree in statistics. “To make these videos the mose valuable use of your time, I’m focusing exclusively on questions and content that have come up during interviews.”  “Data Scientist Interview Walkthrough: Intro”  When I was studying to be a data scientist, I realized that there were lots of resources with loads of material that won’t actually help in an interview because they were too vague or too theoretical, or just contained very little material that actually comes up in an interview. I also noticed that there are plenty of walkthroughs for the problems that come up in software engineering interviews, but nothing like that for data science interviews. So with this series, I’m creating videos that will walk you through the questions that are currently coming up in silicone valley data scientist interviews To make this the most valuable use of your time, I’ll be walking through questions that have come up in my interviews, or in my friends interviews, as well as questions that I gotten from data scientists and product managers who are actively interviewing. This way these videos are going to be the most relevant and helpful resource for you if you want to learn what it takes to excel in a data science interview. So.. what are these videos? Each video will start with a question. I’d recommend pausing the video and trying the question yourself for a few minutes, and then watching my walkthrough for the question. As I walk through the questions, I’ll mention the concepts that the questions are testing for so that you can note them and dive into those later. Now, some of the best questions start easy and become progressively harder, so what that means here is that, if you don’t watch to the end then you might miss surprises that an interviewer can throw at you, that the people who aren’t watching my videos won’t be expecting. So for now, I would recommend watching the videos, trying the problems, and seeing how I walkthrough solutions, and watching through the end so that there aren’t any unexpected surprises If you find this helpful or interesting, like this video so that I know that the work I put into this series is having a good impact for you and other people Also, if there are questions that you have encountered and want answered, comment them below so that I can get you a walkthrough! And finally be sure to subscribe if you want access to the most recent walkthroughs Thank you, and I hope you enjoy these videos!   Data Scientist Interview Walkthrough: Probability Question Set 4 Thumbnail:\n Me centered, looking perplexed in a direction of the title, with a green/blue background?  Intro:\n I was asked this question during a technical phone screen for a large, popular tech company that you know.  Outro:\n So I have a few things to say before I end this video. First, if you have any questions, feel free to leave them in the comment section so that they can be addressed. Second, these videos actually take time to make, time that I could spend doing things that are more fun like drinking coffee. I’m deciding whether I should make more videos like this, so if you liked it, please “make it official” and click the like button on YouTube. Finally, try subscribing if you want to see the latest videos like this   Why do you want this role?  see https://www.youtube.com/watch?v=taHSZEhTzPc Tip #1: Understand their PAIN and how to solve it. Tip #2: Show the right demeanour. Tip #3: Tell stories. Tip #4: Sell yourself. Tip #5: Be confidently YOU. and this https://www.youtube.com/watch?v=RiKXKYNlwFQ Also maybe a professional development workshop on this topic? -general on behavioral interviews general on rapport general on being liked    Current Topics in Data Science Explain some research at Pintrest See:\nPredicting Intent Using Activity Logs  Pintrest:\n Content sharing platform, and image based search engine Prior research found user types; 1) casual browsers, 2) responding to a specific goals Prior research found different temporal horizons, e.g. using Pintrest to plan dinner versus using Pintrest to plan vacations. On Pintrest users view pins (content) to boards (collections). Pins have 33 categories (DIY, food and drink, …) Users can look at closeups of Pins, which provides additional information Users can click through to visit a site affiliated with a pin  Problem and volue of a solution:\n Users can use a product with different intents, and the material that a user finds valuable may depend on their intent. Being able to infer a user’s intent from their behavior during a session would enable a personalized experience aligned with a user’s goals. Example: Someone looking for dinner recepies might want something they can quickly make with common ingredients, while someone looking for potluck ideas might want more unique dishes, and someone who is just browsing food might prefer a variety of exotic food images. User intent can vary with each session, so quickly identifying intent within a session can help with changing the interface and content shown to the user in real time based on their inferred intent  Current paper:\n Goals: Understand how intent informs behavior, and whether intent can be inferred from behavior. Two dimensions of intent: Goal specificity: whether the intent is stimulus specific (glutin free chocolate chip recepies) or vague (just browsing to pass time). and temporal range: Time horizon for goal completion (tonight, next week, next month, …). In psych, motivation is defined as a directing and activating or invigorating force. The directional component maps onto what Pintrest is calling goal specificity, and the invigorating component might map onto the inverse of what Pintrest refers to as temporal range. In psych, there’s a notion of goal-directed and habitual behavior. The former is driven by a specific desired outcome (similar to goal specificity here) while the later is a less mindful response to stimuli (eg boredom triggers a passive arousal seeking). In social psych, attitudes have been thought about along a gradient of specificity – so maybe things like time-related words in a query can be used to identify goal-directed users. Shopping websites can be used for a specific purchase (goal-directed) or in an experiential way (habitual).  Methods:\n Sample: 5369 females mean age 33.5, 564 males mean age 38.6, all from US and on Pintrest during July 2016 Survey asking; 7 point likert scale: “Are you visiting Pintrest with a goal in mind?” “When are you planning to act on what you’re looking for today” Question about Pintrest specific motivations (eg finding DIY ideas) “What are you looking for on Pintrest today?” Response options were based on Pintrest categories Focused on data in the session immediately following the survey primarily analyzed first 10 minutes because this window had peak performance, around 27% of sessions had fewer than 10 minutes Over 850,000 behavioral events (views, closeups, searches) across 5933 users within 10 minutes. Also analyzed behavior from when the user first created account until a week after survey completion used Holm-corrected p-values, a method that is more powerful than a the conservative Bonferroni correction.  Mitigating limitations:\n coverage bias: mitigated by uniformly sampling from users for inclusion participation bias: compared activity of users who completed the survey (addigned survey, took survey) to those who saw the survey popup but did not complete the survey (assigned survey, did not take survey). Survey takers had been using Pintrest longer, and had more saved pins. Inferred from this that engaged users were  Findings:\n Goal-specific users are: more focused, search more (1.1 vs 0.4 searches), spend more time browsing specific categories of content in detail, more likely to reference saved content, less likely to return in next 7 days, less likely to attribute their visit to boredom (2% vs 25% for habitual), more likely to attribute visit to making something (26% vs 5% for habitual) users with short term goals: specific categories of content, likely to reference saved content, less likely to save new content, goal-specific users more likely to act in short term, habitual users more unsure of taking actions Demographic differences: females more likely to be goal-specific (49% vs 40%), males unsure of taking action, older users more short-term goals, younger users more unsure of taking action, food, drink, DIY searches more likely to be goal-specific and act in short term, travel, entertainment more likely to be habitual and likely to act in long term, intent moderates the type of recepies users save Model can predict goal specificity and temporal range. Current session data is most informative, historical activity data also helpful   Understanding behaviors that lead to purchasing    Data Science Topics and Concepts What is Probability and What is a Probability Function?  notes from prob and stats page   What is a Power Analysis? (Explained at 3 levels of difficulty)  Explain a power analysis (start complicated, get simple to keep people watching till the end)  an analysis done to find a sample size formula based on t-distribution example formula based on P(..) General definition and power functions   mix Peter’s github repo / simulations with an explanation   What is a sampling distribution?   A/B testing versus bandits  How I Get Free Bitcoin With This Simple Python Script (And you can too!)  can make video, then make it public later.. (after job searching ends)\n Video on my script for clicking the roll button on freebitco.com Simplify the script to be a python script that can be run from the terminal with one command. In the video, show people how to download the script from my GitHub and run the script from terminal :D Add referral code so that I get a cut of the coins generated by anyone watching my video\n CTR: Thumbnail: Colorful background, with me looking and pointing at a screenshot of the python scrip \u0026amp; maybe text that says free on it?\n Advertising: “Sharing this video is like giving your friends free money!” Incentivize: The more people who consistently do this, the more of the referral bonous I’ll give back. Show an example of how much I could give back if they run this consistently. My goal is to make a certain amount each week, so I’ll modify the referral bonus kickbacks based on that. So share this video to increase your kickback.\n   Behavioral question series Make videos based on the questions / resources from Lacy ..\n Probability Distributions Series  Pick common distributions, describe them from the Wikipedia page Show their probability functions Show (derive?) their CDF Derive their MGFs Derive score and Fisher Information Describe / show conjugacy properties?   ML algorithm series  include scripts, and put the scripts on my GitHub for download (then I can cite GH DLs on my CV) Explanations, intuitions of different ML algorithms Strengths and weaknesses of different ML algorithms   What Data Scientists Do  Break down some blog posts from big companies (Google, Netflix, Instacart, …)   100-Rejection challenge  TED Talk on this self confidence: repetition, managing self-talk, ….    General Strategies and Guides Meta  schema.. an html code snippit that gives google info about a video? go to html code, ask dennis to do it for you… or google it lol\n playlists good for watch time – this might be in place of a long video.. videos with individual titles to funnel people in keyword is the the search query, er the target search query pick a target keyword for each video Youtube algo inferring search intent\n   SEO good overview article\nKeywords Search for similar videos, check their keywords using Google’s ‘inspect source’. Search those keywords on vidIQ   keyword is the the search query, er the target search query Use vidiq to determine search volume potential on video keywords\n Google search volume is not always indicative of interest in a topic on Youtube so it’s not a good idea to rely on it for choosing video keywords Keywords that have video carousels in the Google SERPS can increase CTR of a video and pull in more views   Title:  instead of ‘part 1, ..’ find seperate videos that can rank on their own, maybe try ‘question 1’ so they sound self-contained title case – capitalize first letter of all words in title Video is shorter than 60 characters so it isn’t cut off in the SERP Video contains your target keyword Remove excess jargon See SEO Framework/YouTube Distribution section - in the expanded section in middle of page - for examples. Do not include episode numbers for your videos that are in playlists. CTR and views might go down as episode numbers go up and the playlist is already directing the order in which your audience views so there’s no need to really include the numbers Briggsby found that titles with 47-48 characters perform best. This has not been reflected in our own videos so far but this is still a good target range to adhere to as a best practices. Front-load your keyword in your title if possible. Youtube gives more weight to words that come at the beginning of the title. Don’t do this if it comes at the expense of the flow of your title or users’ understanding of your title. Note that your title in the video description can be different than what appears in the thumbnail (to make the title visually more succinct)   Description  in description, overview of everything, links of anything you want to push people to, timestamps for parts of the video. longer descriptions better for ranking bc youtube, sweet spot ~350 words. Include your target keyword in first line and give an overview of what topics your video will cover Descriptions that consist of 200-350 may to improve rankings Your description should not give away so much of the content of your video that people no longer need to watch to get the bulk of the information Link at the front, so that it isn’t cut off Including time stamps in your video can help prevent people who just want to understand one topic from your video from bouncing off the page when they don’t get the answers they want immediately (this is good for longer videos)\n Add summary with timecodes in the description timecodes\n  From this blog - Brief CTA for a relevant next video to drive session length and related videos. - Subscribe CTA to help build your distribution power. - 50 to 150 words in the description to summarize and describe your video, mentioning a broad match variation of your keyword 1 to 3 times, depending on length. - List additional videos to watch, focused on your best content about the same or a similar subject matter as this video, creating recommendation clusters. - A brief bio and/or list of social accounts, which can help build your distribution power. - Avoid exceeding 400 words without a good reason to do so, because stuffing or going broadly off topic can harm performance.\n Tags  Look at “view page source” and find their keywords. type key words in youtube search, and add the things that it suggests. keyword  long tail keywords  2-3 broadest category ones focus on 6-8 tags\n Include 6-8 tags Use this formula: 1st tag - target keyword, 2nd + 3rd tags - synonyms for your target keyword, 4th + 5th tags - related long tail keywords, 6th + 7th keywords - broad categories that your video fits into Use ‘page inspector’ option in Chrome to look up keywords used in high traffic videos on related topics! This increases your chances of being placed as a suggested video for that video\n   Higher Ranking Good advice from joma here\nvideo guidelines for higher ranking:\n add 5-10s pauses to let users try the problems on their own (and to increase view time) ask users to subscribe sell likes and subscriptions: “As you can imagine, it takes a lot of time and effort to make these videos. If you found this content helpful at all, please click the like button to let me know. Also, if there are interview questions that you’ve gotten, or concepts you would like an explanation on, feel free to comment below so that I know which videos to prioritize in the future. Finally, if you want to stay up to date on interview walkthroughs for common and recent interview questions, then click subscribe to stay on top of the latest interview topics.” “Unfortunately, interviews are largely luck in terms of whether you’ve seen the question before. In this series I walk through problems that reflect those that are currently being asked in data scientist interviews at highly competitive companies. After watching these interview question walkthroughs, you’ll be able to confidently brease through your technical interviews. Many resources, can be overwhelming and ultimately a waste of time because much of that material won’t ever come up. My goal is to make these videos the highest return on your time by focusing on content that my friends and I have seen in interviews.    CTR Thumbnails guide here\nFace in a small frame over written math Face large, with text formulas around it  For a background photo, choose something with blues, greens, and high contrast, and maybe face shapes e.g. search: blue green smoke black background face\n From Jessica: Use bold text that can be read in a variety of different sizes Use high resolution pictures Use colors that contrast against the Youtube website color scheme of red and white Yellow, green, orange, purple pink and blue Use high contrast photos Many experts recommend including people/faces in thumbnails to increase CTR. However, we tried this with the Kanban series and did not see CTR increase so the jury is out.\n Find a high contrast background, and maybe in ppt, put a title in white font on a black box in the center?\n   Brand Consistency   Within Videos Duration  Do an incognito tab search in Youtube for your target keyword and note the average duration of the top three videos. This should give you a good idea of an appropriate duration for the type of content you’re creating Videos should be at least 4:30 long According to Briggsby: The average duration of videos that rank in the top 5 is 11 minutes and 44 seconds, and there appears to be a positive relationship between video length and rank performance. Audiences also tend to “like” videos more that are in the 10-16 minute range However, keep in mind that you should tailor your video duration to be appropriate for the type of content you are creating and that’s why you should always be sure to note how long the videos are that are ranking for your target keyword   Hook and Intro Context: “This video is part of a series where I work though common and current Data Science interview questions. If you’d like to see more, feel free to like so that I know the these videos are having an impact, and to subscribe if you want to see the latest videos.” Credibility “I have a PhD in Cognitive Science and a Masters in Statistics, currently a fellow in a sillicon valley data science bootcamp, where I’m actively interviewing, and networking with data scientists who conduct interviews.” Need / Value: “I realized other content sucks, and this is the best use of your time.” Legitimacy: “This is a question that I got from an interview”   start with an overview of the video. start with what they want for the hook – then ask to like/subscribe at the end for the people that obviously like.\n Hook your audience in the first 10 seconds but don’t give away the answer to the central question of the video that early or your audience will bounce You shouldn’t string them along for too long because you want your video to get to the point, but you don’t want to lose them within the first 10 seconds\n Playlists can help increase the amount of time that your viewers stay on Youtube and, in turn, improve your rankings However, be sure that you keep your playlists focused around one highly-specific topic. If you switch up the topic too much, we see high drop-off and videos end up looking ineffective to the Youtube algorithm. Additionally, if you’re creating a playlist, make sure that videos can stand alone as well within the context of the playlist. If they’re ranking for a standalone keyword, they won’t always appear within the context of your video and you don’t want people to bounce because they feel like they need to have watched 4 or 5 previous videos in order to understand the one that they landed on Writing a script is highly recommended. By sharing your script and refining your opening, you avoid the risk of shooting footage without a clear, strong opening\n   Content  biggest spikes are when there’s new visual information..\n Mention emotions and feelings through a video “At this point you feel like you’re doing well, then …” Speak in a desirable way – engaging or calm. Emphasize value of the content at every step. Pause for them to try and also to increase view time metric\n   End Screen Some advice from YouTube\n Create a custom end screen with bold text to clearly indicate your calls to action Next video to watch and subscriber buttons are good ones If possible have your end screen pop up on the side while your video is still going on, instead of coming on against a static screen. According to Youtube expert Tim Schmoyer, this can increase engagement and prevent people from clicking away from your video Focus on your two most important call to actions instead of bombarding your viewers with too many options Make sure to hold your “subscribe” element in your end screen (see end screen example here) for at least 5 seconds before cutting away.   General tips  Write everything out (maybe in a slightly vague way), and then spend time explaining the terms. From analytics, long periods of writing seem to hurt user retention.     Finished: Data Scientist Interview Walkthrough: Probability, Part 1  Coins in a bag Probability rules Bayes’ Theorem, Bayes Factor Frequentist Hypothesis Testing Likelihood Ratio   Data Scientist Interview Walkthrough: Probability, Part 2 Geometric distribution problem:\n This video is part of a series where I work though common and current Data Science interview questions. Subscribe if you want to see the latest videos. And if this sounds interesting or helpful, give this video a like so that I know the these videos are having an impact,   Data Scientist Interview Walkthrough: Probability Question Set 3 Thumbnail:\n Me centered, looking perplexed in a direction of the title, with the problem full screen?  Intro:\n There’s two questions in this video. The first was from an onsite interview at a late stage startup. The second was from an actual test that a company gave as a screen. Here they are:  Outro:\n So I have a few things to say before I end this video. First, if you have any questions, feel free to leave them in the comment section so that they can be addressed. Second, these videos actually take time to make, time that I could spend doing things that are more fun like drinking coffee. I’m deciding whether I should make more videos like this, so if you liked it, please “make it official” and click the like button on YouTube. Finally, try subscribing if you want to see the latest videos like this    ","date":1567903122,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567903122,"objectID":"d5fac34485e42a71cf7dd1639ebcd491","permalink":"/MacStrelioff/unlisted/youtube_strategy/","publishdate":"2019-09-08T00:38:42Z","relpermalink":"/MacStrelioff/unlisted/youtube_strategy/","section":"Unlisted","summary":"Planned Videos “About Me” Channel Video Data Science Interview Walkthrough Series “Data Scientist Interview Walkthrough: Intro” Data Scientist Interview Walkthrough: Probability Question Set 4 Why do you want this role?  Current Topics in Data Science Explain some research at Pintrest  Data Science Topics and Concepts What is Probability and What is a Probability Function? What is a Power Analysis? (Explained at 3 levels of difficulty) What is a sampling distribution?","tags":null,"title":"YouTube Strategy","type":"Unlisted"},{"authors":null,"categories":null,"content":"  Overview Background and Setup Cookie Clicker Game  Agents Naive: Buy all affordable investments MaxROI: Buy best return on investment MinWait: Buy what minimizes the time to the highest revenue purchase  Performance Revenue Building Count Building Prices Return on Investment (Revenue Per Cost)  Conclusions Appendix: MinWait Decision is Independent of Balance Helper Functions Browser and Game Initialization Clicking Cookies Purchasing Upgrades Logging balance and revenue Get building information     Overview Lately I’ve been interested in writing algorithms (agents) that interact with websites. The game Cookie Clicker is a great testing ground for such algorithms. The game is played by clicking a big cooke to earn money (cookies) that can be used to invest in instruments (buy buildings), which in turn generate revenue (more cookies). Here I’ll describe three agents that I made for this game and assess their performance. I also describe many of the helper functions involved in implementing these agents. The code that implements these agents and reproduces all figures in this blog post can be found on my GitHub, here: https://github.com/MacStrelioff/CookieClickerAgent\n Background and Setup Cookie Clicker Game The interface for Cookie Clicker is shown below.\n The goal of the game is to amass wealth in the form of cookies. Your balance and revenue are shown above the large cookie. Cookies are earned each time you click the large cookie and investments, shown at the bottom right, are unlocked as you acquire wealth. Purchasing an investment (Cursor, Grandma, …) provides recurring revenue in cookies per second. For any specific investment, the price of the next investment increases each time the investment is purchased. In developing the algorithms below I focused on maximizing revenue, which would maximize wealth over time.\nThe game has other mechanics (upgrades, ascension, golden cookies, …). I programed functions to purchase upgrades and click golden cookies, but these functions were disabled in the analyses below to allow for a controlled comparison of the agents.\n  Agents While the goal was to earn as many cookies as possible, the game also allows revenue to accrue while the player is away, and the amount of cookies earned per click can scale with revenue. For these reasons, I focused on maximizing revenue as the overall goal for any strategy.\nNaive: Buy all affordable investments The simplest investment strategy was to purchase any affordable building. This is implemented in the code below:\nclass agent_class_naive: ... def buy_products(self): products = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) while products: # if there are affordable products, buy them products[-1].click() products = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) ... Here products is a list of the web elements that represent the affordable buildings, and the while loop cycles over them, buying the most expensive ones first with products[-1].click(), until no more buildings are affordable. This purchasing logic is implemented through a buy_products method of the naive agent, agent_class_naive. In my code, the naive agent class also contained the necessary helper functions, described in the section above.\n MaxROI: Buy best return on investment The second strategy is to buy the option that will have the best return on investment (revenue to price ratio). The code below extends the naive agent, agent_class_naive, by overriding the buy_products method that implements the investment strategy.\nclass agent_class_max_rps_price_ratio(agent_class_naive): # overwrite the buy_products method def buy_products(self): ## update building info self.get_building_info() # while best is affordable, buy the best rps/price building best_building_affordable = True while best_building_affordable: ## get unlocked products products = (driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) + driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked disabled\u0026quot;]\u0026#39;)) # find max rps/price building max_rps_pp,building_to_buy,product_to_buy = 0,[],[] for i,building in enumerate(self.building_info): # get rps/price for building cur_rps_pp = self.building_info[building][\u0026#39;cps/price\u0026#39;] # if it\u0026#39;s the best so far, update max and building id if cur_rps_pp \u0026gt; max_rps_pp: max_rps_pp,building_to_buy = cur_rps_pp,building product_to_buy = products[i] # store element to click # update balance self.log_balance_and_revenue() # check if best building is affordable. if self.building_info[building_to_buy][\u0026#39;price\u0026#39;]\u0026lt;=self.balance: # buy building_to_buy (click on this product) product_to_buy.click() # update building info (including rps per price rps_pp) self.get_building_info() else: best_building_affordable=False # if not affordable, break the loop  First the MaxROI agent updates building information, including; cookies per second, price, and the ratio cps/price, using the helper method get_building_info(). Then it purchases the buildings that provide the max ROI, until the best building by this metric is unaffordable. The search for the best building is implemented in the section:\n# find max rps/price building max_rps_pp,building_to_buy,product_to_buy = 0,[],[] for i,building in enumerate(self.building_info): # get rps/price for building cur_rps_pp = self.building_info[building][\u0026#39;cps/price\u0026#39;] # if it\u0026#39;s the best so far, update max and building id if cur_rps_pp \u0026gt; max_rps_pp: max_rps_pp,building_to_buy = cur_rps_pp,building product_to_buy = products[i] # store element to click This is an \\(O(N)\\) search through the buildings that have information, where \\(N\\) is the number of buildings. This code logs the maximum ROI in max_rps_pp and the building associated with this ROI in building_to_buy, as well as the web element to click in order to purchase this building, product_to_buy. After the best ROI investment is found, the next few lines of code update the agent’s balance and check if the investment is affordable. If it is, the agent buys it and this process repeats, if it is not then best_building_affordable is set to False which ends the while loop.\n MinWait: Buy what minimizes the time to the highest revenue purchase The intuition of this strategy is to buy the investment that maximizes revenue, however, those investments can be expensive. Other investments may increase revenue enough to decrease the amount of time before the highest revenue investment can be purchased. This intuition is sketched in the figure below, where the naive waiter (red) waits until they can purchase a hypothetical maximum revenue investment for 200, and the MinWait algorithm makes an investment for 100 that increases revenue enough to purchase the maximum revenue investment faster than the naive waiter:\nFormally, this algorithm first computes the wait until the maximum revenue investment can be purchased (\\(w_{max}\\)), then searches for investments that can reduce the wait and purchases any that it finds. For a given current revenue \\(r_{t}\\) and cost of the maximum revenue investment, \\(c_{max}\\), the wait until this investment can be purchased is \\(w_{max}=\\frac{c_{max}}{r_t}\\), which corresponds to the time when the red line reaches 200. This formula ignores current balance, but in the appendix I show that the current balance is irrelevant for the purchasing decision. An alternative investment, \\(b\\), could improve the wait time if it’s addition to revenue is large enough to make up for its cost before the time \\(w_{max}\\). This is shown with the blue dashed line in the example above. If investment \\(b\\) adds \\(r_b\\) to the current revenue \\(r_t\\), and costs \\(c_b\\), then the wait until the maximum revenue investment if \\(b\\) is purchased is: \\(w_b = \\frac{c_b}{r_t}+\\frac{c_a}{r_t+r_b}\\). This algorithm buys \\(b\\) if \\(w_b\u0026lt;w_{max}\\); that is, if purchasing \\(b\\) reduces the wait until the maximum revenue investment can be purchased.\nThe code I used to implement this is provided below.\n# Max RPS/price agent class agent_class_min_wait(agent_class_naive): # overwrite the buy_products method for this agent\u0026#39;s purchase logic def buy_products(self): ## update building info self.get_building_info() # while best building affordable, buy it and look for next best building best_building_affordable = True while best_building_affordable: ## get unlocked products products = (driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) + driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked disabled\u0026quot;]\u0026#39;)) # find building with max revenue per second and it\u0026#39;s cost max_rps,cost_max_rps = 0, float(\u0026#39;inf\u0026#39;) building_to_buy,product_to_buy = [], [] for i,building in enumerate(self.building_info): # get rps for building cur_rps = self.building_info[building][\u0026#39;cps\u0026#39;] # if it\u0026#39;s the best rps far, update max, cost, and building id if cur_rps \u0026gt; max_rps: max_rps,building_to_buy = cur_rps,building cost_max_rps = self.building_info[building][\u0026#39;price\u0026#39;] product_to_buy = products[i] # queue this building to buy # update revenue for computations below self.log_balance_and_revenue() # check if any other purchase would reduce wait time to buying max_rps product wait_max = float(cost_max_rps) / self.revenue if self.revenue else 0 # stops division by 0 for i,building in enumerate(self.building_info): cost_cur = self.building_info[building][\u0026#39;price\u0026#39;] rps_cur = self.revenue + self.building_info[building][\u0026#39;cps\u0026#39;] # conditional to stop division by 0 wait_till_cur = float(cost_cur) / self.revenue if self.revenue else 0 wait_cur = (wait_till_cur + cost_max_rps / rps_cur) if wait_cur \u0026lt;= wait_max: wait_max = wait_cur # update minimum wait building_to_buy = building product_to_buy = products[i] # queue this building to buy instead # update balance for checking if building affordable self.log_balance_and_revenue() # buy either max_rps product, or the building that would reduce wait time # check if best building is affordable if self.building_info[building_to_buy][\u0026#39;price\u0026#39;]\u0026lt;=self.balance: # buy building_to_buy (click on this product) product_to_buy.click() # update building info (including rps per price rps_pp) self.get_building_info() else: best_building_affordable=False # if not affordable, break purchase loop  This implementation again extends the agent_class_naive class by replacing the buy_products method. The algorithm makes two passes through the list of unlocked investments. The fist pass is copied below:\n# find building with max revenue per second and it\u0026#39;s cost max_rps,cost_max_rps = 0, float(\u0026#39;inf\u0026#39;) building_to_buy,product_to_buy = [], [] for i,building in enumerate(self.building_info): # get rps for building cur_rps = self.building_info[building][\u0026#39;cps\u0026#39;] # if it\u0026#39;s the best rps far, update max, cost, and building id if cur_rps \u0026gt; max_rps: max_rps,building_to_buy = cur_rps,building cost_max_rps = self.building_info[building][\u0026#39;price\u0026#39;] product_to_buy = products[i] # queue this building to buy Similar to that used in the MaxROI agent, this code is an \\(O(N)\\) search through the \\(N\\) unlocked buildings. It logs the maximum revenue in max_rps and the building associated with this revenue in building_to_buy, as well as the web element to click in order to purchase this building, product_to_buy.\nThen the agent computes \\(w_{max}\\) with:\nwait_max = float(cost_max_rps) / self.revenue if self.revenue else 0 # stops division by 0 The (value) if (condition) else 0 is used to stop division by 0 – if self.revenue is 0, then wait_max will take the value 0 rather than the computed value which is undefined when self.revenue is 0.\nNext, another pass through the list of buildings, this time searching for a building that will reduce the wait time:\nfor i,building in enumerate(self.building_info): cost_cur = self.building_info[building][\u0026#39;price\u0026#39;] rps_cur = self.revenue + self.building_info[building][\u0026#39;cps\u0026#39;] # conditional to stop division by 0 wait_till_cur = float(cost_cur) / self.revenue if self.revenue else 0 wait_cur = (wait_till_cur + cost_max_rps / rps_cur) if wait_cur \u0026lt;= wait_max: wait_max = wait_cur # update minimum wait building_to_buy = building product_to_buy = products[i] # queue this building to buy instead Here the MinWait agent gets the cost of a candidate investment, cost_cur and the revenue that would be attained if this investment is bought rps_cur. Then computes the time before this candidate investment could be bought at the current revenue, wait_till_cur and finally computes \\(w_b\\), the wait until the maximum revenue option could be bought if the candidate investment is bought first as wait_cur. Lastly, if this is lower than wait_max (\\(w_{max}\\)), then the agent stores the best wait in wait_max and updates the building to buy and the web element to click.\nLike the MaxROI agent, the last few lines of code check if the investment is affordable, and if not, terminates the ends the purchasing loop.\n  Performance Each agent class was instantiated as agent and run for 100,000 big cookie clicks, with the purchase logic run after every 200 clicks. The Naive, MaxROI, and MinWait agents ran for approximately 3650 seconds, 3785 seconds, and 3800 seconds, respectively. The differences in runtime were small enough that I wasn’t worried about differences in the performance metrics below being attributable to extra income earned from a longer runtime.\nRevenue First I looked at the main metric, revenue per second, shown in the figure below:\n The MaxROI and MinWait strategies clearly performed better than the Naive strategy in terms of maximizing revenue per second. It also appeared that the MaxROI algorithm generally had higher revenue when in a purchasing cycle, but the MinWait algorithm surpassed the MaxROI algorithm when waiting for a large purchase.\n Building Count  The Naive agent purchases each investment at about the same rate. At the other extreme, MinWait agent generally saves for the highest revenue option, then occasionally buys cheaper options to reduce the wait until the next purchase of the highest revenue option. This is most clearly seen in the spikes across buildings soon after a new, expensive, building is purchased. Like the Naive agent, the MaxROI agent also buys each investment frequently, however this agent prioritizes the investments that give the best return on investment.\n Building Prices  The Naieve strategy results in equalizing prices, while both the MaxROI and MinWait strategies can save to purchase the most expensive investment.\n Return on Investment (Revenue Per Cost)  The Naive strategy rarely chooses the best ROI option. The MaxROI strategy equalizes the ratio between revenue and price across the investments, while the MinWait strategy similarly picks options with a good ratio here but also frequently chooses worse deals. Overall the Naive and MinWait strategies often end up paying more than they should for revenue.\n  Conclusions Both the MaxROI and MinWait agents perform far better than the Naive agent in terms of maximizing revenue. The MaxROI agent performed better when in a buying cycle, but the MinWait agent surpassed the MaxROI agent during long periods of saving for an expensive purchase. Perhaps a better algorithm would be a hybrid that follows the MaxROI strategy when all revenues are known, and uses the MinWait strategy when saving up for an expensive option with an unknown revenue.\n Appendix: MinWait Decision is Independent of Balance Another consideration for the MinWait strategy was that the balance could reduce wait overall, and this might mathematically result in a preference reversal if the wait for \\(b\\) becomes negligably small. Accounting for balance and using \\(c_{max}\\) to represent the cost of the maximum revenue option, \\(r_t\\) to represent the current revenue, \\(c_b\\) to represent the cost of another investment, and \\(r_b\\) to be the additional revenue provided by that investment, the wait time calculations become;\n\\[ \\begin{aligned} w_{max} \u0026amp;= \\frac{c_{max}-balance}{r_t} \\\\ w_{b} \u0026amp;= \\frac{c_b-balance}{r_t} + \\frac{c_{max}}{r_t+r_b} \\end{aligned} \\]\nThe the decision rule can be cast as: buy \\(b\\) if \\(w_{max} - w_{b}\u0026lt;0\\). This results in the decision function:\n\\[ \\begin{aligned} w_{max} - w_{b} \u0026amp; = \\frac{c_{max}-balance}{r_t} - \\left(\\frac{c_b-balance}{r_t} + \\frac{c_{max}}{r_t+r_b}\\right) \\\\ \u0026amp;= \\frac{c_{max}-balance-c_b+balance}{r_t} + \\frac{c_{max}}{r_t+r_b} \\\\ \u0026amp;= \\frac{c_{max}-c_b}{r_t} + \\frac{c_{max}}{r_t+r_b} \\\\ \\end{aligned} \\]\nThe same function results from \\(w_{max}=\\frac{c_{max}}{r_t}\\) and \\(w_{b} = \\frac{c_b}{r_t} + \\frac{c_{max}}{r_t+r_b}\\), hence the decision does not depend on balance.\n Helper Functions The base agent class, agent_class_naive, contained many helper functions as well as the naive investment purchasing logic. This section explains the code used for the helper functions.\nBrowser and Game Initialization The agent was initialized with a web driver object stored in driver. The first part of the agent class __init__ method is copied below:\nclass agent_class_naive: def __init__(self,driver): # navigate to site driver.get(\u0026#39;https://orteil.dashnet.org/cookieclicker/\u0026#39;) time.sleep(10) # time for page to load self.big_cookie = driver.find_element_by_id(\u0026#39;bigCookie\u0026#39;) self.golden_cookie_clicks = 0 # initialize balance and revenue variables self.balance=0 self.revenue=0 # initialize balance and revenue logs self.log_balance=[0] self.log_revenue=[0] self.log_bal_rev_epoch=[0] # initialize building info, and logs of building info self.get_building_info() self.log_build_info = dict() self.building_info_logger(epoch=0) ... First the agent navigates the webdriver to the Cookie Clicker URL and pauses for 10 seconds to let the page load. After that, the agent finds the big cookie web element and assigns it to attribute big_cookie. The remaining lines above initialize various attributes that were either used in purchasing logic, or used to log data on agent performance.\nThe second part of the __init__ method navigated to the ‘options’ tab and changed the game settings. One important setting to change was the numbersButton option – this toggled between displaying numbers numerically, ‘1,000,000’, versus with words, ‘1 million’. Since the balance is scraped from this text, the agents require that numbers be displayed numerically. The other changed settings related to graphics and game performance. Code for this second part of __init__ is shown below:\n # CHANGE GRAPHICS AND OTHER SETTINGS # click \u0026#39;options\u0026#39; tab driver.find_element_by_id(\u0026quot;prefsButton\u0026quot;).click() time.sleep(1) # let page load # disable text instead of numbers, e.g. \u0026#39;million\u0026#39; -\u0026gt; \u0026#39;000,000\u0026#39; driver.find_element_by_id(\u0026quot;numbersButton\u0026quot;).click() # slide volume to around 25% time.sleep(.5) # so actions don\u0026#39;t happen too fast volume = driver.find_element_by_class_name(\u0026quot;slider\u0026quot;) move = ActionChains(driver) move.click_and_hold(volume).move_by_offset(-50, 0).release().perform() # change graphics for optimal performance buttons = (\u0026quot;fancyButton\u0026quot;,\u0026quot;particlesButton\u0026quot;,\u0026quot;cursorsButton\u0026quot;, \u0026quot;milkButton\u0026quot;,\u0026quot;wobblyButton\u0026quot;,\u0026quot;cookiesoundButton\u0026quot;, \u0026quot;formatButton\u0026quot;,\u0026quot;extraButtonsButton\u0026quot;,\u0026quot;customGrandmasButton\u0026quot;) for button in buttons: time.sleep(.5) # so actions don\u0026#39;t happen too fast to execute driver.find_element_by_id(button).click()  Clicking Cookies A simple, important function, click_cookie() effects the cookie click. The game also has golden cookies that provide a large lump sum of cookies, or transient increases in revenue. Golden cookies appear at random times, and at random locations on the screen. The second function below identifies and clicks these golden cookies until there are no more golden cookies on the screen, and logs the number of golden cookie clicks.\n def click_cookie(self): self.big_cookie.click() def click_golden_cookie(self): golden_cookies = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;shimmer\u0026quot;]\u0026#39;) while len(golden_cookies)\u0026gt;0: # if there are products, and while we can afford products, for golden_cookie in golden_cookies: golden_cookie.click() # buy each one self.golden_cookie_clicks+=1 golden_cookies = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;shimmer\u0026quot;]\u0026#39;)  Purchasing Upgrades Upgrades are another way to spend cookies. The function below finds affordable upgrades and purchases (click) them, starting with the most expensive avilable upgrade.\n def buy_upgrades(self): upgrades = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;crate upgrade enabled\u0026quot;]\u0026#39;) while len(upgrades)\u0026gt;0: # if there are products, and while we can afford products, try: upgrades[-1].click() # buy each one, most expensive first except: None upgrades = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;crate upgrade enabled\u0026quot;]\u0026#39;)  Logging balance and revenue Balance and revenue were important for some strategies and were logged as a metric to compare the agents. To facilitate both use cases, I created a method that took an argument epoch. This method parses the text above the big cookie to convert a string like ‘177 cookies \\n per second: 1.1’ to extract the balance of 177 and revenue of 1.1. If the method is called without an epoch, then it only updates the balance and revenue. Alternatively, if an epoch is passed, then this method also logs the balance, revenue, and eopch or click number. The code for this is shown below:\n def log_balance_and_revenue(self,epoch=None): # parse string with balance and revenue tmp = driver.find_elements_by_xpath(\u0026#39;//div[@id=\u0026quot;cookies\u0026quot;]\u0026#39;) tmp = tmp[0].text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;) # remove camas 1,000 -\u0026gt; 1000 tmp = re.findall(\u0026quot;\\d+\u0026quot;,tmp) # extract balance and revenue tmp = [int(i) for i in tmp] # convert str -\u0026gt; int # update balance and revenue self.balance = tmp[0] # update current balance self.revenue = tmp[1] # update revenue # if epoch passed, log balance and revenue at this epoch if epoch: self.log_bal_rev_epoch.append(epoch) # index for balance and revenue self.log_balance.append(tmp[0]) # log balance self.log_revenue.append(tmp[1]) # log revenue  Get building information Building information like the cost and revenue was used in purchasing logic. The code used to extract this is shown below, and each component is elaborated on afterwards:\n def get_building_info(self): # get unlocked products products_unlocked = (driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) + driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked disabled\u0026quot;]\u0026#39;)) # info for unlocked buildings building_info = dict() for i,building in enumerate(products_unlocked): # get info from building button tmp=building.text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;).split(sep=\u0026quot;\\n\u0026quot;) building_name,building_price,building_count = tmp if len(tmp)==3 else tmp+[0] # initialize dict for building building_info[building_name] = dict() # fill in count and price building_info[building_name][\u0026#39;count\u0026#39;]=int(building_count) building_info[building_name][\u0026#39;price\u0026#39;]=int(building_price) # get info from building tooltip hover = ActionChains(driver).move_to_element(building) hover.perform() tooltip = driver.find_elements_by_xpath(\u0026#39;//div[@id=\u0026quot;tooltip\u0026quot;]\u0026#39;) tmp=tooltip[0].text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;); tmp_cps = re.findall(r\u0026quot;produces [-+]?\\d*\\.\\d+|produces \\d+\u0026quot;,tmp); # \u0026gt; \u0026#39;produces X\u0026#39; if tmp_cps: # if building has been purchased tmp_cps_2=float(re.findall(r\u0026quot;[-+]?\\d*\\.\\d+|\\d+\u0026quot;,tmp_cps[0])[0]) building_cps = tmp_cps_2 else: # if building hasn\u0026#39;t been purchased, store cps as infinity building_cps = float(\u0026#39;inf\u0026#39;) # \u0026gt; X #### default of inf below encourages purchasing unlocked, unowned buildings #building_cps = float(tmp_cps[0][:tmp_cps[0].find(\u0026#39; \u0026#39;)]) if tmp_cps else float(\u0026#39;inf\u0026#39;) building_info[building_name][\u0026#39;cps\u0026#39;]=building_cps building_info[building_name][\u0026#39;cps/price\u0026#39;]=building_cps/int(building_price) self.building_info = building_info This code first obtains a list of the buildings that are unlocked, products_unlocked, then iterates over these to extract the relevant information: count or number owned, price of the next building, revenue, and the revenue to price ratio. Count and price could be obtained by parsing the text on the building button. This was done in the the following lines:\n# get info from building button tmp=building.text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;).split(sep=\u0026quot;\\n\u0026quot;) building_name,building_price,building_count = tmp if len(tmp)==3 else tmp+[0] # initialize dict for building building_info[building_name] = dict() # fill in count and price building_info[building_name][\u0026#39;count\u0026#39;]=int(building_count) building_info[building_name][\u0026#39;price\u0026#39;]=int(building_price) Revenue could only be obtained from a tooltip that appeared when the mouse hovered over the building button. The code below effects a mouse hover over the building, then extracts and parses the text from the building tooltip;\n# get info from building tooltip hover = ActionChains(driver).move_to_element(building) hover.perform() tooltip = driver.find_elements_by_xpath(\u0026#39;//div[@id=\u0026quot;tooltip\u0026quot;]\u0026#39;) tmp=tooltip[0].text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;); tmp_cps = re.findall(r\u0026quot;produces [-+]?\\d*\\.\\d+|produces \\d+\u0026quot;,tmp); if tmp_cps: # if building has been purchased tmp_cps_2=float(re.findall(r\u0026quot;[-+]?\\d*\\.\\d+|\\d+\u0026quot;,tmp_cps[0])[0]) building_cps = tmp_cps_2 else: # if building hasn\u0026#39;t been purchased, store cps as infinity building_cps = float(\u0026#39;inf\u0026#39;) One challenge was that the revenue was only viewable for owned buildings. To address this, I assumed a revenue of infinity for unowned buildings. This would incentivise agents that bought based on revenue to save and purchase the new building – which was reasonable because these buildings had higher revenue than the owned buildings. The last few lines in the code chunk above extract the revenue for owned buildings, and impute a revenue of infinity for unlocked but unowned buildings.\nFinally, the last few lines of code log the revenue and the return on investment (revenue divided by price) for each building and store the updated building information.\nSince this method was long already, I used a seperate method when logging this information. This logging function is shown below:\n def building_info_logger(self,epoch): if self.building_info: # if self.building_info exists # modified from get_building_info to append. log_keys = [\u0026#39;count\u0026#39;,\u0026#39;price\u0026#39;,\u0026#39;cps\u0026#39;,\u0026#39;cps/price\u0026#39;] # info for unlocked buildings for building in self.building_info: # initialize new buildings if building not in self.log_build_info: self.log_build_info[building] = dict() for k in log_keys+[\u0026#39;epoch\u0026#39;]: self.log_build_info[building][k]=[] # fill in count,price,cps, cps/price for k in log_keys: self.log_build_info[building][k].append(self.building_info[building][k]) # log epoch, within each building since buildings become available at different times self.log_build_info[building][\u0026#39;epoch\u0026#39;].append(epoch)    ","date":1564761569,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564761569,"objectID":"15924bd008cba0bb0f0b25969f503971","permalink":"/MacStrelioff/data-science/cookie-clicker-bot/","publishdate":"2019-08-02T15:59:29Z","relpermalink":"/MacStrelioff/data-science/cookie-clicker-bot/","section":"data-science","summary":"Overview Background and Setup Cookie Clicker Game  Agents Naive: Buy all affordable investments MaxROI: Buy best return on investment MinWait: Buy what minimizes the time to the highest revenue purchase  Performance Revenue Building Count Building Prices Return on Investment (Revenue Per Cost)  Conclusions Appendix: MinWait Decision is Independent of Balance Helper Functions Browser and Game Initialization Clicking Cookies Purchasing Upgrades Logging balance and revenue Get building information     Overview Lately I’ve been interested in writing algorithms (agents) that interact with websites.","tags":null,"title":"Example Web Agent","type":"docs"},{"authors":null,"categories":null,"content":"  Overview Background and Setup Cookie Clicker Game  Agents Naive: Buy all affordable investments MaxROI: Buy best return on investment MinWait: Buy what minimizes the time to the highest revenue purchase  Performance Revenue Building Count Building Prices Return on Investment (Revenue Per Cost)  Conclusions Appendix: MinWait Decision is Independent of Balance Helper Functions Browser and Game Initialization Clicking Cookies Purchasing Upgrades Logging balance and revenue Get building information     Overview Lately I’ve been interested in writing algorithms (agents) that interact with websites. The game Cookie Clicker is a great testing ground for such algorithms. The game is played by clicking a big cooke to earn money (cookies) that can be used to invest in instruments (buy buildings), which in turn generate revenue (more cookies). Here I’ll describe three agents that I made for this game and assess their performance. I also describe many of the helper functions involved in implementing these agents. The code that implements these agents and reproduces all figures in this blog post can be found on my GitHub, here: https://github.com/MacStrelioff/CookieClickerAgent\n Background and Setup Cookie Clicker Game The interface for Cookie Clicker is shown below.\n The goal of the game is to amass wealth in the form of cookies. Your balance and revenue are shown above the large cookie. Cookies are earned each time you click the large cookie and investments, shown at the bottom right, are unlocked as you acquire wealth. Purchasing an investment (Cursor, Grandma, …) provides recurring revenue in cookies per second. For any specific investment, the price of the next investment increases each time the investment is purchased. In developing the algorithms below I focused on maximizing revenue, which would maximize wealth over time.\nThe game has other mechanics (upgrades, ascension, golden cookies, …). I programed functions to purchase upgrades and click golden cookies, but these functions were disabled in the analyses below to allow for a controlled comparison of the agents.\n  Agents While the goal was to earn as many cookies as possible, the game also allows revenue to accrue while the player is away, and the amount of cookies earned per click can scale with revenue. For these reasons, I focused on maximizing revenue as the overall goal for any strategy.\nNaive: Buy all affordable investments The simplest investment strategy was to purchase any affordable building. This is implemented in the code below:\nclass agent_class_naive: ... def buy_products(self): products = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) while products: # if there are affordable products, buy them products[-1].click() products = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) ... Here products is a list of the web elements that represent the affordable buildings, and the while loop cycles over them, buying the most expensive ones first with products[-1].click(), until no more buildings are affordable. This purchasing logic is implemented through a buy_products method of the naive agent, agent_class_naive. In my code, the naive agent class also contained the necessary helper functions, described in the section above.\n MaxROI: Buy best return on investment The second strategy is to buy the option that will have the best return on investment (revenue to price ratio). The code below extends the naive agent, agent_class_naive, by overriding the buy_products method that implements the investment strategy.\nclass agent_class_max_rps_price_ratio(agent_class_naive): # overwrite the buy_products method def buy_products(self): ## update building info self.get_building_info() # while best is affordable, buy the best rps/price building best_building_affordable = True while best_building_affordable: ## get unlocked products products = (driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) + driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked disabled\u0026quot;]\u0026#39;)) # find max rps/price building max_rps_pp,building_to_buy,product_to_buy = 0,[],[] for i,building in enumerate(self.building_info): # get rps/price for building cur_rps_pp = self.building_info[building][\u0026#39;cps/price\u0026#39;] # if it\u0026#39;s the best so far, update max and building id if cur_rps_pp \u0026gt; max_rps_pp: max_rps_pp,building_to_buy = cur_rps_pp,building product_to_buy = products[i] # store element to click # update balance self.log_balance_and_revenue() # check if best building is affordable. if self.building_info[building_to_buy][\u0026#39;price\u0026#39;]\u0026lt;=self.balance: # buy building_to_buy (click on this product) product_to_buy.click() # update building info (including rps per price rps_pp) self.get_building_info() else: best_building_affordable=False # if not affordable, break the loop  First the MaxROI agent updates building information, including; cookies per second, price, and the ratio cps/price, using the helper method get_building_info(). Then it purchases the buildings that provide the max ROI, until the best building by this metric is unaffordable. The search for the best building is implemented in the section:\n# find max rps/price building max_rps_pp,building_to_buy,product_to_buy = 0,[],[] for i,building in enumerate(self.building_info): # get rps/price for building cur_rps_pp = self.building_info[building][\u0026#39;cps/price\u0026#39;] # if it\u0026#39;s the best so far, update max and building id if cur_rps_pp \u0026gt; max_rps_pp: max_rps_pp,building_to_buy = cur_rps_pp,building product_to_buy = products[i] # store element to click This is an \\(O(N)\\) search through the buildings that have information, where \\(N\\) is the number of buildings. This code logs the maximum ROI in max_rps_pp and the building associated with this ROI in building_to_buy, as well as the web element to click in order to purchase this building, product_to_buy. After the best ROI investment is found, the next few lines of code update the agent’s balance and check if the investment is affordable. If it is, the agent buys it and this process repeats, if it is not then best_building_affordable is set to False which ends the while loop.\n MinWait: Buy what minimizes the time to the highest revenue purchase The intuition of this strategy is to buy the investment that maximizes revenue, however, those investments can be expensive. Other investments may increase revenue enough to decrease the amount of time before the highest revenue investment can be purchased. This intuition is sketched in the figure below, where the naive waiter (red) waits until they can purchase a hypothetical maximum revenue investment for 200, and the MinWait algorithm makes an investment for 100 that increases revenue enough to purchase the maximum revenue investment faster than the naive waiter:\nFormally, this algorithm first computes the wait until the maximum revenue investment can be purchased (\\(w_{max}\\)), then searches for investments that can reduce the wait and purchases any that it finds. For a given current revenue \\(r_{t}\\) and cost of the maximum revenue investment, \\(c_{max}\\), the wait until this investment can be purchased is \\(w_{max}=\\frac{c_{max}}{r_t}\\), which corresponds to the time when the red line reaches 200. This formula ignores current balance, but in the appendix I show that the current balance is irrelevant for the purchasing decision. An alternative investment, \\(b\\), could improve the wait time if it’s addition to revenue is large enough to make up for its cost before the time \\(w_{max}\\). This is shown with the blue dashed line in the example above. If investment \\(b\\) adds \\(r_b\\) to the current revenue \\(r_t\\), and costs \\(c_b\\), then the wait until the maximum revenue investment if \\(b\\) is purchased is: \\(w_b = \\frac{c_b}{r_t}+\\frac{c_a}{r_t+r_b}\\). This algorithm buys \\(b\\) if \\(w_b\u0026lt;w_{max}\\); that is, if purchasing \\(b\\) reduces the wait until the maximum revenue investment can be purchased.\nThe code I used to implement this is provided below.\n# Max RPS/price agent class agent_class_min_wait(agent_class_naive): # overwrite the buy_products method for this agent\u0026#39;s purchase logic def buy_products(self): ## update building info self.get_building_info() # while best building affordable, buy it and look for next best building best_building_affordable = True while best_building_affordable: ## get unlocked products products = (driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) + driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked disabled\u0026quot;]\u0026#39;)) # find building with max revenue per second and it\u0026#39;s cost max_rps,cost_max_rps = 0, float(\u0026#39;inf\u0026#39;) building_to_buy,product_to_buy = [], [] for i,building in enumerate(self.building_info): # get rps for building cur_rps = self.building_info[building][\u0026#39;cps\u0026#39;] # if it\u0026#39;s the best rps far, update max, cost, and building id if cur_rps \u0026gt; max_rps: max_rps,building_to_buy = cur_rps,building cost_max_rps = self.building_info[building][\u0026#39;price\u0026#39;] product_to_buy = products[i] # queue this building to buy # update revenue for computations below self.log_balance_and_revenue() # check if any other purchase would reduce wait time to buying max_rps product wait_max = float(cost_max_rps) / self.revenue if self.revenue else 0 # stops division by 0 for i,building in enumerate(self.building_info): cost_cur = self.building_info[building][\u0026#39;price\u0026#39;] rps_cur = self.revenue + self.building_info[building][\u0026#39;cps\u0026#39;] # conditional to stop division by 0 wait_till_cur = float(cost_cur) / self.revenue if self.revenue else 0 wait_cur = (wait_till_cur + cost_max_rps / rps_cur) if wait_cur \u0026lt;= wait_max: wait_max = wait_cur # update minimum wait building_to_buy = building product_to_buy = products[i] # queue this building to buy instead # update balance for checking if building affordable self.log_balance_and_revenue() # buy either max_rps product, or the building that would reduce wait time # check if best building is affordable if self.building_info[building_to_buy][\u0026#39;price\u0026#39;]\u0026lt;=self.balance: # buy building_to_buy (click on this product) product_to_buy.click() # update building info (including rps per price rps_pp) self.get_building_info() else: best_building_affordable=False # if not affordable, break purchase loop  This implementation again extends the agent_class_naive class by replacing the buy_products method. The algorithm makes two passes through the list of unlocked investments. The fist pass is copied below:\n# find building with max revenue per second and it\u0026#39;s cost max_rps,cost_max_rps = 0, float(\u0026#39;inf\u0026#39;) building_to_buy,product_to_buy = [], [] for i,building in enumerate(self.building_info): # get rps for building cur_rps = self.building_info[building][\u0026#39;cps\u0026#39;] # if it\u0026#39;s the best rps far, update max, cost, and building id if cur_rps \u0026gt; max_rps: max_rps,building_to_buy = cur_rps,building cost_max_rps = self.building_info[building][\u0026#39;price\u0026#39;] product_to_buy = products[i] # queue this building to buy Similar to that used in the MaxROI agent, this code is an \\(O(N)\\) search through the \\(N\\) unlocked buildings. It logs the maximum revenue in max_rps and the building associated with this revenue in building_to_buy, as well as the web element to click in order to purchase this building, product_to_buy.\nThen the agent computes \\(w_{max}\\) with:\nwait_max = float(cost_max_rps) / self.revenue if self.revenue else 0 # stops division by 0 The (value) if (condition) else 0 is used to stop division by 0 – if self.revenue is 0, then wait_max will take the value 0 rather than the computed value which is undefined when self.revenue is 0.\nNext, another pass through the list of buildings, this time searching for a building that will reduce the wait time:\nfor i,building in enumerate(self.building_info): cost_cur = self.building_info[building][\u0026#39;price\u0026#39;] rps_cur = self.revenue + self.building_info[building][\u0026#39;cps\u0026#39;] # conditional to stop division by 0 wait_till_cur = float(cost_cur) / self.revenue if self.revenue else 0 wait_cur = (wait_till_cur + cost_max_rps / rps_cur) if wait_cur \u0026lt;= wait_max: wait_max = wait_cur # update minimum wait building_to_buy = building product_to_buy = products[i] # queue this building to buy instead Here the MinWait agent gets the cost of a candidate investment, cost_cur and the revenue that would be attained if this investment is bought rps_cur. Then computes the time before this candidate investment could be bought at the current revenue, wait_till_cur and finally computes \\(w_b\\), the wait until the maximum revenue option could be bought if the candidate investment is bought first as wait_cur. Lastly, if this is lower than wait_max (\\(w_{max}\\)), then the agent stores the best wait in wait_max and updates the building to buy and the web element to click.\nLike the MaxROI agent, the last few lines of code check if the investment is affordable, and if not, terminates the ends the purchasing loop.\n  Performance Each agent class was instantiated as agent and run for 100,000 big cookie clicks, with the purchase logic run after every 200 clicks. The Naive, MaxROI, and MinWait agents ran for approximately 3650 seconds, 3785 seconds, and 3800 seconds, respectively. The differences in runtime were small enough that I wasn’t worried about differences in the performance metrics below being attributable to extra income earned from a longer runtime.\nRevenue First I looked at the main metric, revenue per second, shown in the figure below:\n The MaxROI and MinWait strategies clearly performed better than the Naive strategy in terms of maximizing revenue per second. It also appeared that the MaxROI algorithm generally had higher revenue when in a purchasing cycle, but the MinWait algorithm surpassed the MaxROI algorithm when waiting for a large purchase.\n Building Count  The Naive agent purchases each investment at about the same rate. At the other extreme, MinWait agent generally saves for the highest revenue option, then occasionally buys cheaper options to reduce the wait until the next purchase of the highest revenue option. This is most clearly seen in the spikes across buildings soon after a new, expensive, building is purchased. Like the Naive agent, the MaxROI agent also buys each investment frequently, however this agent prioritizes the investments that give the best return on investment.\n Building Prices  The Naieve strategy results in equalizing prices, while both the MaxROI and MinWait strategies can save to purchase the most expensive investment.\n Return on Investment (Revenue Per Cost)  The Naive strategy rarely chooses the best ROI option. The MaxROI strategy equalizes the ratio between revenue and price across the investments, while the MinWait strategy similarly picks options with a good ratio here but also frequently chooses worse deals. Overall the Naive and MinWait strategies often end up paying more than they should for revenue.\n  Conclusions Both the MaxROI and MinWait agents perform far better than the Naive agent in terms of maximizing revenue. The MaxROI agent performed better when in a buying cycle, but the MinWait agent surpassed the MaxROI agent during long periods of saving for an expensive purchase. Perhaps a better algorithm would be a hybrid that follows the MaxROI strategy when all revenues are known, and uses the MinWait strategy when saving up for an expensive option with an unknown revenue.\n Appendix: MinWait Decision is Independent of Balance Another consideration for the MinWait strategy was that the balance could reduce wait overall, and this might mathematically result in a preference reversal if the wait for \\(b\\) becomes negligably small. Accounting for balance and using \\(c_{max}\\) to represent the cost of the maximum revenue option, \\(r_t\\) to represent the current revenue, \\(c_b\\) to represent the cost of another investment, and \\(r_b\\) to be the additional revenue provided by that investment, the wait time calculations become;\n\\[ \\begin{aligned} w_{max} \u0026amp;= \\frac{c_{max}-balance}{r_t} \\\\ w_{b} \u0026amp;= \\frac{c_b-balance}{r_t} + \\frac{c_{max}}{r_t+r_b} \\end{aligned} \\]\nThe the decision rule can be cast as: buy \\(b\\) if \\(w_{max} - w_{b}\u0026lt;0\\). This results in the decision function:\n\\[ \\begin{aligned} w_{max} - w_{b} \u0026amp; = \\frac{c_{max}-balance}{r_t} - \\left(\\frac{c_b-balance}{r_t} + \\frac{c_{max}}{r_t+r_b}\\right) \\\\ \u0026amp;= \\frac{c_{max}-balance-c_b+balance}{r_t} + \\frac{c_{max}}{r_t+r_b} \\\\ \u0026amp;= \\frac{c_{max}-c_b}{r_t} + \\frac{c_{max}}{r_t+r_b} \\\\ \\end{aligned} \\]\nThe same function results from \\(w_{max}=\\frac{c_{max}}{r_t}\\) and \\(w_{b} = \\frac{c_b}{r_t} + \\frac{c_{max}}{r_t+r_b}\\), hence the decision does not depend on balance.\n Helper Functions The base agent class, agent_class_naive, contained many helper functions as well as the naive investment purchasing logic. This section explains the code used for the helper functions.\nBrowser and Game Initialization The agent was initialized with a web driver object stored in driver. The first part of the agent class __init__ method is copied below:\nclass agent_class_naive: def __init__(self,driver): # navigate to site driver.get(\u0026#39;https://orteil.dashnet.org/cookieclicker/\u0026#39;) time.sleep(10) # time for page to load self.big_cookie = driver.find_element_by_id(\u0026#39;bigCookie\u0026#39;) self.golden_cookie_clicks = 0 # initialize balance and revenue variables self.balance=0 self.revenue=0 # initialize balance and revenue logs self.log_balance=[0] self.log_revenue=[0] self.log_bal_rev_epoch=[0] # initialize building info, and logs of building info self.get_building_info() self.log_build_info = dict() self.building_info_logger(epoch=0) ... First the agent navigates the webdriver to the Cookie Clicker URL and pauses for 10 seconds to let the page load. After that, the agent finds the big cookie web element and assigns it to attribute big_cookie. The remaining lines above initialize various attributes that were either used in purchasing logic, or used to log data on agent performance.\nThe second part of the __init__ method navigated to the ‘options’ tab and changed the game settings. One important setting to change was the numbersButton option – this toggled between displaying numbers numerically, ‘1,000,000’, versus with words, ‘1 million’. Since the balance is scraped from this text, the agents require that numbers be displayed numerically. The other changed settings related to graphics and game performance. Code for this second part of __init__ is shown below:\n # CHANGE GRAPHICS AND OTHER SETTINGS # click \u0026#39;options\u0026#39; tab driver.find_element_by_id(\u0026quot;prefsButton\u0026quot;).click() time.sleep(1) # let page load # disable text instead of numbers, e.g. \u0026#39;million\u0026#39; -\u0026gt; \u0026#39;000,000\u0026#39; driver.find_element_by_id(\u0026quot;numbersButton\u0026quot;).click() # slide volume to around 25% time.sleep(.5) # so actions don\u0026#39;t happen too fast volume = driver.find_element_by_class_name(\u0026quot;slider\u0026quot;) move = ActionChains(driver) move.click_and_hold(volume).move_by_offset(-50, 0).release().perform() # change graphics for optimal performance buttons = (\u0026quot;fancyButton\u0026quot;,\u0026quot;particlesButton\u0026quot;,\u0026quot;cursorsButton\u0026quot;, \u0026quot;milkButton\u0026quot;,\u0026quot;wobblyButton\u0026quot;,\u0026quot;cookiesoundButton\u0026quot;, \u0026quot;formatButton\u0026quot;,\u0026quot;extraButtonsButton\u0026quot;,\u0026quot;customGrandmasButton\u0026quot;) for button in buttons: time.sleep(.5) # so actions don\u0026#39;t happen too fast to execute driver.find_element_by_id(button).click()  Clicking Cookies A simple, important function, click_cookie() effects the cookie click. The game also has golden cookies that provide a large lump sum of cookies, or transient increases in revenue. Golden cookies appear at random times, and at random locations on the screen. The second function below identifies and clicks these golden cookies until there are no more golden cookies on the screen, and logs the number of golden cookie clicks.\n def click_cookie(self): self.big_cookie.click() def click_golden_cookie(self): golden_cookies = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;shimmer\u0026quot;]\u0026#39;) while len(golden_cookies)\u0026gt;0: # if there are products, and while we can afford products, for golden_cookie in golden_cookies: golden_cookie.click() # buy each one self.golden_cookie_clicks+=1 golden_cookies = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;shimmer\u0026quot;]\u0026#39;)  Purchasing Upgrades Upgrades are another way to spend cookies. The function below finds affordable upgrades and purchases (click) them, starting with the most expensive avilable upgrade.\n def buy_upgrades(self): upgrades = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;crate upgrade enabled\u0026quot;]\u0026#39;) while len(upgrades)\u0026gt;0: # if there are products, and while we can afford products, try: upgrades[-1].click() # buy each one, most expensive first except: None upgrades = driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;crate upgrade enabled\u0026quot;]\u0026#39;)  Logging balance and revenue Balance and revenue were important for some strategies and were logged as a metric to compare the agents. To facilitate both use cases, I created a method that took an argument epoch. This method parses the text above the big cookie to convert a string like ‘177 cookies \\n per second: 1.1’ to extract the balance of 177 and revenue of 1.1. If the method is called without an epoch, then it only updates the balance and revenue. Alternatively, if an epoch is passed, then this method also logs the balance, revenue, and eopch or click number. The code for this is shown below:\n def log_balance_and_revenue(self,epoch=None): # parse string with balance and revenue tmp = driver.find_elements_by_xpath(\u0026#39;//div[@id=\u0026quot;cookies\u0026quot;]\u0026#39;) tmp = tmp[0].text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;) # remove camas 1,000 -\u0026gt; 1000 tmp = re.findall(\u0026quot;\\d+\u0026quot;,tmp) # extract balance and revenue tmp = [int(i) for i in tmp] # convert str -\u0026gt; int # update balance and revenue self.balance = tmp[0] # update current balance self.revenue = tmp[1] # update revenue # if epoch passed, log balance and revenue at this epoch if epoch: self.log_bal_rev_epoch.append(epoch) # index for balance and revenue self.log_balance.append(tmp[0]) # log balance self.log_revenue.append(tmp[1]) # log revenue  Get building information Building information like the cost and revenue was used in purchasing logic. The code used to extract this is shown below, and each component is elaborated on afterwards:\n def get_building_info(self): # get unlocked products products_unlocked = (driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked enabled\u0026quot;]\u0026#39;) + driver.find_elements_by_xpath(\u0026#39;//div[@class=\u0026quot;product unlocked disabled\u0026quot;]\u0026#39;)) # info for unlocked buildings building_info = dict() for i,building in enumerate(products_unlocked): # get info from building button tmp=building.text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;).split(sep=\u0026quot;\\n\u0026quot;) building_name,building_price,building_count = tmp if len(tmp)==3 else tmp+[0] # initialize dict for building building_info[building_name] = dict() # fill in count and price building_info[building_name][\u0026#39;count\u0026#39;]=int(building_count) building_info[building_name][\u0026#39;price\u0026#39;]=int(building_price) # get info from building tooltip hover = ActionChains(driver).move_to_element(building) hover.perform() tooltip = driver.find_elements_by_xpath(\u0026#39;//div[@id=\u0026quot;tooltip\u0026quot;]\u0026#39;) tmp=tooltip[0].text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;); tmp_cps = re.findall(r\u0026quot;produces [-+]?\\d*\\.\\d+|produces \\d+\u0026quot;,tmp); # \u0026gt; \u0026#39;produces X\u0026#39; if tmp_cps: # if building has been purchased tmp_cps_2=float(re.findall(r\u0026quot;[-+]?\\d*\\.\\d+|\\d+\u0026quot;,tmp_cps[0])[0]) building_cps = tmp_cps_2 else: # if building hasn\u0026#39;t been purchased, store cps as infinity building_cps = float(\u0026#39;inf\u0026#39;) # \u0026gt; X #### default of inf below encourages purchasing unlocked, unowned buildings #building_cps = float(tmp_cps[0][:tmp_cps[0].find(\u0026#39; \u0026#39;)]) if tmp_cps else float(\u0026#39;inf\u0026#39;) building_info[building_name][\u0026#39;cps\u0026#39;]=building_cps building_info[building_name][\u0026#39;cps/price\u0026#39;]=building_cps/int(building_price) self.building_info = building_info This code first obtains a list of the buildings that are unlocked, products_unlocked, then iterates over these to extract the relevant information: count or number owned, price of the next building, revenue, and the revenue to price ratio. Count and price could be obtained by parsing the text on the building button. This was done in the the following lines:\n# get info from building button tmp=building.text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;).split(sep=\u0026quot;\\n\u0026quot;) building_name,building_price,building_count = tmp if len(tmp)==3 else tmp+[0] # initialize dict for building building_info[building_name] = dict() # fill in count and price building_info[building_name][\u0026#39;count\u0026#39;]=int(building_count) building_info[building_name][\u0026#39;price\u0026#39;]=int(building_price) Revenue could only be obtained from a tooltip that appeared when the mouse hovered over the building button. The code below effects a mouse hover over the building, then extracts and parses the text from the building tooltip;\n# get info from building tooltip hover = ActionChains(driver).move_to_element(building) hover.perform() tooltip = driver.find_elements_by_xpath(\u0026#39;//div[@id=\u0026quot;tooltip\u0026quot;]\u0026#39;) tmp=tooltip[0].text.replace(\u0026#39;,\u0026#39;,\u0026#39;\u0026#39;); tmp_cps = re.findall(r\u0026quot;produces [-+]?\\d*\\.\\d+|produces \\d+\u0026quot;,tmp); if tmp_cps: # if building has been purchased tmp_cps_2=float(re.findall(r\u0026quot;[-+]?\\d*\\.\\d+|\\d+\u0026quot;,tmp_cps[0])[0]) building_cps = tmp_cps_2 else: # if building hasn\u0026#39;t been purchased, store cps as infinity building_cps = float(\u0026#39;inf\u0026#39;) One challenge was that the revenue was only viewable for owned buildings. To address this, I assumed a revenue of infinity for unowned buildings. This would incentivise agents that bought based on revenue to save and purchase the new building – which was reasonable because these buildings had higher revenue than the owned buildings. The last few lines in the code chunk above extract the revenue for owned buildings, and impute a revenue of infinity for unlocked but unowned buildings.\nFinally, the last few lines of code log the revenue and the return on investment (revenue divided by price) for each building and store the updated building information.\nSince this method was long already, I used a seperate method when logging this information. This logging function is shown below:\n def building_info_logger(self,epoch): if self.building_info: # if self.building_info exists # modified from get_building_info to append. log_keys = [\u0026#39;count\u0026#39;,\u0026#39;price\u0026#39;,\u0026#39;cps\u0026#39;,\u0026#39;cps/price\u0026#39;] # info for unlocked buildings for building in self.building_info: # initialize new buildings if building not in self.log_build_info: self.log_build_info[building] = dict() for k in log_keys+[\u0026#39;epoch\u0026#39;]: self.log_build_info[building][k]=[] # fill in count,price,cps, cps/price for k in log_keys: self.log_build_info[building][k].append(self.building_info[building][k]) # log epoch, within each building since buildings become available at different times self.log_build_info[building][\u0026#39;epoch\u0026#39;].append(epoch)    ","date":1564761393,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564761393,"objectID":"8545f58c4d8ed3e53d61205996e6eb2a","permalink":"/MacStrelioff/data-science/cookie_clicker_images/cookie-clicker-bot/","publishdate":"2019-08-02T15:56:33Z","relpermalink":"/MacStrelioff/data-science/cookie_clicker_images/cookie-clicker-bot/","section":"data-science","summary":"Overview Background and Setup Cookie Clicker Game  Agents Naive: Buy all affordable investments MaxROI: Buy best return on investment MinWait: Buy what minimizes the time to the highest revenue purchase  Performance Revenue Building Count Building Prices Return on Investment (Revenue Per Cost)  Conclusions Appendix: MinWait Decision is Independent of Balance Helper Functions Browser and Game Initialization Clicking Cookies Purchasing Upgrades Logging balance and revenue Get building information     Overview Lately I’ve been interested in writing algorithms (agents) that interact with websites.","tags":null,"title":"Cookie Clicker Agent","type":"data-science"},{"authors":["Mac Strelioff"],"categories":null,"content":" Supplementary notes can be added here, including code and math.   ","date":1554620400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554620400,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/MacStrelioff/publication/preprint/","publishdate":"2019-04-07T00:00:00-07:00","relpermalink":"/MacStrelioff/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["Mac Strelioff"],"categories":[],"content":" from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and Jupyter Install Anaconda which includes Python 3 and Jupyter notebook.\nOtherwise, for advanced users, install Jupyter notebook with pip3 install jupyter.\nCreate a new blog post as usual Run the following commands in your Terminal, substituting \u0026lt;MY_WEBSITE_FOLDER\u0026gt; and my-post with the file path to your Academic website folder and a name for your blog post (without spaces), respectively:\ncd \u0026lt;MY_WEBSITE_FOLDER\u0026gt; hugo new --kind post post/my-post cd \u0026lt;MY_WEBSITE_FOLDER\u0026gt;/content/post/my-post/  Create or upload a Jupyter notebook Run the following command to start Jupyter within your new blog post folder. Then create a new Jupyter notebook (New \u0026gt; Python Notebook) or upload a notebook.\njupyter notebook  Convert notebook to Markdown jupyter nbconvert Untitled.ipynb --to markdown --NbConvertApp.output_files_dir=. # Copy the contents of Untitled.md and append it to index.md: cat Untitled.md | tee -a index.md # Remove the temporary file: rm Untitled.md  Edit your post metadata Open index.md in your text editor and edit the title etc. in the front matter according to your preference.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/MacStrelioff/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/MacStrelioff/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/MacStrelioff/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/MacStrelioff/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" Basic Applied Model Comparison: F-test for nested models  Model Comparison: F-test, all parameters in a model  Correlation: R-square and correlation  Correlation: Partial correlation  Correlation: Part correlations   --- ","date":1536476400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536476400,"objectID":"3a02829a684d4e7a4157c7113ea70cac","permalink":"/MacStrelioff/video-lectures/basic-statistics/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/video-lectures/basic-statistics/","section":"video-lectures","summary":" Basic Applied Model Comparison: F-test for nested models  Model Comparison: F-test, all parameters in a model  Correlation: R-square and correlation  Correlation: Partial correlation  Correlation: Part correlations   --- ","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"Check back later\u0026hellip;\n --- ","date":1536476400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536476400,"objectID":"e7d4a56c1a53559b9d1870c69c485368","permalink":"/MacStrelioff/video-lectures/fun/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/video-lectures/fun/","section":"video-lectures","summary":"Check back later\u0026hellip;\n --- ","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":" H1 In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nH3 123\nTip 2 \u0026hellip;\n","date":1536476400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536476400,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/MacStrelioff/tutorial/example/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/tutorial/example/","section":"tutorial","summary":"H1 In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nH3 123\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":null,"categories":null,"content":" true  H1 In this tutorial, I’ll share my top 10 tips for getting started with Academic:\nTip 1 plot(rnorm(20),runif(20)) …\nH3 123\n  Tip 2 …\n  ","date":1536476400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536476400,"objectID":"cfe2453ca8d8ae42ddecf626ed999e22","permalink":"/MacStrelioff/tutorial2/example/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/MacStrelioff/tutorial2/example/","section":"tutorial2","summary":" true  H1 In this tutorial, I’ll share my top 10 tips for getting started with Academic:\nTip 1 plot(rnorm(20),runif(20)) …\nH3 123\n  Tip 2 …\n  ","tags":null,"title":"Example Page","type":"docs"},{"authors":null,"categories":null,"content":"","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/MacStrelioff/project/external-project/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/MacStrelioff/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/MacStrelioff/project/internal-project/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/MacStrelioff/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Mac Strelioff"],"categories":null,"content":" Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n Setup Academic Get Started View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Color Themes Academic comes with day (light) and night (dark) mode built-in. Click the sun/moon icon in the top right of the Demo to see it in action!\nChoose a stunning color and font theme for your site. Themes are fully customizable and include:\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461135600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555484400,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/MacStrelioff/post/getting-started/","publishdate":"2016-04-20T00:00:00-07:00","relpermalink":"/MacStrelioff/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Mac Strelioff"],"categories":null,"content":" Supplementary notes can be added here, including code and math.   ","date":1441090800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441090800,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/MacStrelioff/publication/journal-article/","publishdate":"2015-09-01T00:00:00-07:00","relpermalink":"/MacStrelioff/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"ca77a28b841b271a15d5420351f3e354","permalink":"/MacStrelioff/post/2015-07-23/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/MacStrelioff/post/2015-07-23/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["Mac Strelioff","Robert Ford"],"categories":null,"content":" Supplementary notes can be added here, including code and math.   ","date":1372662000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372662000,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/MacStrelioff/publication/conference-paper/","publishdate":"2013-07-01T00:00:00-07:00","relpermalink":"/MacStrelioff/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":" Sources / Alternatives  Netflix Experimentation and Sequential Testing Optamizely Google Analytics   TODO: redo in Python, make an agent that uses each strategy as a method. Build the agent throughout the script.   Intro Scientists and business students are trained in decision making from an outdated perspective – classical decision making based on p-values.\n(make a case against p-values – inflated error rates, incoherence, difficulty integrating with expected value)\n Bandit Algorithms Much of this is from this blog.\nHere I evaluate different algorithms for bandit problems similar to those anticipated in industry or testing settings. Criteria of consideration are;\nProblem Formalization Bandit tasks can be cast as a Markov Decision Process.\n\\[ \\begin{aligned} t \u0026amp;\\in \\{1,...,T\\} \\\\ a_t \u0026amp;\\in \\mathcal{A} \\\\ s_t \u0026amp;\\in \\mathcal{S} \\\\ r_t \u0026amp;= R(s_{t+1}|a_t,s_t) = v(s_{t+1}|a_t,s_t) \\\\ T(s_{t+1}|a_t,s_t) \u0026amp;= p(s_{t+1}|a_t,s_t) \\\\ \\pi(s_t)\u0026amp;=p(a_t|s_t) \\end{aligned} \\]\n\\(\\pi\\) is referred to as a policy or decision rule. Mathematically, it is a probability distribution over actions – a funciton that maps from states to actions.\nThe decision maker’s goal here is to learn a policy (\\(\\pi\\)) that is optimal for some criteria. A variety of possible criteria are discussed and evaluated below. This objective is considered when chooseing the value function \\(v(s_{t+1}|a_t,s_t)\\).\nObjective is to maximize \\[ E\\left(\\sum_t r_t\\right)=\\sum_tE(r_t) \\]\nIn a typical testing scenario, the policy replaces the assignment mechanism. Hence, I treat assignment mechanisms as policies here.\n Use Cases and Evaluation Criteria Bandit problems arise across many theoretical and applied fields. Everything from industry A/B testing, medical clinical trials, experimental lab studies, and toy problems for reinforcement learning algorithms can be cast as a bandit task. These different domains generally have different goals. A/B tests are conducted to find evidence for an advantage of one version of a product over another while emphasizing classical statistical objectives like minimizing type I error rates or false discovery rates. The goal of clinical experiments is to quickly discover the best treatment so that patient lives can be improved or saved. In simulation settings, bandit problems have been used to benchmark a variety of algorithms in terms of regret. Here I conduct similar benchmarks, while also evaluating standard ‘best proctices’ in terms of type I error rates and false discovery rates.\nType I Error Among situations where there is no difference, how often is a difference detected?\nType I error occurs when a null hypothesis is reongly rejected – so when a difference in outcomes of arms is detected when none actually exists.\n False Discovery Rate Among detected differences, how many are real?\nA false discovery occurs when an arm is selected but is not the actual optimal arm.\nI’ll consider this on a trial-by-trial level as well as the result of the overall experiment.\n Regret Regret is the difference between the reward that would have been obtained had the optimal action been chosen, and the reward that was actually obtained from the chosen action.\n\\[ \\begin{aligned} E(Regret) \u0026amp;= \\sum_t E(r^*_{t}-r_t) \\end{aligned} \\]\n  Uniform Policy This corresponds to a simple random sample type of assignment mechanism – the gold standard for causal inference from experimental data.\n\\[ \\begin{aligned} \\pi(s_t) \u0026amp;= \\frac{1}{|\\mathcal{A}|} \\\\ E(Regret) \u0026amp;= TE(r^*_t) - \\sum_t E(r_t|\\pi) \\\\ \u0026amp;= T(E(r^*_t) - E(r_t)) \\\\ \\end{aligned} \\]\nThe expected regret on each trial is the difference between the maximal reward and mean reward across actions.\n Greedy Policies \\(\\epsilon\\)-Greedy Policy  Softmax Policy Might be good for parameter estimation while also reducing regret.\nna=5 # Number of arms as=1:na # action IDs beta = 5 R = runif(na) # arm probabilities #R[1]=1; R[2]=.5; R[3]=0 T = 1500 # Number of trials q=rep(0,na) pis = c() qs = c() ats = c() rts = c() regret = c() regrett= 0; for(ti in 1:T){ # select action pi = exp(beta*q)/sum(exp(beta*q)) at = rmultinom(n=1,size=as,prob=pi) at = which(at==1) # observe outcome rt = rbinom(1,size=1,prob=R[at]) # save stats pis = rbind(pis,pi) ats = c(ats,at) rts = c(rts,rt) # update action values q[at] = q[at] + .2 * (rt - q[at]) qs = rbind(qs,q) # regret regrett= regrett+max(R)-R[at] regret = c(regret,regrett) } plot(regret,type=\u0026quot;l\u0026quot;) cols = rainbow(na,s=1,v=.7) for(ai in as){ if( ai\u0026gt;1){par(new=TRUE)} plot(qs[,ai],type=\u0026quot;l\u0026quot;,ylim=c(0,1),col=cols[ai], main=\u0026quot;Estimation\u0026quot;, ylab=\u0026quot;Q-value\u0026quot;, xlab=\u0026quot;Trial\u0026quot;) abline(h=R[ai],col=cols[ai],lty=2) } for(ai in as){ if( ai\u0026gt;1){par(new=TRUE)} plot(pis[,ai],type=\u0026quot;l\u0026quot;,ylim=c(0,1),col=cols[ai], main=\u0026quot;Action Probabilities\u0026quot;, ylab=\u0026quot;Policy\u0026quot;, xlab=\u0026quot;Trial\u0026quot;) #abline(h=R[ai],col=cols[ai],lty=2) } ent = 0 ps=c() for(ai in as){ p = sum(ats==ai)/length(ats) ent = ent + p*(-log2(p)) ps=c(ps,p) } c(ent,ps) ## [1] 1.41206826 0.01533333 0.68200000 0.03400000 0.14333333 0.12533333 c(entropy.empirical(table(ats),unit=\u0026quot;log2\u0026quot;),freqs.empirical(table(ats))) ## 1 2 3 4 5 ## 1.41206826 0.01533333 0.68200000 0.03400000 0.14333333 0.12533333   Upper Confidence Bound (UCB) Policy  Thompson Sampling Policy #na=5 # Number of arms #as=1:na # action IDs #beta = 5 # keeps same as those above # R = runif(na) # arm probabilities #T = 5000 # Number of trials #priors: rows: actions, col1:alpha, col2:beta prior = matrix(1,nrow=na,ncol=2) aposts=c() bposts=c() thompsonSamples = c() ats = c() rts = c() regret = c() regrett= 0; for(ti in 1:T){ # select action thompsonSample=c() for(ai in as){ thompsonSample = c(thompsonSample,rbeta(1,prior[ai,1],prior[ai,2])) } at = which.max(thompsonSample) # observe outcome rt = rbinom(1,size=1,prob=R[at]) # save stats thompsonSamples = rbind(thompsonSamples,thompsonSample) ats = c(ats,at) rts = c(rts,rt) # update beta distributions prior[at,1]=prior[at,1]+rt prior[at,2]=prior[at,2]+(1-rt) # save posterior parameters aposts=rbind(aposts,prior[,1]) bposts=rbind(bposts,prior[,2]) # regret regrett= regrett+max(R)-R[at] regret = c(regret,regrett) } plot(regret,type=\u0026quot;l\u0026quot;, main=\u0026quot;Regret = max E(reward) - E(reward|choice)\u0026quot;, ylab=\u0026quot;Cumulative Regret\u0026quot;, xlab=\u0026quot;Trial\u0026quot;) # something might be wrong with rbeta(x,vec1,vec2) cols = rainbow(na,s=1,v=.7) for(ai in as){ if( ai\u0026gt;1){par(new=TRUE)} plot(aposts[,ai]/(aposts[,ai]+bposts[,ai]),type=\u0026quot;l\u0026quot;,ylim=c(0,1),col=cols[ai], main=\u0026quot;Reward Probability Estimation\u0026quot;, ylab=\u0026quot;Posterior Means\u0026quot;, xlab=\u0026quot;Trial\u0026quot;) abline(h=R[ai],col=cols[ai],lty=2) } legend(1100,.8,c(\u0026quot;Estimate\u0026quot;,\u0026quot;True\u0026quot;),lty=c(1,2)) for(ai in as){ if( ai\u0026gt;1){par(new=TRUE)} plot(thompsonSamples[,ai],type=\u0026quot;l\u0026quot;,ylim=c(0,1),col=cols[ai], main=\u0026quot;Posterior Samples\u0026quot;, #ylab=expression(\u0026#39;Sampled Value -- Policy=argmax\u0026#39;[\u0026#39;a\u0026#39;]*\u0026#39;(sample\u0026#39;[\u0026#39;a\u0026#39;]*\u0026#39;)\u0026#39;), ylab=expression(\u0026#39;Sampled Value\u0026#39;), xlab=\u0026quot;Trial\u0026quot;) #abline(h=R[ai],col=cols[ai],lty=2) } ent = 0 ps=c() for(ai in as){ p = sum(ats==ai)/length(ats) ent = ent + p*(-log2(p)) ps=c(ps,p) } c(ent,ps) ## [1] 0.109426242 0.001333333 0.988666667 0.003333333 0.001333333 0.005333333 c(entropy.empirical(table(ats),unit=\u0026quot;log2\u0026quot;),freqs.empirical(table(ats))) ## 1 2 3 4 5 ## 0.109426242 0.001333333 0.988666667 0.003333333 0.001333333 0.005333333   Policy Comparisons  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e63993d0b6bdc1a53b39e8c13704179f","permalink":"/MacStrelioff/unlisted/banditalgos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/unlisted/banditalgos/","section":"Unlisted","summary":"Sources / Alternatives  Netflix Experimentation and Sequential Testing Optamizely Google Analytics   TODO: redo in Python, make an agent that uses each strategy as a method. Build the agent throughout the script.   Intro Scientists and business students are trained in decision making from an outdated perspective – classical decision making based on p-values.\n(make a case against p-values – inflated error rates, incoherence, difficulty integrating with expected value)","tags":null,"title":"Bandit Algos for Estimation, Hypothesis Testing, and Decision Making","type":"Unlisted"},{"authors":null,"categories":null,"content":" Sources / Alternatives https://superuser.com/questions/214759/connect-to-another-mac-via-terminal\nUseful terminal commands:\nsudo shutdown # powers off  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"32a484bbcffac66103d8d81bd6bc87b8","permalink":"/MacStrelioff/unlisted/runningremotejobs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/unlisted/runningremotejobs/","section":"Unlisted","summary":" Sources / Alternatives https://superuser.com/questions/214759/connect-to-another-mac-via-terminal\nUseful terminal commands:\nsudo shutdown # powers off  ","tags":null,"title":"Bandit Algos for Estimation, Hypothesis Testing, and Decision Making","type":"Unlisted"},{"authors":null,"categories":null,"content":" Background As part of my fellowship at Insight Data Science, I worked on a 2 week consulting project with an external company. Their product was a SaaS application enabling team collaboration on shared files, and has a 30-day free trial model. Multiple users can be associated with an account, and users can have different roles that enable different privileges within the service. The overall goal was to identify free trial accounts that would convert to subscription-based paying customers.\nAt the request of the client, some of the information in this post has been masked so as to not reveal any confidential information.\n Business Need The survival of any company hinges on it’s ability to acquire new users. However, the majority of free trial users for my client failed to convert to customers. This leaves much opportunity to increase their userbase.\nProject Goals As a consultant, I helped with two major goals focused on issuing nudges to users in order to increase user acquisition:\nIdentify, as early as possible, patterns in user behavior that indicate whether a free trial user is likely to become a customer after the trial. Leverage those patterns to identify outreach strategies for users that might otherwise be unlikely to continue using the service..    Data sources and processing The original dataset consisted of account activity and product performance data for all accounts over a one year period. The dataset contained a large number of accounts, including some that were not germane to the project goals. Since the primary goal focused on behavior during the free trial, I excluded any accounts that were never on a free trial during the data collection period. In exploratory analysis, I found a large number of accounts that showed little to no activity. This prompted me to believe there are two types of trial accounts that do not convert to paying customers – 1) accounts that were created then never engaged with the product, and 2) accounts that engaged with the product, then failed to find the product valuable and decided to stop engagement. Since the strategies to address these accounts might differ, I decided to exclude any account without a minimal degree of engagement with the product and focus on the \\(2^{nd}\\) type of nonconversion. The criteria for a minimal level of engagement was chosen based on dependencies between product features, and decided during discussion with the client. Finally, some product features were not available during the full duration of data collection, as the product evolved over time. Since there was a large sample size, the easiest way to make the analyses pertinent for all features, and to keep accounts comparable to one another, was to exclude data collected before all product features were available.\nFeature Engineering and Exploration The original account activity data was in terms of counts of each possible action (e.g. workspaces created) on each date during data collection. To make the accounts easily comparable regardless of observation dates, I created a variable for account age (days since the account was created). Also, rather than working with daily counts I computed cumulative sums, which represented an account’s total usage aggregated over all its users’ activity of a product feature up to a particular age of their account. Finally, to mitigate confounding of the counts of activity by the number of users, I divided the cumulative sums by the number of users. These were features that I focused on – total usage of each product activity per user up to a particular day since the creation of the account.\nThe time of conversion could be many months after a trial had ended, as it may take time for a user associated with an organization to gain approval to purchase a subscription, or it may take time for a large organization to negotiate a price with my client. To focus on classifying free users as potential customers based on activity, I created a variable that indicated whether an account ever ended up as a customer. I then conceptualized the problem as a classification problem where, based on account activity over time since the account’s creation, I estimated the probability that the account would ever convert to a customer.\nI initially thought that the accounts that converted would differ in terms of the distribution of these features (cumulative activity per user), relative to those that did not convert. Hence, in exploration, I focused on probing this intuition by plotting the median and \\(20^{th}\\) to \\(80^{th}\\) quantiles of cross sections of these features across account age, split by users who ended up converting versus those who did not. An example, focusing on the number of workspaces created per user, is shown in the figure below. Classification would be easiest and most interpretable if there were features that the converters clearly used more than those who never converted.\nMedian (solid line) and middle 60% (shading) of the distribution of cumulative workspaces created per user, split by those who ever paid (blue) and those that were on a free trial forever (red)\n   Modeling Considerations My intuition about differing distributions is natrually expressed in linear discriminant analysis or quadratic discriminant analysis. However, these algorithms hinge on an assumption that the features are Gaussian distributed, which was clearly not the case – values were strictly non-negative, and distributions were skewed such that there were lots of values around 0 and some values far from the mean. Because of these violations, I also considered a support vector classifier with radial basis functions, and tree based algorithms – random forests, and gradient boosting decision trees (GBT). An advantage of the tree-based approaches is their robustness to any distribution of the features, and any functional relationship between the features and the probability of an account continuing product use after the free trial.\nAnother issue was class imbalance, since the majority of accounts did not continue. I used SMOTE, an algorithm that generates synthetic data from the underrepresented class (continuing customers), to address the class imbalance when fitting the model in training sets. I also considered metrics beyond accuracy, such as AUC and the F1 score, when selecting a final model.\n Initial Performance To quickly hone in on a model, I assessed the algorithms mentioned above with default hyperparameter values using scikit learn in Python. I focused on classification accuracy in a test set, and the tree-based algorithms outperformed the others by approximately 10%. This outperformance is likely due to the non-standard distributions of the features.\n Hyperparameter Tuning To assess performance across hyperparameters for the tree-based algorithms, I created validation curves with 5-fold cross validation and a set of hyperparameter values. The performance of both tree based algorithms was mostly stable in terms of F1 scores, except for poor performance when there were very few (\\(\u0026lt;10\\)) estimators. To mitigate potential overfitting, I increased the minimum number of observations in a leaf to 10, but left all other hyperparameters at their default values.\n Fitting Procedure I fit the random forests and GBT algorithms to cross-sections of the data at 7, 14, and 30 days since account creation. For each cross section, I split the data into 5 folds, and used SMOTE when training the algorithms within each fold to account for the class imbalance. In each fold, I logged the feature importances and performance metrics from both algorithms.\n  Actionable Results I used the mean feature importances across folds from the GBT algorithm to identify the features that differentiated between successful accounts and accounts with users that may have needed more onboarding. Since these features seperate continuing accounts from those that did not continue after the free trial, these are the features to prioritize when considering interventions to add value to the user’s experience.\nMean (bar length) and standard deviation (black error bars) of feature importance evaluated across the 5 folds for the gradient boosting trees algorithm. Feature names have been obscured at the client’s request.\n To understand the form of the relationship between these features and continued engagement after the trial, I binned accounts based on product feature usage and plotted the proportion of accounts that continued using the product after the free trial across these bins. Figures like this, paired with data on an individual account activity, could help in personalizing user outreach to focus on aligning users’ feature usage with that of users in more successful accounts. For example, based on the figure below, if an account has fewer than 1 workspace per user, their experience might be improved by resources that make workspace creation easier to understand or engage with.\nProportion of accounts that convert as a function of workspaces per user. There seems to be a bump in conversion rates from around 20% to around 40% above around 1 workspace per user.\n To identify struggling accounts for outreach, I applied the GBT algorithm to all data and focused on the confusion matrix, shown below. Different actions could be taken with respect to accounts in each quadrant. Accounts in the bottom right quadrant are currently customers, and were identified as such by the algorithm. These are the accounts with users who were successful in identifying value in the product and establishing an ongoing relationship with my client. Accounts in the top right quadrant are those who have not yet become customers, but are engaging with the product in ways that are similar to those who have become customers. Users in these accounts have likely identified valuable aspects of the product, and could be contacted by a customer success team to help them find a subscription plan that suits their needs.\nAccounts on the top left and bottom left quadrants were identified as accounts that would not continue with the product after the free trial – these are the accounts that may benefit from outreach that demonstrates the value this product can add to their workflows. Accounts in the top left quadrant were correctly identified as accounts that would not continue with the product. Users in these accounts may have failed to identify valuable aspects of the product, and may have had a better experience if they had been contacted early by customer support or had access to educational resources that could have helped them use the product. Accounts in the bottom left quadrant are those that became paying customers, but were incorrectly identified as accounts that would not continue with the product based on their activity in the first 7 days. Misclassifying these accounts has essentially no harm, as it would only encourage efforts to improve their experience early in their trial.\n Summary I began with an intuition that accounts that converted would have a different distribution of product feature usage per user, relative to those that did not convert, when feature usage was assessed at cross sections based on account age. To explore this, I looked at the quantiles of distributions across feature usage. Focusing on this with formal models, I found that tree-based algorithms could perform well across accuracy, precision, recall, and F1 scores, in identifying the accounts that converted, based on daily snapshots of aggregate feature usage.\nTo derive insights from this data and analysis, I focused on confusion matrices which identified free trial accounts that acted as if they would continue product usage, and accounts that were currently unlikely to continue with the product (those in need of educational resources, and/or contact from support teams). I focused on the features found to be important by the tree based algorithms in order to identify specific features to target when reaching out to users in struggling accounts. To discover how feature usage relates to a propensity to continue using the product, I looked at the proportion of accounts that continued after trial across levels of engagement with the important product features.\nOverall, my work provided valuable tools for identifying accounts to connect with for long term relationships or for onboarding and educational assistance, as well as feature usage patterns indicative of success with the product.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"88d1e86fdf825201ff65160488a6e85c","permalink":"/MacStrelioff/consultingproject/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/consultingproject/","section":"","summary":"Background As part of my fellowship at Insight Data Science, I worked on a 2 week consulting project with an external company. Their product was a SaaS application enabling team collaboration on shared files, and has a 30-day free trial model. Multiple users can be associated with an account, and users can have different roles that enable different privileges within the service. The overall goal was to identify free trial accounts that would convert to subscription-based paying customers.","tags":null,"title":"Growing Smarter: Understanding User Acquisition","type":"page"},{"authors":null,"categories":null,"content":" Overview Here I breed ideas from hypothesis testing, with those from the machine learning community on evaluating classifiers.\n Hypothesis Testing Hypothesis testing is based on a notion of accepting or rejecting a hypothesis based on data from an experiment.\naccept, reject\nType I error –\nType II error –\n\\(\\alpha\\) \\(\\beta\\) power\nbase rates\nfalse discovery rate\n Classification Evaluation Calssification evaluation is based on selecting a model based on performance in out-of-sample performance. Many performance measures, that I’ll cover throughout, as they relate to concepts from hypothesis testing.\npositive (true), negative (false) true positive, true negative, false positive, false negative, …\nfalse discovery rates probably related to one of – accuracy, precision, recall, sensitivity, specificity\nclass imbalance (base rates)\nF1 score\n Hybrid Ideas Relate \\(\\alpha\\), \\(\\beta\\), and false discovery rate to accuracy, precision, recall.\nsensitivity and specificity\nSignal detection – hit, miss, false alarm?\nResources with more detail on each metric; Most ML metrics\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"df3c67c1e3083448aa76b96b8416852f","permalink":"/MacStrelioff/unlisted/hypothesesaremodels/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/unlisted/hypothesesaremodels/","section":"Unlisted","summary":"Overview Here I breed ideas from hypothesis testing, with those from the machine learning community on evaluating classifiers.\n Hypothesis Testing Hypothesis testing is based on a notion of accepting or rejecting a hypothesis based on data from an experiment.\naccept, reject\nType I error –\nType II error –\n\\(\\alpha\\) \\(\\beta\\) power\nbase rates\nfalse discovery rate\n Classification Evaluation Calssification evaluation is based on selecting a model based on performance in out-of-sample performance.","tags":null,"title":"Hypothesis Testing as Classifier Evaluation","type":"Unlisted"},{"authors":null,"categories":null,"content":" Overview: Made this doc to document my journey through the Insight Data Science program.\n1-3 work on project and professional skills. Week 4 work on demo. Weeks 5-8 deliver demo, work on interview preparation.\n Professional Skills Mindset (Day 1: 6/3/2019) Imposter syndrome\nFail quickly and iterate\nOpen mindedness – new problem space, …\nAdaptability, identify weakenesses and adapt\n Applying Identify strengths, and demonstrantions of value to a company\nLinkedIn workshop\n Resume hub page\nworkshop lecture\nResume is a marketing tool to get an interview. Resumes should be understood in 15-45 seconds.\nAudience:\nHiring managers   Wants: quickly hire, culture fit, compliments skillsets on team Dislike: lack of detail, ‘fluff’, verbose  Recruiter   Wants: Pass high quality Dislikes: Poor writing or grammer, “creative” resumes that take time to orient to, verbose  Convey:\n Technical fit for role Potential for learning and growth Unique professional value (differentiation)  Components:\nOrder from most to least impactful. Focus on content relevant for next role.\n Header, contact information. Location that is local to the company being applied to. LinkedIn should also include anything not on resume. Skills, core competencies for recruiter to check off required skills. Sort into meaningful clusters. Experience, for hiring manager. Include evidence of the skills. Talk about publications here, and emphasize their impact or value. Start with past-tense verb. Situation, Task, Action, Result. Education, also mainly for recruiters. Could include a section on specific courses, but would be more impactful as projects in the experience section. NO SUMMARY, experience is more valuable. Can put one on LinkedIn. Avoid making too specific (pidgenhole) or general (cliche).  Tips:\n Include numbers to quantify impacts, numbers can be salient relative to text. Include URLs, for those who read on paper. Consistent puncuation, … .   Pitch A pitch is a quick and compelling story used to start conversations.\n10 second:\n “Hi I’m (). I got my PhD in () where I used () to ()” “Hi I’m Mac. I got my PhD in Cognitive Science at UC Irvine, where I used reinforcement learning algorithms as models of how people learn about and interact with a new technology.”  30 second:\n Appeals to imagination and empathy to facilitate recall and decision-making Differentaites you as a leader rather than hopeful employee Creates a story from past experiences that clearly leads to the target job   Demos A demo is a presentation of work to a hiring committee.\nKinds of questions to anticipate:\n Very techinical questions Business sense Thought process – diagnostics, model selection, validation or definition of success Alternative approaches, and their strengths and weaknesses    Opportunities: Networking and Company Visits At Insight, data science hiring teams frequently visit. During the first week, we had visits from Square, Lab 41, and App Annie.\nAttempt:\n Ask questions to assess fit: size, hierarchy, business model / monetization Ask about experiences – “Tell me about a time when someone …”. This leads to an opportunity to make them feel heard and important, or to foster a sense of connection around a similar shared experience. Demonstrating curiosity and engagement, to foster a connection and sense of trust.  Avoid:\n “Questions” purely intended to demonstrate your own knowledge. Instead, introduce yourself after the talk. Trying to prove you are smarter than the conterparty, which can make them view you as a threat. Instead cooperate with them to foster trust. Implying that their company is inferior to a competitor, this can make them feel defensive and mitigate the potential for a trusting connection.  Profiling an opportunity Project lifecycles and autonomy?   How do data scientists get projects? What is the hierarchy? How often are check-ups with the team or managers?  Who are the colleagues?   Team composition – team size and roles? Background and expertise of team members?  Work culture   Company sponsored activities? Leanring or mentoring opportunities? Work hours / work from home policies? Vacation policies?  Next steps   Interview and onboarding process? Current projects?     Project Ideation (5/21-6/5) Prediction Market  Sentiment Analysis tools\nhttps://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e\nhttp://sentdex.com/sentiment-analysis/\n Stats Website Shiny app that generates practice problems and contains lessons\n Bandit Analysis good example\nhttps://blog.insightdatascience.com/multi-armed-bandits-for-dynamic-movie-recommendations-5eb8f325ed1d\ngood dashboarding\n Car price recommender (this has already been done on fb…)\nSync data from Facebook, Amazon, and Kelly Blue Book to find distributions over car prices, to empower buyers and sellers in social markets.\nI wanted to sell a car and didn’t know what it was worth.\nLearn the KBB API, setup a shiny app that allows one to enter KBB info, and query KBB and FB and Amazon for KBB price, and amazon and fb postings.\n Kaggle competition? Air bnb new user bookings\n Model a user’s behavior from landing on site to their first booking. Look for ways to improve bookings? – book in fewer searches, book in less time, … Do all NDF locations have a missing ‘date first booked’ variable? Does a missing ‘date_first_booked’ mean that the person did not book?  Google store revenue - few items - makeup items? - predict probability of purchasing an item\nFacebook checkin prediction - fake data…\n  Selection Data scientists make data products.\nAssess value\nWhat is the product? Why is this useful to a specific company? Why is it useful to users?  Assess feasibility\nWhat data is needed for this product? How much data is there, where does it come from? What technical methods are used? How could AI/ML improve the product? Are there any limits on data access or ethical constraints? How could it be monetized?  Assess potential\nHow might a company expand the product?   Guiding principles for analysis This wasn’t taught at insight, so I’m drawing on my training in statistics and model building here.\nThinking about Variables Think of the variables and their structure, before seeing data; confounds, precision, neusance, …    Thinking about Models Estimand\ninterpretation\nvalidation (CV)\nefficiency – computational, memory load\ndeployment\n  Consulting I applied for, and was awarded, a consulting project. This section describes notes on professional consulting relationships.\n populate from consulting class…  Constant communication to clarify goals and stay on track. It can be tempting or habitual to conduct an extravagent analysis without regard for its usefulness to the cliant – avoid this waste of time by continually checking in, presenting work, and clarifying the client’s goals and desired outcomes.\n Minimum Viable Product (MVP) Working model and actionable insights\n Final Deliverable Blog post describing the project\n Presentation or Demo  context need vision (‘stretch goal’) outcome  Demonstrate:\n Value of the solution Value of you – 1-2 years of salary, benefits, … Reasoning throughout the project.  Business Value Statement hub page\nSummarize project and its use case  “I’m using [data] to develop [deliverable] that [outcome] so that [client] can [solution to problem]”\nMine was: “I’m using daily user activity during a free trial to estimate the probability that the user will convert to a paid user, so that my client can decide when and how to nudge free users that are unlikely to convert”\nQuantify impact;   Statistics that give the scope of the problem What is the market, or how many potential customers exist? What resources, and how much, will the solution save?  “The fate of a start-up hinges on user acquisition.”\nBroaden use case. Convey the abstract or general challenge that was solved.\n Combine for final pitch\n  My value statement for this project was:\n“The fate of a start-up depends on user acquisition. I’m using data on user behavior during a free trial to estimate the probability that a free user will convert to a paid user, and determine which product features drive this conversion. My analysis will guide decisions about when and how to nudge the free users that are unlikely to convert, so that my client can acquire more paying users”\nThings to consider;\n Concise description of project Who are the potential users, how many exist? What problem is solved, evidence that it is a real problem What solutions already exist, how is yours better? How would this solution save time, money, emotional headache, … ? After watching the demo, what skills would the audiance know you can offer on Day 1? How will your demo make these skills explicit? Given the technical challenges of executing the project, who is going to be most excited to interview you? How does your project relate to the challenges they face? (specific companies, types of teams, industries, … )  Product: I’m conducting analyses on user demographics, and making a model to predict user conversion after a free trial.\nPotential users: My client. Various teams will use the demographic analyses.\nProblem: Want to know what features or experiences with the product are driving sales.\ncompetitors: none here.\nAfter demo: Summary stat skills for demographics, root cause analysis for finding features that drive conversion, feature engineering for the predictive model, ML model building and fitting. Interpreting data for a general audience.\nWho will like the presentation?: Collaborative teams, since I delivered a little for mutltiple teams. Teams that rely on data scientists for business decisions, since I worked actionably product insights.\n   Interview Preparation  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f63259ce0213d0353398ab77db038ab7","permalink":"/MacStrelioff/unlisted/insight/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/unlisted/insight/","section":"Unlisted","summary":"Overview: Made this doc to document my journey through the Insight Data Science program.\n1-3 work on project and professional skills. Week 4 work on demo. Weeks 5-8 deliver demo, work on interview preparation.\n Professional Skills Mindset (Day 1: 6/3/2019) Imposter syndrome\nFail quickly and iterate\nOpen mindedness – new problem space, …\nAdaptability, identify weakenesses and adapt\n Applying Identify strengths, and demonstrantions of value to a company","tags":null,"title":"Insight","type":"Unlisted"},{"authors":null,"categories":null,"content":" Recommendation Lots of recommendation algorithms\nData science methods play a major role in discovering recommendations for users.\nEcon, compliments and substitutes (competitors).\nTypes of recommendation; compliments (these go together), competitors (you might also like…), temporal (might buy this again in the future). Horizontal and vertical focus\nTemporal involves forecasting, which is a topic for another post.\n Sort Algorithms Lots of sort algorithms\n Search Algorithms Lots of search algorithms\n Ranking Algorithms Lots of ranking algorithms\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"676de85ee3cafb38225bcf5fac2ec817","permalink":"/MacStrelioff/unlisted/searchsortrank/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/unlisted/searchsortrank/","section":"Unlisted","summary":"Recommendation Lots of recommendation algorithms\nData science methods play a major role in discovering recommendations for users.\nEcon, compliments and substitutes (competitors).\nTypes of recommendation; compliments (these go together), competitors (you might also like…), temporal (might buy this again in the future). Horizontal and vertical focus\nTemporal involves forecasting, which is a topic for another post.\n Sort Algorithms Lots of sort algorithms\n Search Algorithms Lots of search algorithms","tags":null,"title":"Recommending: Searching, Sorting, Ranking","type":"Unlisted"},{"authors":null,"categories":null,"content":"  Overview Shiny apps UI: User Interface Server Components Rock Paper Scissors Agent Logic  Hosting Hosting locally Hosting online     Overview Here I document what I learned, and what resources I found helpful, while I was making my first Shiny app. Shiny apps are an easy way to make web apps from RStudio, with a syntax geared towards online dashboards. As a graduate student in an experimental psychology lab, I wondered if shiny apps could be used to host online experiments. My experiments were essentially simple games – there would be buttons that participants could press, and feedback that they would see based on their actions. I decided to make a rock-paper-scissors app to gain experience with Shiny apps and probe their utility as tools for hosting experiments. You can check out the app here (https://macstrelioff.shinyapps.io/rockpaperscissorsagent/) though I only have 25 hours a month of free hosting, so it may be down occasionally.\nThe source code for this app can be found on my GitHub here\n Shiny apps Shiny apps are primarily a tool for dashboarding. A dashboard is a tool that a data professional could create in order to communicate insights and actionable results to decision-makers. Ideally these apps enable decison-makers to easily interact with the data in a way that streamlines their decision making process. Many examples, with code, can be seen in the shiny app gallary – this was the primary resource I turned to while putting together my app.\nShiny apps are comprised of a user interface (UI) component and a server component; a common layout might look like this;\nlibrary(shiny) ui \u0026lt;- fluidPage() server \u0026lt;- function(input, output){} shinyApp(ui = ui, server = server) The ui will contain functions that control the layout of the page and the names of interactive components like buttons and sliders. The server defines how the page changes in response to events and user actions, and the final line shinyApp(ui=ui,server=server) runs the app. For hosting on shinyapps.io (described below), the script that runs the app must be called App.R.\nUI: User Interface My code for the user interface is shown below and broken down in this section;\nui \u0026lt;- fluidPage( # Application title titlePanel(\u0026quot;Rock Paper Scissors!\u0026quot;), # figure fluidRow( column(width=5, plotOutput(\u0026quot;distPlot\u0026quot;) ) ), # buttons fluidRow( column(width=5,offest=2, actionButton(\u0026quot;rock\u0026quot;,\u0026quot;Rock\u0026quot;), actionButton(\u0026quot;paper\u0026quot;,\u0026quot;Paper\u0026quot;), actionButton(\u0026quot;scissors\u0026quot;,\u0026quot;Scissors\u0026quot;) ) ), fluidRow(width=5,offset=5, textOutput(\u0026quot;result\u0026quot;),br(), p(\u0026quot;Source code available at: https://github.com/MacStrelioff/RockPaperScissors\u0026quot;) ) ) The fluidPage() function is named after a type of layout that adjusts to the dimensions of a browser. Functions within fluidPage() add elements to the webpage. titlePanel(\u0026quot;TITLE\u0026quot;) controls the large title at the top of a page. fluidRow() adds rows of elements to the page, the length of which are determined by the column() function. I add the figure with;\ncolumn(width=5, plotOutput(\u0026quot;distPlot\u0026quot;) ) Here plotOutput(\u0026quot;OUTPUT_NAME\u0026quot;) takes an output from the server function, described in the next section, and plots it. More information on reactive output can be found here.\nNext I create the row of buttons with;\n# buttons fluidRow( column(width=5,offest=2, actionButton(\u0026quot;rock\u0026quot;,\u0026quot;Rock\u0026quot;), actionButton(\u0026quot;paper\u0026quot;,\u0026quot;Paper\u0026quot;), actionButton(\u0026quot;scissors\u0026quot;,\u0026quot;Scissors\u0026quot;) ) ) Here offset controls spacing from a previous column call (not used here since everything is in one column() call). Each actionButton() call draws one of the buttons – the first argument is the variable name of this button, which is used as input for the server, and the second argument is the text that appears on the button. An overview of the many kinds of interactive elements you can add is avilable here.\nFinally I add some text to describe game events and point interested users to the source code, with;\nfluidRow(width=5,offset=5, textOutput(\u0026quot;result\u0026quot;),br(), p(\u0026quot;Source code available at: https://github.com/MacStrelioff/RockPaperScissors\u0026quot;) ) Here textOutput(\u0026quot;OUTPUT_NAME\u0026quot;) takes the text ouput variable OUTPUT_NAME from the server and displays it. br(), named after a line break in HTML (\u0026lt;br\u0026gt;) adds a line break. And p() adds static text, again named after a paragraph tag (\u0026lt;p\u0026gt;) in HTML.\n Server The server defines how page elements interact with user input and server events.\nComponents My code for the server is shown below and broken down in this section with an emphasis on the functions used. In the code below, I replaced opponent logic with ... to keep the emphasis here on understanding server functions. This logic is revealed and detailed in the next section.\nserver \u0026lt;- function(input, output) { # initialize variables (runs once when app visited) values \u0026lt;- reactiveValues() values$round =0; # track round values$opp_actions = c() # track opponent actions values$score =0; # track score values$scores=0; # track score history for feedback values$grams = data.frame(\u0026#39;rrrrr\u0026#39;=rep(0,3)) # initialize to store gram counts values$a = \u0026quot;init\u0026quot;; values$as = c(\u0026quot;r\u0026quot;,\u0026quot;p\u0026quot;,\u0026quot;s\u0026quot;) # possible actions observeEvent(input$rock | input$paper | input$scissors,{ # if any action taken (done to block the first run when these are all NULL-\u0026gt;0) if(input$rock | input$paper | input$scissors){ # increment round values$round = values$round+1; # policy -- code to greedily pick best action ## if fewer than 5 actions taken, draw uniformly if(length(values$opp_actions)\u0026lt;5){ values$a=sample(values$as,1) } else{ # if at least 5 actions taken nobs = length(values$opp_actions) ngram = paste(values$opp_actions[(nobs-4):nobs],collapse = \u0026quot;\u0026quot;) #cat(\u0026quot;\\n\u0026quot;,ngram) # if this pattern not observed before, initialize it and choose randomly if(!any(names(values$grams)==ngram)){ values$grams[ngram]=rep(0,3) values$a=sample(values$as,1) } else { # if at least 5 actions taken, and this pattern has been seen before, pred = values$as[which.max(values$grams[ngram][[1]])] values$a=switch(pred,\u0026quot;r\u0026quot;=\u0026quot;p\u0026quot;,\u0026quot;p\u0026quot;=\u0026quot;s\u0026quot;,\u0026quot;s\u0026quot;=\u0026quot;r\u0026quot;) } #cat(\u0026quot;\\n\u0026quot;,names(values$grams)) #cat(\u0026quot;\\n\u0026quot;,values$grams[ngram][[1]]) } # get opponent action and outcome if(input$rock -sum(values$opp_actions==\u0026quot;r\u0026quot;)==1){ opp_action=\u0026quot;r\u0026quot; dscore = switch(values$a,\u0026quot;r\u0026quot;=0,\u0026quot;p\u0026quot;=-1,\u0026quot;s\u0026quot;=1) } if(input$paper -sum(values$opp_actions==\u0026quot;p\u0026quot;)==1){ opp_action=\u0026quot;p\u0026quot; dscore = switch(values$a,\u0026quot;r\u0026quot;=1,\u0026quot;p\u0026quot;=0,\u0026quot;s\u0026quot;=-1) } if(input$scissors-sum(values$opp_actions==\u0026quot;s\u0026quot;)==1){ opp_action=\u0026quot;s\u0026quot; dscore = switch(values$a,\u0026quot;r\u0026quot;=-1,\u0026quot;p\u0026quot;=1,\u0026quot;s\u0026quot;=0) } # evaluate outcome values$score = values$score+dscore values$scores = c(values$scores,values$score); # update opponent model values$opp_actions = c(values$opp_actions,opp_action); if(length(values$opp_actions)\u0026gt;5){ if(any(names(values$grams)==ngram)){ values$grams[ngram][[1]]=values$grams[ngram][[1]]+(values$as==opp_action) } } } # use strings to code, then just take last 5 strings and use as the key for the dictionary of 5-grams... output$distPlot \u0026lt;- renderPlot({ try({ x = seq(0,values$round); y = values$scores; cat(\u0026quot;\\n round:\u0026quot;,values$round, \u0026quot;, score:\u0026quot;,values$score,\u0026quot;, len(x): \u0026quot;,length(x),\u0026quot; len(y):\u0026quot;,length(y),\u0026quot;, opp_act:\u0026quot;,values$opp_actions, \u0026quot;\\n a: \u0026quot;,values$a, sep=\u0026quot;\u0026quot;) # draw the histogram with the specified number of bins plot(x,y,type=\u0026quot;l\u0026quot;,xlab = \u0026quot;Rounds\u0026quot;,ylab=\u0026quot;Score\u0026quot;,main=\u0026quot;Cumulative Score\u0026quot;) }) }) }) output$result = renderText({ paste(\u0026quot;Opponent chose: \u0026quot;,switch(values$a,\u0026quot;r\u0026quot;=\u0026quot;Rock\u0026quot;,\u0026quot;p\u0026quot;=\u0026quot;Paper\u0026quot;,\u0026quot;s\u0026quot;=\u0026quot;Scissors\u0026quot;,\u0026quot;init\u0026quot;=\u0026quot;Nothing yet, ...\u0026quot;)) }) } The first chunk here, shown below, uses the reactiveValues() function to create a named list of variables that can be updated throughout the app session.\n# initialize variables (runs once when app visited) values \u0026lt;- reactiveValues() values$round =0; # track round values$opp_actions = c() # track opponent actions values$score =0; # track score values$scores=0; # track score history for feedback values$grams = data.frame(\u0026#39;rrrrr\u0026#39;=rep(0,3)) # initialize to store gram counts values$a = \u0026quot;init\u0026quot;; values$as = c(\u0026quot;r\u0026quot;,\u0026quot;p\u0026quot;,\u0026quot;s\u0026quot;) # possible actions The next section uses observeEvent(LOGICAL) to check if an event has occurred. Here the events are a TRUE value from any of the buttons, which would represent that the button had been pressed. The variables input$NAME represent the button whose label is NAME. The second argument is a script to run when an event is detected. Note that the values for variables that reflect button presses, here input$rock, input$paper, input$scissors, are initialized as NULL, so the server will first run once with these values as NULL. To avoid the game from starting on this run, I included a conditional that required one of their values to be TRUE, which would indicate that the player clicked one of the buttons. The rest of this block is replaced with ... because it is game logic that is described below, however, it heavily relies on access to the reactive values stored in the values structure.\n observeEvent(input$rock | input$paper | input$scissors,{ # if any action taken (done to block the first run when these are all NULL-\u0026gt;0) if(input$rock | input$paper | input$scissors){ ... } } The last two chunks use the renderPlot() function to produce the distPlot variable, stored in the output structure, which is referenced in the ui when drawing the figure. This code occasionally crashed when button presses happened rapidly, so I wrapped it in a try() block. The cat() function was used to print values to the console while debugging. Finally, I used the renderText() function to assign textual feedback on the agent’s actions to the output variable result which is referenced in the ui when displaying the text that is rendered here.\noutput$distPlot \u0026lt;- renderPlot({ try({ x = seq(0,values$round); y = values$scores; cat(\u0026quot;\\n round:\u0026quot;,values$round, \u0026quot;, score:\u0026quot;,values$score,\u0026quot;, len(x): \u0026quot;,length(x),\u0026quot; len(y):\u0026quot;,length(y),\u0026quot;, opp_act:\u0026quot;,values$opp_actions, \u0026quot;\\n a: \u0026quot;,values$a, sep=\u0026quot;\u0026quot;) # draw the histogram with the specified number of bins plot(x,y,type=\u0026quot;l\u0026quot;,xlab = \u0026quot;Rounds\u0026quot;,ylab=\u0026quot;Score\u0026quot;,main=\u0026quot;Cumulative Score\u0026quot;) }) }) }) output$result = renderText({ paste(\u0026quot;Opponent chose: \u0026quot;,switch(values$a,\u0026quot;r\u0026quot;=\u0026quot;Rock\u0026quot;,\u0026quot;p\u0026quot;=\u0026quot;Paper\u0026quot;,\u0026quot;s\u0026quot;=\u0026quot;Scissors\u0026quot;,\u0026quot;init\u0026quot;=\u0026quot;Nothing yet, ...\u0026quot;)) })  Rock Paper Scissors Agent Logic Here I return to the logic inside the observeEvent() call that implements the game. This code is run whenever a user chooses an action. First I increment the round, which is stored in the reactiveValue structure, values;\n# increment round values$round = values$round+1; I then implemented the agent’s policy. In a reinforcement learning context, a policy is an agent’s probability distribution over actions. The actions here are stored in the reactive value as which consists of “r”,“p”, and “s”, respectively representing the actions Rock, Paper, or Scissors. The policy I implemented here depends on the last 5 actions that a user takes. The entire history of a user’s actions, excluding the current action, is stored in the reactive value opp_actions which is a string consisting of the charasters “r”, “p”, or “s”. For example, if opp_actions is “rrps”, it would mean that the user chose rock twice, then paper, then scissors, before picking the current action which is not yet part of the action history. The agent’s action is stored in the reactive value a. On the first 5 rounds, the agent picks uniformly from the actions Rock, Paper, Scissors;\nif(length(values$opp_actions)\u0026lt;5){ values$a=sample(values$as,1) }  After 5 rounds, the agent uses 5-grams (sequences of the last 5 user actions), to pick an action that will beat the most likely player action based on the previous times the player has emitted this sequence of 5 actions. To implement this, I first get the number of observed actions, nobs, and then get a string that represents the last 5 actions the user has taken, ngram. If theis sequence has not been observed, the agent creates an instance of the sequence in its memory of the users’s 5-grams (grams), initializes counts of the uses subsequent Rock, Paper, Scissors actions to 0, and finally uniformly samples an action. Otherwise, if this sequence has been observed before, the agent predicts what the user will choose on this round (pred) by finding the action that the player most frequently chose in the past after an identical sequence of 5 actions, and then picks the action a that would beat what it expects the player to chose. The code that implements this process is shown below;\n else{ # if at least 5 actions taken nobs = length(values$opp_actions) ngram = paste(values$opp_actions[(nobs-4):nobs],collapse = \u0026quot;\u0026quot;) # if this pattern not observed before, initialize it and choose randomly if(!any(names(values$grams)==ngram)){ values$grams[ngram]=rep(0,3) values$a=sample(values$as,1) } else { # if at least 5 actions taken, and this pattern has been seen before, pred = values$as[which.max(values$grams[ngram][[1]])] values$a=switch(pred,\u0026quot;r\u0026quot;=\u0026quot;p\u0026quot;,\u0026quot;p\u0026quot;=\u0026quot;s\u0026quot;,\u0026quot;s\u0026quot;=\u0026quot;r\u0026quot;) } #cat(\u0026quot;\\n\u0026quot;,names(values$grams)) #cat(\u0026quot;\\n\u0026quot;,values$grams[ngram][[1]]) } The game environment then processes the user’s action and the agent’s action, and determines an outcome of +1 if the user won, 0 if the agent and user tied, and -1 if the agent won;\n# get opponent action and outcome if(input$rock -sum(values$opp_actions==\u0026quot;r\u0026quot;)==1){ opp_action=\u0026quot;r\u0026quot; dscore = switch(values$a,\u0026quot;r\u0026quot;=0,\u0026quot;p\u0026quot;=-1,\u0026quot;s\u0026quot;=1) } if(input$paper -sum(values$opp_actions==\u0026quot;p\u0026quot;)==1){ opp_action=\u0026quot;p\u0026quot; dscore = switch(values$a,\u0026quot;r\u0026quot;=1,\u0026quot;p\u0026quot;=0,\u0026quot;s\u0026quot;=-1) } if(input$scissors-sum(values$opp_actions==\u0026quot;s\u0026quot;)==1){ opp_action=\u0026quot;s\u0026quot; dscore = switch(values$a,\u0026quot;r\u0026quot;=-1,\u0026quot;p\u0026quot;=1,\u0026quot;s\u0026quot;=0) } The outcome value is added to the cumulative score, score, and the score is appended to the scores variables which stores the score on every round for plotting.\n# evaluate outcome values$score = values$score+dscore values$scores = c(values$scores,values$score); Finally, the agent updates its model of the user by appending the current action to the user’s action history, opp_actions, and updating it’s memory of user behavior stored in grams by incrementing the count of the user’s action associated with the 5-gram for this round, ngram.\n# update opponent model values$opp_actions = c(values$opp_actions,opp_action); if(length(values$opp_actions)\u0026gt;5){ if(any(names(values$grams)==ngram)){ values$grams[ngram][[1]]=values$grams[ngram][[1]]+(values$as==opp_action) }   Hosting Hosting locally Running the function shinyApp(ui = ui, server = server) from RStudio will run the application on a local host. This is great for debugging, but not great for making the app avilable to users on other computers.\n Hosting online RStudio supports many ways of hosting a shiny app, but the one that worked best for me was to host through the free plan at Shinnyapps.io. A detailed walkthrough on deploying shiny apps can be found here.\nIt is also possible to host a Shiny app through Amazon Web Services. More resources on that can be found here, here, or here.\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e8d73948031b59ca722af61e7e30019","permalink":"/MacStrelioff/data-science/shiny_apps_rps/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/data-science/shiny_apps_rps/","section":"data-science","summary":"Overview Shiny apps UI: User Interface Server Components Rock Paper Scissors Agent Logic  Hosting Hosting locally Hosting online     Overview Here I document what I learned, and what resources I found helpful, while I was making my first Shiny app. Shiny apps are an easy way to make web apps from RStudio, with a syntax geared towards online dashboards. As a graduate student in an experimental psychology lab, I wondered if shiny apps could be used to host online experiments.","tags":null,"title":"Shiny Apps","type":"docs"},{"authors":null,"categories":null,"content":" Overview Coherent Examples where frequentist stats is incoherent?\n Flexible  easy to model complex processes easy to test non-standard hypotheses, e.g. “does every”, or “two groups higher, one group lower”   Integration with decision theory Thompson sampling example\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3534ab2119e521ba1e4cffefce56d710","permalink":"/MacStrelioff/unlisted/why_bayes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/MacStrelioff/unlisted/why_bayes/","section":"Unlisted","summary":" Overview Coherent Examples where frequentist stats is incoherent?\n Flexible  easy to model complex processes easy to test non-standard hypotheses, e.g. “does every”, or “two groups higher, one group lower”   Integration with decision theory Thompson sampling example\n  ","tags":null,"title":"Why I Like Bayesian Statistics","type":"Unlisted"}]